{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Midterm Challenge Notebook - Mike Dean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain langchain_openai langchain_core==0.2.40 langchain_community\n",
    "!pip install -qU qdrant_client pymupdf tiktoken ragas pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.  Dealing with the Data\n",
    "(Role: AI Solutions Engineer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, tiktoken\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Path to my directory containing PDF files\n",
    "directory = \"References/\"\n",
    "\n",
    "# List to store all the documents\n",
    "all_docs = []\n",
    "\n",
    "# Iterate through all the files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".pdf\"):  # Check if the file is a PDF\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        loader = PyMuPDFLoader(file_path)\n",
    "        docs = loader.load()\n",
    "        all_docs.extend(docs)  # Append the loaded docs to my list\n",
    "\n",
    "# Default behavior is to break PDF files into their pages\n",
    "# Using tiktoken, I checked the token lengths of several representative pages and\n",
    "# the lengths were always less than 1000 tokens, so INITIAL STRATEGY is to use\n",
    "# each document as a single chunk and not further split.\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "page_split_vectorstore = Qdrant.from_documents(\n",
    "    all_docs,\n",
    "    embedding_model,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"page_split_collection\",\n",
    ")\n",
    "page_split_retriever = page_split_vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ALTERNATIVE STRATEGY is to recombine all the pages into one string document and then\n",
    "# split it.  The advantage of this approach is to have chunk overlap, which is not\n",
    "# possible with my initial strategy.\n",
    "\n",
    "one_document = \"\"\n",
    "for doc in all_docs:\n",
    "    one_document += doc.page_content\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    tokens = tiktoken.encoding_for_model(\"gpt-4o\").encode(\n",
    "        text,\n",
    "    )\n",
    "    return len(tokens)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap = 400,\n",
    "    length_function = tiktoken_len,\n",
    ")\n",
    "\n",
    "split_chunks = text_splitter.split_text(one_document)\n",
    "\n",
    "chunk_split_vectorstore = Qdrant.from_documents(\n",
    "    text_splitter.create_documents(split_chunks),\n",
    "    embedding_model,\n",
    "    location=\":memory:\",\n",
    "    collection_name=\"chunk_split_collection\",\n",
    ")\n",
    "\n",
    "chunk_split_retriever = chunk_split_vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='page_split_collection')]\n",
      "collections=[CollectionDescription(name='chunk_split_collection')]\n"
     ]
    }
   ],
   "source": [
    "## Check that I have two vectorstores in memory\n",
    "client = page_split_vectorstore.client\n",
    "print(client.get_collections())\n",
    "client = chunk_split_vectorstore.client\n",
    "print(client.get_collections())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 Deliverables:\n",
    "1.  Describe the default chunking strategy that I will use:<br>\n",
    "The default strategy will be to load the two PDF files using `PyMuPDFLoader` just as we have previously done.  This results in each PDF page being its own document.  I have checked sample pages with `tiktoken` and the token count per page is <1000, so these are small enough to just embed without further splitting. I saved these embeddings in `page_split_vectorstore`.\n",
    "\n",
    "2.  Articulate a chunking strategy that I will also test:<br>\n",
    "The disadvantage of the default strategy is that there is no chunk overlapping between the pages, and this might worsen the ability connect two pages that are both relevant to a query.  So I  recombine the page_content of all pages into a single string, convert it into a document, and split it with a chunk size of 800 and an overlap of 400 (the default settings used by OpenAI).  This strategy allows chunks to overlap, pehaps adding semantic continuity between adjacent pages.  These were embedded with the same embedding model and saved in `chunk_split_vectorstore`.\n",
    "\n",
    "3.  Describe how and why I made these decisions:<br>\n",
    "The default behavior of `PyMuPDFLoader` is not bad and I have been using it for several months.  However, I was splitting each of the documents created, not thinking through that if I had chunk sizes greater than the page itself, this was meaningless.  I also had chunk overlap, but had not thought through the implications of each page being a separate document.  So I made these decision for this Midterm Challenge so I can later compare the performance using RAGAS in Task 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2.  Building a Quick End-to-End Prototype\n",
    "(Role: AI Systems Engineer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "rag_prompt_template = \"\"\"\\\n",
    "You are a helpful and polite and cheerful assistant who answers questions based solely on the provided context. \n",
    "Use the context to answer the question and provide a  clear answer. Do not mention the document in your\n",
    "response.\n",
    "If there is no specific information\n",
    "relevant to the question, then tell the user that you can't answer based on the context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(rag_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "## CREATE MY TWO RAG CHAINS\n",
    "\n",
    "page_split_rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | page_split_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | rag_prompt | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "chunk_split_rag_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | chunk_split_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | rag_prompt | llm | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided context, the ten major risks of AI include:\n",
       "\n",
       "1. Confabulation\n",
       "2. Dangerous or Violent Recommendations\n",
       "3. Data Privacy\n",
       "4. Value Chain and Component Integration\n",
       "5. Harmful Bias\n",
       "6. Homogenization\n",
       "7. CBRN Information or Capabilities\n",
       "8. Human-AI Configuration\n",
       "9. Obscene, Degrading, and/or Abusive Content\n",
       "10. Information Integrity"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Some risks of AI include:\n",
       "\n",
       "1. **Confabulation**: The production of confidently stated but erroneous or false content, misleading or deceiving users.\n",
       "2. **Dangerous, Violent, or Hateful Content**: Easier production and access to violent, inciting, radicalizing, or threatening content, including recommendations to carry out self-harm or illegal activities.\n",
       "3. **Data Privacy**: Impacts due to leakage and unauthorized use, disclosure, or de-anonymization of personal or sensitive data.\n",
       "4. **Environmental Impacts**: Adverse effects on ecosystems due to high compute resource utilization in training or operating AI models.\n",
       "5. **Harmful Bias or Homogenization**: Amplification and exacerbation of historical, societal, and systemic biases, and performance disparities between different sub-groups or languages.\n",
       "6. **Algorithmic Monocultures**: Increased susceptibility to correlated failures due to multiple actors relying on the same model or algorithm in decision-making settings.\n",
       "7. **Disinformation**: Long-term effects on societal trust in public institutions due to the distribution of harmful deepfake images and disinformation.\n",
       "\n",
       "These risks can vary significantly depending on the characteristics of the AI model, system, or use case, and may require tailored risk management approaches."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "## TEST THE TWO CHAINS\n",
    "page_response = (page_split_rag_chain.invoke({\"question\": \"List the ten major risks of AI?\"}))\n",
    "display(Markdown(page_response))\n",
    "\n",
    "chunk_response = (chunk_split_rag_chain.invoke({\"question\": \"What are some risks of AI?\"}))\n",
    "display(Markdown(chunk_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 Deliverables:\n",
    "1.  Build a live public prototype on Hugging Face, and include the public URL link to my space.<br>\n",
    "\n",
    "Here is a one minute Loom video that demonstrates the prototype running in Hugging Face.\n",
    "https://www.loom.com/share/70b741d3e4e14af792572b3aa9106463?sid=5aeb2e51-0f75-4c74-9f8c-6bc6d14aaa52\n",
    "\n",
    "I used the page split retriever for this prototype, meaning that the documents were broken by page, not recombined, and were chunked as whole pages without overlap.\n",
    "\n",
    "2.  How did I choose my stack, and why did I select each tool the way it Did? <br>\n",
    "\n",
    "My stack consists of the following:\n",
    "- Hardware is Apple Mac Studio\n",
    "- Editor is VSC as recommended, and I have grown to like it very much  because it includes everything.\n",
    "- Qdrant is the vector store.  I have used FAISS and Chroma, but Qdrant is fantastic.  I run it locally as a server, though for this Hugging Face situation, I am using a memory-based implementation.\n",
    "- ChainLit is the interface, as recommended.  Notably, the current version of ChainLit does NOT work on Hugging Face, and the version needs to be locked (chainlit==0.7.700).\n",
    "- RAGAS is part of my stack for purposes of later evaluation.\n",
    "- LangChain is used to help simplify the code.\n",
    "\n",
    "I didn't choose this stack by accident, as all of it was suggested in the course.  However, I have resisted moving from one framework to another, etc., because I think important to stop wandering in the AIE jungle and learn one set of tools well.  This will prepare me to switch to other frameworks, if desired, but I think the key is to learn a set of reliable tools well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3.  Creating a Golden Test Data Set\n",
    "(Role: AI Evaluation and Performance Engineer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We already have loaded the text but need to chunk it differently\n",
    "\n",
    "\n",
    "text_splitter_eval = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 400,\n",
    "    chunk_overlap = 100,\n",
    "    length_function = tiktoken_len,\n",
    ")\n",
    "\n",
    "eval_chunks = text_splitter_eval.split_text(one_document)\n",
    "eval_documents = text_splitter_eval.create_documents(eval_chunks)\n",
    "len(eval_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c38a82fc366d4c1f8d68338fd6a87c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding nodes:   0%|          | 0/578 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filename and doc_id are the same for all nodes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3c0d04afc04e40832c9e2cfd93f994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "      <th>evolution_type</th>\n",
       "      <th>metadata</th>\n",
       "      <th>episode_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why should data collection be minimized and cl...</td>\n",
       "      <td>[from reidentification, and appropriate techni...</td>\n",
       "      <td>Data collection should be minimized and clearl...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why are proactive equity assessments important...</td>\n",
       "      <td>[sex \\n(including \\npregnancy, \\nchildbirth, \\...</td>\n",
       "      <td>Proactive equity assessments are important in ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the limitations of early lifecycle TE...</td>\n",
       "      <td>[49 \\nearly lifecycle TEVV approaches are deve...</td>\n",
       "      <td>Currently available pre-deployment TEVV proces...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the significance of intellectual prope...</td>\n",
       "      <td>[content transparency, while balancing the pro...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What measures are suggested to address harmful...</td>\n",
       "      <td>[experts, experience with GAI technology) with...</td>\n",
       "      <td>The suggested measures to address harmful bias...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What is the purpose of the Technical Companion...</td>\n",
       "      <td>[moving principles into practice. \\nThe expect...</td>\n",
       "      <td>The expectations given in the Technical Compan...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What are some examples of automated systems fo...</td>\n",
       "      <td>[Examples of automated systems for which the B...</td>\n",
       "      <td>Examples of automated systems for which the Bl...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What is the purpose of engaging in internal an...</td>\n",
       "      <td>[MS-1.1-008 \\nDeﬁne use cases, contexts of use...</td>\n",
       "      <td>The purpose of engaging in internal and extern...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How does the Office of Management and Budget (...</td>\n",
       "      <td>[requirements on drivers, such as slowing down...</td>\n",
       "      <td>The Office of Management and Budget (OMB) has ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What are the sources of bias in GAI training a...</td>\n",
       "      <td>[might be impacted by GAI systems through dire...</td>\n",
       "      <td>Sources of bias in GAI training and TEVV data ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>What actions are suggested to address harmful ...</td>\n",
       "      <td>[Human-AI Conﬁguration; \\nConfabulation  \\nAI ...</td>\n",
       "      <td>The suggested actions to address harmful bias ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Why is it important for notices about the use ...</td>\n",
       "      <td>[explained below. \\nProvide clear, timely, und...</td>\n",
       "      <td>Users should receive notice of the use of auto...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>What measures are necessary to manage privacy ...</td>\n",
       "      <td>[from reidentification, and appropriate techni...</td>\n",
       "      <td>Entities that collect, use, share, or store se...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>What is the purpose of the AI RMF Playbook pro...</td>\n",
       "      <td>[20in%20this%20category,data%20providers%2C%20...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>What is the purpose of creating measurement er...</td>\n",
       "      <td>[applications, and address green-washing conce...</td>\n",
       "      <td>The purpose of creating measurement error mode...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How can AI red-teaming be used to enhance the ...</td>\n",
       "      <td>[making tasks informed by GAI content), and ho...</td>\n",
       "      <td>Integrating pre- and post-deployment external ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How are systems derived from machine learning ...</td>\n",
       "      <td>[innovation to flourish while protecting peopl...</td>\n",
       "      <td>Systems derived from machine learning are cate...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How did transparency requirements in smart cit...</td>\n",
       "      <td>[Devin E. Willis, Attorney, Division of Privac...</td>\n",
       "      <td>Strong transparency requirements in smart city...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What types of systems related to equal opportu...</td>\n",
       "      <td>[Examples of automated systems for which the B...</td>\n",
       "      <td>Education-related systems such as algorithms t...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>How are hacking, malware, and phishing related...</td>\n",
       "      <td>[hacking, malware, and phishing. Reports have ...</td>\n",
       "      <td>LLMs are already able to discover some vulnera...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Who were some of the participants from the pri...</td>\n",
       "      <td>[61\\nAPPENDIX\\n• OSTP conducted meetings with ...</td>\n",
       "      <td>Participants from the private sector and civil...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Why is clear and understandable notice importa...</td>\n",
       "      <td>[ness of a recommendation before enacting it. ...</td>\n",
       "      <td>Clear and understandable notice is important w...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>What are the suggested actions for addressing ...</td>\n",
       "      <td>[the AI system, or other data are identiﬁed an...</td>\n",
       "      <td>The suggested actions for addressing content p...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What action is suggested to ensure information...</td>\n",
       "      <td>[conditions under which the technology was dev...</td>\n",
       "      <td>Verify GAI system training data and TEVV data ...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>What are the key requirements for the independ...</td>\n",
       "      <td>[identify contexts for limited reuse based on ...</td>\n",
       "      <td>The key requirements for the independent evalu...</td>\n",
       "      <td>simple</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>How to spot and reduce hidden risks in GAI wit...</td>\n",
       "      <td>[Information or Capabilities; \\nDangerous, Vio...</td>\n",
       "      <td>To spot and reduce hidden risks in GAI with ne...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>How can devs ensure transparency, user agency,...</td>\n",
       "      <td>[and data agency can be meaningful and not ove...</td>\n",
       "      <td>Developers can ensure transparency, user agenc...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>What did the panelists suggest for AI transpar...</td>\n",
       "      <td>[human-computer \\ninteraction with an emphasis...</td>\n",
       "      <td>The panelists suggested ongoing transparency, ...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>How do equity assessments and avoiding demogra...</td>\n",
       "      <td>[research and development or during its acquis...</td>\n",
       "      <td>Equity assessments and avoiding demographic pr...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>How do Algorithmic Bias Safeguards tackle data...</td>\n",
       "      <td>[recommending early interventions for the pati...</td>\n",
       "      <td>Algorithmic Bias Safeguards tackle data privac...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>How does AI red-teaming help secure GAI system...</td>\n",
       "      <td>[Information Integrity; Information \\nSecurity...</td>\n",
       "      <td>AI red-teaming helps secure GAI systems by ass...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>How might GAI in daily life reduce linguistic ...</td>\n",
       "      <td>[endangered languages more diﬃcult if GAI syst...</td>\n",
       "      <td>GAI systems embedded in everyday processes cou...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>How can those managing automated systems ensur...</td>\n",
       "      <td>[SECTION TITLE\\nBLUEPRINT FOR AN\\nSAFE AND E \\...</td>\n",
       "      <td>Those responsible for the development, use, or...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Who from private sector and civil society disc...</td>\n",
       "      <td>[Philadelphia Unemployment \\nProject \\nProject...</td>\n",
       "      <td>Participants from the private sector and civil...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>How do public insights shape fraud detection i...</td>\n",
       "      <td>[impact control algorithms; and\\nSystems relat...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>How might adapting GAI models to new domains i...</td>\n",
       "      <td>[the AI system, or other data are identiﬁed an...</td>\n",
       "      <td>Adapting GAI models to new domains may increas...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>How do GAI security co-pilots and disinfo camp...</td>\n",
       "      <td>[hacking, malware, and phishing. Reports have ...</td>\n",
       "      <td>GAI security co-pilots can exploit system flaw...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Who should get reports on automated systems fo...</td>\n",
       "      <td>[monitoring, and governance structures for aut...</td>\n",
       "      <td>Reports on automated systems should be provide...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>How do NIST's AI Safety Institute and RMF supp...</td>\n",
       "      <td>[Gina M. Raimondo, Secretary \\nNational Instit...</td>\n",
       "      <td>NIST established the U.S. AI Safety Institute ...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>What are the short and long-term societal impa...</td>\n",
       "      <td>[the impact of GAI on the labor market, though...</td>\n",
       "      <td>Short-term societal impacts of human-GAI inter...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>How does the 2022 NIST pub handle AI bias and ...</td>\n",
       "      <td>[20in%20this%20category,data%20providers%2C%20...</td>\n",
       "      <td>The answer to given question is not present in...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>How do transparent models in high-risk systems...</td>\n",
       "      <td>[highest level of risk so the system is design...</td>\n",
       "      <td>Transparent models in high-risk systems ensure...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Where to direct inquiries about AI RMF 1.0 for...</td>\n",
       "      <td>[Stanley, and Elham Tabassi. \\nNIST Technical ...</td>\n",
       "      <td>Inquiries about AI RMF 1.0 for Generative AI i...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>How did the panel suggest managing AI risks in...</td>\n",
       "      <td>[human-computer \\ninteraction with an emphasis...</td>\n",
       "      <td>The panel suggested managing AI risks in high-...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>How do orgs manage data privacy and IP risks w...</td>\n",
       "      <td>[48 \\n• Data protection \\n• Data retention  \\n...</td>\n",
       "      <td>Organizations manage data privacy and intellec...</td>\n",
       "      <td>multi_context</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Which doc outlines civil rights principles in AI?</td>\n",
       "      <td>[design, use, and deployment of automated syst...</td>\n",
       "      <td>The Blueprint for an AI Bill of Rights outline...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>How to adapt GAI models to new domains with ri...</td>\n",
       "      <td>[the AI system, or other data are identiﬁed an...</td>\n",
       "      <td>Re-evaluate risks when adapting GAI models to ...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{}, {}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>How does AI red-teaming differ from early part...</td>\n",
       "      <td>[decision making, and enhancing system documen...</td>\n",
       "      <td>AI red-teaming is an evolving practice that in...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>What issues do NPR and Motherboard highlight a...</td>\n",
       "      <td>[6. Andrew Wong et al. External validation of ...</td>\n",
       "      <td>NPR and Motherboard highlight issues related t...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>How does monitoring tackle unexpected algorith...</td>\n",
       "      <td>[justification for any continued use of the sy...</td>\n",
       "      <td>Monitoring tackles unexpected algorithm bias b...</td>\n",
       "      <td>reasoning</td>\n",
       "      <td>[{}]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "0   Why should data collection be minimized and cl...   \n",
       "1   Why are proactive equity assessments important...   \n",
       "2   What are the limitations of early lifecycle TE...   \n",
       "3   What is the significance of intellectual prope...   \n",
       "4   What measures are suggested to address harmful...   \n",
       "5   What is the purpose of the Technical Companion...   \n",
       "6   What are some examples of automated systems fo...   \n",
       "7   What is the purpose of engaging in internal an...   \n",
       "8   How does the Office of Management and Budget (...   \n",
       "9   What are the sources of bias in GAI training a...   \n",
       "10  What actions are suggested to address harmful ...   \n",
       "11  Why is it important for notices about the use ...   \n",
       "12  What measures are necessary to manage privacy ...   \n",
       "13  What is the purpose of the AI RMF Playbook pro...   \n",
       "14  What is the purpose of creating measurement er...   \n",
       "15  How can AI red-teaming be used to enhance the ...   \n",
       "16  How are systems derived from machine learning ...   \n",
       "17  How did transparency requirements in smart cit...   \n",
       "18  What types of systems related to equal opportu...   \n",
       "19  How are hacking, malware, and phishing related...   \n",
       "20  Who were some of the participants from the pri...   \n",
       "21  Why is clear and understandable notice importa...   \n",
       "22  What are the suggested actions for addressing ...   \n",
       "23  What action is suggested to ensure information...   \n",
       "24  What are the key requirements for the independ...   \n",
       "25  How to spot and reduce hidden risks in GAI wit...   \n",
       "26  How can devs ensure transparency, user agency,...   \n",
       "27  What did the panelists suggest for AI transpar...   \n",
       "28  How do equity assessments and avoiding demogra...   \n",
       "29  How do Algorithmic Bias Safeguards tackle data...   \n",
       "30  How does AI red-teaming help secure GAI system...   \n",
       "31  How might GAI in daily life reduce linguistic ...   \n",
       "32  How can those managing automated systems ensur...   \n",
       "33  Who from private sector and civil society disc...   \n",
       "34  How do public insights shape fraud detection i...   \n",
       "35  How might adapting GAI models to new domains i...   \n",
       "36  How do GAI security co-pilots and disinfo camp...   \n",
       "37  Who should get reports on automated systems fo...   \n",
       "38  How do NIST's AI Safety Institute and RMF supp...   \n",
       "39  What are the short and long-term societal impa...   \n",
       "40  How does the 2022 NIST pub handle AI bias and ...   \n",
       "41  How do transparent models in high-risk systems...   \n",
       "42  Where to direct inquiries about AI RMF 1.0 for...   \n",
       "43  How did the panel suggest managing AI risks in...   \n",
       "44  How do orgs manage data privacy and IP risks w...   \n",
       "45  Which doc outlines civil rights principles in AI?   \n",
       "46  How to adapt GAI models to new domains with ri...   \n",
       "47  How does AI red-teaming differ from early part...   \n",
       "48  What issues do NPR and Motherboard highlight a...   \n",
       "49  How does monitoring tackle unexpected algorith...   \n",
       "\n",
       "                                             contexts  \\\n",
       "0   [from reidentification, and appropriate techni...   \n",
       "1   [sex \\n(including \\npregnancy, \\nchildbirth, \\...   \n",
       "2   [49 \\nearly lifecycle TEVV approaches are deve...   \n",
       "3   [content transparency, while balancing the pro...   \n",
       "4   [experts, experience with GAI technology) with...   \n",
       "5   [moving principles into practice. \\nThe expect...   \n",
       "6   [Examples of automated systems for which the B...   \n",
       "7   [MS-1.1-008 \\nDeﬁne use cases, contexts of use...   \n",
       "8   [requirements on drivers, such as slowing down...   \n",
       "9   [might be impacted by GAI systems through dire...   \n",
       "10  [Human-AI Conﬁguration; \\nConfabulation  \\nAI ...   \n",
       "11  [explained below. \\nProvide clear, timely, und...   \n",
       "12  [from reidentification, and appropriate techni...   \n",
       "13  [20in%20this%20category,data%20providers%2C%20...   \n",
       "14  [applications, and address green-washing conce...   \n",
       "15  [making tasks informed by GAI content), and ho...   \n",
       "16  [innovation to flourish while protecting peopl...   \n",
       "17  [Devin E. Willis, Attorney, Division of Privac...   \n",
       "18  [Examples of automated systems for which the B...   \n",
       "19  [hacking, malware, and phishing. Reports have ...   \n",
       "20  [61\\nAPPENDIX\\n• OSTP conducted meetings with ...   \n",
       "21  [ness of a recommendation before enacting it. ...   \n",
       "22  [the AI system, or other data are identiﬁed an...   \n",
       "23  [conditions under which the technology was dev...   \n",
       "24  [identify contexts for limited reuse based on ...   \n",
       "25  [Information or Capabilities; \\nDangerous, Vio...   \n",
       "26  [and data agency can be meaningful and not ove...   \n",
       "27  [human-computer \\ninteraction with an emphasis...   \n",
       "28  [research and development or during its acquis...   \n",
       "29  [recommending early interventions for the pati...   \n",
       "30  [Information Integrity; Information \\nSecurity...   \n",
       "31  [endangered languages more diﬃcult if GAI syst...   \n",
       "32  [SECTION TITLE\\nBLUEPRINT FOR AN\\nSAFE AND E \\...   \n",
       "33  [Philadelphia Unemployment \\nProject \\nProject...   \n",
       "34  [impact control algorithms; and\\nSystems relat...   \n",
       "35  [the AI system, or other data are identiﬁed an...   \n",
       "36  [hacking, malware, and phishing. Reports have ...   \n",
       "37  [monitoring, and governance structures for aut...   \n",
       "38  [Gina M. Raimondo, Secretary \\nNational Instit...   \n",
       "39  [the impact of GAI on the labor market, though...   \n",
       "40  [20in%20this%20category,data%20providers%2C%20...   \n",
       "41  [highest level of risk so the system is design...   \n",
       "42  [Stanley, and Elham Tabassi. \\nNIST Technical ...   \n",
       "43  [human-computer \\ninteraction with an emphasis...   \n",
       "44  [48 \\n• Data protection \\n• Data retention  \\n...   \n",
       "45  [design, use, and deployment of automated syst...   \n",
       "46  [the AI system, or other data are identiﬁed an...   \n",
       "47  [decision making, and enhancing system documen...   \n",
       "48  [6. Andrew Wong et al. External validation of ...   \n",
       "49  [justification for any continued use of the sy...   \n",
       "\n",
       "                                         ground_truth evolution_type  \\\n",
       "0   Data collection should be minimized and clearl...         simple   \n",
       "1   Proactive equity assessments are important in ...         simple   \n",
       "2   Currently available pre-deployment TEVV proces...         simple   \n",
       "3   The answer to given question is not present in...         simple   \n",
       "4   The suggested measures to address harmful bias...         simple   \n",
       "5   The expectations given in the Technical Compan...         simple   \n",
       "6   Examples of automated systems for which the Bl...         simple   \n",
       "7   The purpose of engaging in internal and extern...         simple   \n",
       "8   The Office of Management and Budget (OMB) has ...         simple   \n",
       "9   Sources of bias in GAI training and TEVV data ...         simple   \n",
       "10  The suggested actions to address harmful bias ...         simple   \n",
       "11  Users should receive notice of the use of auto...         simple   \n",
       "12  Entities that collect, use, share, or store se...         simple   \n",
       "13  The answer to given question is not present in...         simple   \n",
       "14  The purpose of creating measurement error mode...         simple   \n",
       "15  Integrating pre- and post-deployment external ...         simple   \n",
       "16  Systems derived from machine learning are cate...         simple   \n",
       "17  Strong transparency requirements in smart city...         simple   \n",
       "18  Education-related systems such as algorithms t...         simple   \n",
       "19  LLMs are already able to discover some vulnera...         simple   \n",
       "20  Participants from the private sector and civil...         simple   \n",
       "21  Clear and understandable notice is important w...         simple   \n",
       "22  The suggested actions for addressing content p...         simple   \n",
       "23  Verify GAI system training data and TEVV data ...         simple   \n",
       "24  The key requirements for the independent evalu...         simple   \n",
       "25  To spot and reduce hidden risks in GAI with ne...  multi_context   \n",
       "26  Developers can ensure transparency, user agenc...  multi_context   \n",
       "27  The panelists suggested ongoing transparency, ...  multi_context   \n",
       "28  Equity assessments and avoiding demographic pr...  multi_context   \n",
       "29  Algorithmic Bias Safeguards tackle data privac...  multi_context   \n",
       "30  AI red-teaming helps secure GAI systems by ass...  multi_context   \n",
       "31  GAI systems embedded in everyday processes cou...  multi_context   \n",
       "32  Those responsible for the development, use, or...  multi_context   \n",
       "33  Participants from the private sector and civil...  multi_context   \n",
       "34  The answer to given question is not present in...  multi_context   \n",
       "35  Adapting GAI models to new domains may increas...  multi_context   \n",
       "36  GAI security co-pilots can exploit system flaw...  multi_context   \n",
       "37  Reports on automated systems should be provide...  multi_context   \n",
       "38  NIST established the U.S. AI Safety Institute ...  multi_context   \n",
       "39  Short-term societal impacts of human-GAI inter...  multi_context   \n",
       "40  The answer to given question is not present in...  multi_context   \n",
       "41  Transparent models in high-risk systems ensure...  multi_context   \n",
       "42  Inquiries about AI RMF 1.0 for Generative AI i...  multi_context   \n",
       "43  The panel suggested managing AI risks in high-...  multi_context   \n",
       "44  Organizations manage data privacy and intellec...  multi_context   \n",
       "45  The Blueprint for an AI Bill of Rights outline...      reasoning   \n",
       "46  Re-evaluate risks when adapting GAI models to ...      reasoning   \n",
       "47  AI red-teaming is an evolving practice that in...      reasoning   \n",
       "48  NPR and Motherboard highlight issues related t...      reasoning   \n",
       "49  Monitoring tackles unexpected algorithm bias b...      reasoning   \n",
       "\n",
       "    metadata  episode_done  \n",
       "0       [{}]          True  \n",
       "1       [{}]          True  \n",
       "2       [{}]          True  \n",
       "3       [{}]          True  \n",
       "4       [{}]          True  \n",
       "5       [{}]          True  \n",
       "6       [{}]          True  \n",
       "7       [{}]          True  \n",
       "8       [{}]          True  \n",
       "9       [{}]          True  \n",
       "10      [{}]          True  \n",
       "11      [{}]          True  \n",
       "12  [{}, {}]          True  \n",
       "13  [{}, {}]          True  \n",
       "14      [{}]          True  \n",
       "15      [{}]          True  \n",
       "16      [{}]          True  \n",
       "17      [{}]          True  \n",
       "18  [{}, {}]          True  \n",
       "19  [{}, {}]          True  \n",
       "20      [{}]          True  \n",
       "21      [{}]          True  \n",
       "22      [{}]          True  \n",
       "23      [{}]          True  \n",
       "24      [{}]          True  \n",
       "25  [{}, {}]          True  \n",
       "26  [{}, {}]          True  \n",
       "27  [{}, {}]          True  \n",
       "28  [{}, {}]          True  \n",
       "29  [{}, {}]          True  \n",
       "30  [{}, {}]          True  \n",
       "31  [{}, {}]          True  \n",
       "32  [{}, {}]          True  \n",
       "33  [{}, {}]          True  \n",
       "34  [{}, {}]          True  \n",
       "35  [{}, {}]          True  \n",
       "36  [{}, {}]          True  \n",
       "37  [{}, {}]          True  \n",
       "38  [{}, {}]          True  \n",
       "39  [{}, {}]          True  \n",
       "40  [{}, {}]          True  \n",
       "41  [{}, {}]          True  \n",
       "42      [{}]          True  \n",
       "43  [{}, {}]          True  \n",
       "44  [{}, {}]          True  \n",
       "45      [{}]          True  \n",
       "46  [{}, {}]          True  \n",
       "47      [{}]          True  \n",
       "48      [{}]          True  \n",
       "49      [{}]          True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "\n",
    "## llm and embedding models were set earlier\n",
    "generator_llm = llm\n",
    "critic_llm = llm\n",
    "embeddings = embedding_model\n",
    "\n",
    "generator = TestsetGenerator.from_langchain(\n",
    "    generator_llm,\n",
    "    critic_llm,\n",
    "    embeddings\n",
    ")\n",
    "\n",
    "distributions = {\n",
    "    simple: 0.5,\n",
    "    multi_context: 0.4,\n",
    "    reasoning: 0.1\n",
    "}\n",
    "\n",
    "num_qa_pairs = 50 # I increased this from 20 because I have a surplus of OpenAI credits\n",
    "\n",
    "testset = generator.generate_with_langchain_docs(eval_documents, num_qa_pairs, distributions)\n",
    "testset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "testset_df = testset.to_pandas()\n",
    "testset_df.to_csv(\"testset.csv\")\n",
    "test_df = pd.read_csv(\"testset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_questions = test_df[\"question\"].values.tolist()\n",
    "test_groundtruths = test_df[\"ground_truth\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "# Set up chains\n",
    "primary_qa_llm = llm\n",
    "\n",
    "retrieval_augmented_qa_chain_chunk = (\n",
    "    {\"context\": itemgetter(\"question\") | chunk_split_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
    ")\n",
    "retrieval_augmented_qa_chain_paged = (\n",
    "    {\"context\": itemgetter(\"question\") | page_split_retriever, \"question\": itemgetter(\"question\")}\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    | {\"response\": rag_prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't answer that based on the context provided.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is a rule of thumb for selecting an industry to invest in?\"\n",
    "\n",
    "result = retrieval_augmented_qa_chain_chunk.invoke({\"question\" : question})\n",
    "\n",
    "print(result[\"response\"].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate responses with our questions\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for question in test_questions:\n",
    "  response = retrieval_augmented_qa_chain_chunk.invoke({\"question\" : question})\n",
    "  answers.append(response[\"response\"].content)\n",
    "  contexts.append([context.page_content for context in response[\"context\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Why should data collection be minimized and clearly communicated to the people whose data is collected?',\n",
       " 'answer': \"Data collection should be minimized and clearly communicated to the people whose data is collected to protect privacy by default and to ensure that individuals understand what data is being collected about them and how it will be used. This approach helps to match the data collection with people's expectations and desires, thereby minimizing potential harms and privacy risks.\",\n",
       " 'contexts': ['be understandable in plain language, and give you agency over data collection \\nand the specific context of use; current hard-to-understand no\\xad\\ntice-and-choice practices for broad uses of data should be changed. Enhanced \\nprotections and restrictions for data and inferences related to sensitive do\\xad\\nmains, including health, work, education, criminal justice, and finance, and \\nfor data pertaining to youth should put you first. In sensitive domains, your \\ndata and related inferences should only be used for necessary functions, and \\nyou should be protected by ethical review and use prohibitions. You and your \\ncommunities should be free from unchecked surveillance; surveillance tech\\xad\\nnologies should be subject to heightened oversight that includes at least \\npre-deployment assessment of their potential harms and scope limits to pro\\xad\\ntect privacy and civil liberties. Continuous surveillance and monitoring \\nshould not be used in education, work, housing, or in other contexts where the \\nuse of such surveillance technologies is likely to limit rights, opportunities, or \\naccess. Whenever possible, you should have access to reporting that confirms \\nyour data decisions have been respected and provides an assessment of the \\npotential impact of surveillance technologies on your rights, opportunities, or \\naccess. \\nDATA PRIVACY\\n30\\n \\n \\n  \\n \\n \\n \\nDATA PRIVACY \\nWHY THIS PRINCIPLE IS IMPORTANT\\nThis section provides a brief summary of the problems which the principle seeks to address and protect \\nagainst, including illustrative examples. \\nData privacy is a foundational and cross-cutting principle required for achieving all others in this framework. Surveil\\xad\\nlance and data collection, sharing, use, and reuse now sit at the foundation of business models across many industries, \\nwith more and more companies tracking the behavior of the American public, building individual profiles based on \\nthis data, and using this granular-level information as input into automated systems that further track, profile, and \\nimpact the American public. Government agencies, particularly law enforcement agencies, also use and help develop \\na variety of technologies that enhance and expand surveillance capabilities, which similarly collect data used as input \\ninto other automated systems that directly impact people’s lives. Federal law has not grown to address the expanding \\nscale of private data collection, or of the ability of governments at all levels to access that data and leverage the means \\nof private collection.  \\nMeanwhile, members of the American public are often unable to access their personal data or make critical decisions \\nabout its collection and use. Data brokers frequently collect consumer data from numerous sources without \\nconsumers’ permission or knowledge.60 Moreover, there is a risk that inaccurate and faulty data can be used to \\nmake decisions about their lives, such as whether they will qualify for a loan or get a job. Use of surveillance \\ntechnologies has increased in schools and workplaces, and, when coupled with consequential management and \\nevaluation decisions, it is leading to mental health harms such as lowered self-confidence, anxiety, depression, and \\na reduced ability to use analytical reasoning.61 Documented patterns show that personal data is being aggregated by \\ndata brokers to profile communities in harmful ways.62 The impact of all this data harvesting is corrosive, \\nbreeding distrust, anxiety, and other mental health problems; chilling speech, protest, and worker organizing; and \\nthreatening our democratic process.63 The American public should be protected from these growing risks. \\nIncreasingly, some companies are taking these concerns seriously and integrating mechanisms to protect consumer \\nprivacy into their products by design and by default, including by minimizing the data they collect, communicating \\ncollection and use clearly, and improving security practices. Federal government surveillance and other collection and',\n",
       "  'Standardization,57 and the World Wide Web Consortium Web Content Accessibility Guidelines,58 a globally \\nrecognized voluntary consensus standard for web content and other information and communications \\ntechnology. \\nNIST has released Special Publication 1270, Towards a Standard for Identifying and Managing Bias \\nin Artificial Intelligence.59 The special publication: describes the stakes and challenges of bias in artificial \\nintelligence and provides examples of how and why it can chip away at public trust; identifies three categories \\nof bias in AI – systemic, statistical, and human – and describes how and where they contribute to harms; and \\ndescribes three broad challenges for mitigating bias – datasets, testing and evaluation, and human factors – and \\nintroduces preliminary guidance for addressing them. Throughout, the special publication takes a socio-\\ntechnical perspective to identifying and managing AI bias. \\n29\\nAlgorithmic \\nDiscrimination \\nProtections \\nYou should be protected from abusive data practices via built-in \\nprotections and you should have agency over how data about \\nyou is used. You should be protected from violations of privacy through \\ndesign choices that ensure such protections are included by default, including \\nensuring that data collection conforms to reasonable expectations and that \\nonly data strictly necessary for the specific context is collected. Designers, de\\xad\\nvelopers, and deployers of automated systems should seek your permission \\nand respect your decisions regarding collection, use, access, transfer, and de\\xad\\nletion of your data in appropriate ways and to the greatest extent possible; \\nwhere not possible, alternative privacy by design safeguards should be used. \\nSystems should not employ user experience and design decisions that obfus\\xad\\ncate user choice or burden users with defaults that are privacy invasive. Con\\xad\\nsent should only be used to justify collection of data in cases where it can be \\nappropriately and meaningfully given. Any consent requests should be brief, \\nbe understandable in plain language, and give you agency over data collection \\nand the specific context of use; current hard-to-understand no\\xad\\ntice-and-choice practices for broad uses of data should be changed. Enhanced \\nprotections and restrictions for data and inferences related to sensitive do\\xad\\nmains, including health, work, education, criminal justice, and finance, and \\nfor data pertaining to youth should put you first. In sensitive domains, your \\ndata and related inferences should only be used for necessary functions, and \\nyou should be protected by ethical review and use prohibitions. You and your \\ncommunities should be free from unchecked surveillance; surveillance tech\\xad\\nnologies should be subject to heightened oversight that includes at least \\npre-deployment assessment of their potential harms and scope limits to pro\\xad\\ntect privacy and civil liberties. Continuous surveillance and monitoring \\nshould not be used in education, work, housing, or in other contexts where the \\nuse of such surveillance technologies is likely to limit rights, opportunities, or \\naccess. Whenever possible, you should have access to reporting that confirms \\nyour data decisions have been respected and provides an assessment of the \\npotential impact of surveillance technologies on your rights, opportunities, or \\naccess. \\nDATA PRIVACY\\n30\\n \\n \\n  \\n \\n \\n \\nDATA PRIVACY \\nWHY THIS PRINCIPLE IS IMPORTANT\\nThis section provides a brief summary of the problems which the principle seeks to address and protect \\nagainst, including illustrative examples. \\nData privacy is a foundational and cross-cutting principle required for achieving all others in this framework. Surveil\\xad\\nlance and data collection, sharing, use, and reuse now sit at the foundation of business models across many industries, \\nwith more and more companies tracking the behavior of the American public, building individual profiles based on',\n",
       "  \"this data, and using this granular-level information as input into automated systems that further track, profile, and \\nimpact the American public. Government agencies, particularly law enforcement agencies, also use and help develop \\na variety of technologies that enhance and expand surveillance capabilities, which similarly collect data used as input \\ninto other automated systems that directly impact people’s lives. Federal law has not grown to address the expanding \\nscale of private data collection, or of the ability of governments at all levels to access that data and leverage the means \\nof private collection.  \\nMeanwhile, members of the American public are often unable to access their personal data or make critical decisions \\nabout its collection and use. Data brokers frequently collect consumer data from numerous sources without \\nconsumers’ permission or knowledge.60 Moreover, there is a risk that inaccurate and faulty data can be used to \\nmake decisions about their lives, such as whether they will qualify for a loan or get a job. Use of surveillance \\ntechnologies has increased in schools and workplaces, and, when coupled with consequential management and \\nevaluation decisions, it is leading to mental health harms such as lowered self-confidence, anxiety, depression, and \\na reduced ability to use analytical reasoning.61 Documented patterns show that personal data is being aggregated by \\ndata brokers to profile communities in harmful ways.62 The impact of all this data harvesting is corrosive, \\nbreeding distrust, anxiety, and other mental health problems; chilling speech, protest, and worker organizing; and \\nthreatening our democratic process.63 The American public should be protected from these growing risks. \\nIncreasingly, some companies are taking these concerns seriously and integrating mechanisms to protect consumer \\nprivacy into their products by design and by default, including by minimizing the data they collect, communicating \\ncollection and use clearly, and improving security practices. Federal government surveillance and other collection and \\nuse of data is governed by legal protections that help to protect civil liberties and provide for limits on data retention \\nin some cases. Many states have also enacted consumer data privacy protection regimes to address some of these \\nharms. \\nHowever, these are not yet standard practices, and the United States lacks a comprehensive statutory or regulatory \\nframework governing the rights of the public when it comes to personal data. While a patchwork of laws exists to \\nguide the collection and use of personal data in specific contexts, including health, employment, education, and credit, \\nit can be unclear how these laws apply in other contexts and in an increasingly automated society. Additional protec\\xad\\ntions would assure the American public that the automated systems they use are not monitoring their activities, \\ncollecting information on their lives, or otherwise surveilling them without context-specific consent or legal authori\\xad\\nty. \\n31\\n \\n \\n  \\n \\nDATA PRIVACY \\nWHY THIS PRINCIPLE IS IMPORTANT\\nThis section provides a brief summary of the problems which the principle seeks to address and protect \\nagainst, including illustrative examples. \\n•\\nAn insurer might collect data from a person's social media presence as part of deciding what life\\ninsurance rates they should be offered.64\\n•\\nA data broker harvested large amounts of personal data and then suffered a breach, exposing hundreds of\\nthousands of people to potential identity theft. 65\\n•\\nA local public housing authority installed a facial recognition system at the entrance to housing complexes to\\nassist law enforcement with identifying individuals viewed via camera when police reports are filed, leading\\nthe community, both those living in the housing complex and not, to have videos of them sent to the local\\npolice department and made available for scanning by its facial recognition software.66\\n•\\nCompanies use surveillance software to track employee discussions about union activity and use the\",\n",
       "  'resulting data to surveil individual employees and surreptitiously intervene in discussions.67\\n32\\n \\n \\n \\n \\n \\n \\nDATA PRIVACY \\nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \\ntechnical standards and practices that are tailored for particular sectors and contexts. \\nTraditional terms of service—the block of text that the public is accustomed to clicking through when using a web\\xad\\nsite or digital app—are not an adequate mechanism for protecting privacy. The American public should be protect\\xad\\ned via built-in privacy protections, data minimization, use and collection limitations, and transparency, in addition \\nto being entitled to clear mechanisms to control access to and use of their data—including their metadata—in a \\nproactive, informed, and ongoing way. Any automated system collecting, using, sharing, or storing personal data \\nshould meet these expectations. \\nProtect privacy by design and by default \\nPrivacy by design and by default. Automated systems should be designed and built with privacy protect\\xad\\ned by default. Privacy risks should be assessed throughout the development life cycle, including privacy risks \\nfrom reidentification, and appropriate technical and policy mitigation measures should be implemented. This \\nincludes potential harms to those who are not users of the automated system, but who may be harmed by \\ninferred data, purposeful privacy violations, or community surveillance or other community harms. Data \\ncollection should be minimized and clearly communicated to the people whose data is collected. Data should \\nonly be collected or used for the purposes of training or testing machine learning models if such collection and \\nuse is legal and consistent with the expectations of the people whose data is collected. User experience \\nresearch should be conducted to confirm that people understand what data is being collected about them and \\nhow it will be used, and that this collection matches their expectations and desires. \\nData collection and use-case scope limits. Data collection should be limited in scope, with specific, \\nnarrow identified goals, to avoid \"mission creep.\"  Anticipated data collection should be determined to be \\nstrictly necessary to the identified goals and should be minimized as much as possible. Data collected based on \\nthese identified goals and for a specific context should not be used in a different context without assessing for \\nnew privacy risks and implementing appropriate mitigation measures, which may include express consent. \\nClear timelines for data retention should be established, with data deleted as soon as possible in accordance \\nwith legal or policy-based limitations. Determined data retention timelines should be documented and justi\\xad\\nfied. \\nRisk identification and mitigation. Entities that collect, use, share, or store sensitive data should \\nattempt to proactively identify harms and seek to manage them so as to avoid, mitigate, and respond appropri\\xad\\nately to identified risks. Appropriate responses include determining not to process data when the privacy risks \\noutweigh the benefits or implementing measures to mitigate acceptable risks. Appropriate responses do not \\ninclude sharing or transferring the privacy risks to users via notice or consent requests where users could not \\nreasonably be expected to understand the risks without further support. \\nPrivacy-preserving security. Entities creating, using, or governing automated systems should follow \\nprivacy and security best practices designed to ensure data and metadata do not leak beyond the specific \\nconsented use case. Best practices could include using privacy-enhancing cryptography or other types of \\nprivacy-enhancing technologies or fine-grained permissions and access control mechanisms, along with \\nconventional system security protocols. \\n33\\n \\n \\n \\n \\n \\n \\nDATA PRIVACY \\nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS'],\n",
       " 'ground_truth': 'Data collection should be minimized and clearly communicated to the people whose data is collected to ensure that the collection and use are legal and consistent with the expectations of the people whose data is collected. User experience research should be conducted to confirm that people understand what data is being collected about them and how it will be used, and that this collection matches their expectations and desires.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "response_dataset = Dataset.from_dict({\n",
    "    \"question\" : test_questions,\n",
    "    \"answer\" : answers,\n",
    "    \"contexts\" : contexts,\n",
    "    \"ground_truth\" : test_groundtruths\n",
    "})\n",
    "\n",
    "response_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1d531c9b434421a586df5f03daf1f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No statements were generated from the answer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'faithfulness': 0.9074, 'answer_relevancy': 0.9634, 'context_recall': 0.9267, 'context_precision': 0.9061}\n"
     ]
    }
   ],
   "source": [
    "results = evaluate(response_dataset, metrics)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb206bf22134ef7847cff7df314b11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No statements were generated from the answer.\n",
      "No statements were generated from the answer.\n"
     ]
    }
   ],
   "source": [
    "## Generate responses with our questions using paged retriever\n",
    "answers = []\n",
    "contexts = []\n",
    "\n",
    "for question in test_questions:\n",
    "  response = retrieval_augmented_qa_chain_paged.invoke({\"question\" : question})\n",
    "  answers.append(response[\"response\"].content)\n",
    "  contexts.append([context.page_content for context in response[\"context\"]])\n",
    "\n",
    "paged_response_dataset = Dataset.from_dict({\n",
    "    \"question\" : test_questions,\n",
    "    \"answer\" : answers,\n",
    "    \"contexts\" : contexts,\n",
    "    \"ground_truth\" : test_groundtruths\n",
    "})\n",
    "\n",
    "paged_results = evaluate(paged_response_dataset, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>paged</th>\n",
       "      <th>chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.873630</td>\n",
       "      <td>0.907450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_relevancy</td>\n",
       "      <td>0.944051</td>\n",
       "      <td>0.963378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context_recall</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.926667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>context_precision</td>\n",
       "      <td>0.905000</td>\n",
       "      <td>0.906111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric     paged    chunks\n",
       "0       faithfulness  0.873630  0.907450\n",
       "1   answer_relevancy  0.944051  0.963378\n",
       "2     context_recall  0.850000  0.926667\n",
       "3  context_precision  0.905000  0.906111"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunked = pd.DataFrame(list(results.items()), columns=['Metric', 'chunks'])\n",
    "df_paged = pd.DataFrame(list(paged_results.items()), columns=['Metric', 'paged'])\n",
    "# df_comparison = pd.DataFrame(list(te3_advanced_retrieval_results.items()), columns=['Metric', 'TE3'])\n",
    "\n",
    "df_merged = pd.merge(df_paged, df_chunked, on='Metric')\n",
    "\n",
    "# df_merged['Baseline -> TE3'] = df_merged['TE3'] - df_merged['ADA']\n",
    "\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 Deliverables:\n",
    "1.  Assess my pipeline using the RAGAS framework including key metrics faithfulness, answer relevancy, context precision, and context recall.  Provide a table of my output results.<br>\n",
    "\n",
    "I did the evaluation of my prototype model which was based on the PDF documents being divided by pages, but while I was here, I compared this with the other strategy, which was to recombine all the text and then split by chunks with overlap.\n",
    "\n",
    "<div>\n",
    "<style scoped>\n",
    "    .dataframe tbody tr th:only-of-type {\n",
    "        vertical-align: middle;\n",
    "    }\n",
    "\n",
    "    .dataframe tbody tr th {\n",
    "        vertical-align: top;\n",
    "    }\n",
    "\n",
    "    .dataframe thead th {\n",
    "        text-align: right;\n",
    "    }\n",
    "</style>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>Metric</th>\n",
    "      <th>paged</th>\n",
    "      <th>chunks</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>faithfulness</td>\n",
    "      <td>0.873630</td>\n",
    "      <td>0.907450</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>answer_relevancy</td>\n",
    "      <td>0.944051</td>\n",
    "      <td>0.963378</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>context_recall</td>\n",
    "      <td>0.850000</td>\n",
    "      <td>0.926667</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>3</th>\n",
    "      <td>context_precision</td>\n",
    "      <td>0.905000</td>\n",
    "      <td>0.906111</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "</div>\n",
    "\n",
    "It is obvious that the paged approach, using the default for the PDF loader, is INFERIOR and I should alter my app to use the chunking strategy.  In Task 5, I will compare the fine tuned embedding model with the OpenAI embedding model, but with the chunking strategy in both instances.  There is no point in re-studying the paged strategy.\n",
    "\n",
    "2.  What conclusions can I draw about performance and effectiveness of my pipeline with this information? <br>\n",
    "\n",
    "First, the comparison of chunking strategies is clearcut - dividing PDF documents by pages and embedding those pages is very inferior to combining all the PDF text into one document and then splitting that with chunk overlap.\n",
    "\n",
    "- Faithfulness: Measures whether all claims or statements in the answer can be completely inferred from the context that was provided.  The value is the percentage of claims that can be inferred over the total number of claims.  This metric is improved with a chunking overlap strategy.\n",
    "- Answer relevancy: Measures whether the answer is relevant to the question. It does not matter if the answer is actually correct - only that it directly answers the question without redundancy. This metric was not affected by the chunking strategy.\n",
    "- Context recall: This measures whether the facts that are in the ground truth reference answer can be inferred from the context that was provided to the LLM.  In a perfect situation, every statement in the ground truth should be able to be linked to the context.  This metric was improved with the chunking overlap strategy.\n",
    "- Context precision: This measures whether all the elements in the ground truth are in the highest ranked parts of the context.  This metric was not affected by the chunking strategy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4.  Fine-Tuning Open-Source Embeddings\n",
    "(Role: Machine Learning Engineer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I performed the training in a different notebook because I needed to run in Colab.\n",
    "### The notebook is in this GitHub repository and is called FineTuneEmbed.ipynb \n",
    "### The model was then placed in Hugging Face and the link is provided as part of the deliverable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 Deliverables:\n",
    "1.  Swap out my existing embedding model for the new fine tuned version.  Provide a link to m fine-tuned embedding model on the Hugging Face Hub.<br>\n",
    "\n",
    "2.  How did I choose the embedding model for this application?<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5.  Assessing Performance\n",
    "(Role: AI Evaluation and Performance Engineer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 Deliverables:\n",
    "1.  Test the fine-tuned embedding model using the RAGAS frameworks to quantify any improvements.  Provide results in a table.<br>\n",
    "\n",
    "2.  Test the two chunking strategies using the RAGAS frameworks to quantify any improvements.  Provide results in a table.<br>\n",
    "\n",
    "3.  The AI Solutions Engineer asks me \"Which one is the best to test with internal stakeholders next week, and why?<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6.  Managing Your Boss and User Expectations\n",
    "(Role: SVP of Technology)\n",
    "\n",
    "## Task 6 Deliverables:\n",
    "1.  What is the story that I will give to the CEO to tell the whole company at the launch next month?<br>\n",
    "\n",
    "2.  There appears to be important information not included in our build.  How might we incorporate relevant white-house briefing information in future versions? <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIE4a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

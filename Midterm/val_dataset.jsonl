{"questions": {"f4469d7b-76af-4198-8251-51b9cf1f4db6": "What are the key components that should be included in incident response plans for third-party GAI technologies?", "0f553460-0139-4fbc-a1f0-927fe821dadc": "How can organizations improve their incident response plans for GAI systems based on retrospective learning?", "8d1be6cc-13d8-49e9-845f-90fb19a6e978": "What policies and procedures should be established to manage risks related to rollover and fallback technologies for GAI systems?", "ac42a1f0-d1cf-4f64-ad79-76fb3a6f549a": "What considerations should be taken into account when reviewing vendor contracts for critical GAI technologies?", "c2fb43d9-4053-41ac-8d68-0d79ac5388d6": "What factors should be considered when identifying the intended purposes of an AI system according to MAP 11?", "7715eaa8-da8c-4e25-896c-c746832a1622": "How can collaboration with socio-cultural and domain experts enhance the documentation of a GAI system's context of use?", "d7951f67-f349-4da8-890d-eb3244897e6b": "What are some examples of cognitive biases that could affect AI Actors in the design and implementation of GAI systems?", "95d2342f-c3a3-47c4-9c20-2af2036e014a": "How can organizations document and address foreseeable illegal uses of GAI systems that exceed their risk tolerances?", "2136fdde-e9d6-4012-a9c0-0f36bb21098c": "What are the potential illegal uses of the GAI system that exceed organizational risk tolerances?", "5b46dbd1-a98c-45fc-b0ed-8bb47cda9452": "How can interdisciplinary teams contribute to risk measurement and management functions in the context of GAI deployment?", "18101f93-26e5-4184-86ab-20fd67306098": "What measures should be taken to ensure that the data or benchmarks used in risk measurement are representative of diverse user populations in structured GAI public feedback exercises?", "87be6444-6be3-4e57-895a-095c575bd9ed": "How should the AI system document its knowledge limits and the oversight of its output by humans to assist relevant AI Actors in decision-making?", "0b57e0f2-ef29-45c5-aa95-7bf32b6b1060": "What is the purpose of documenting how the system relies on upstream data sources in the context of GAI risks?", "8f672c26-a63e-4631-8655-54113bb55a63": "How can the accuracy and reliability of GAI output be assessed according to the suggested actions?", "67442dee-b6a9-432c-bce7-cb9153274817": "What evaluation methods are suggested for ensuring information integrity in AI systems?", "0ed6171e-2fe8-4371-b4ca-99945d9be04b": "What techniques should be deployed to verify the accuracy of information generated by GAI systems?", "79311850-4ed3-483c-bd54-80550107e3ca": "What processes are defined, assessed, and documented for operator and practitioner proficiency with AI system performance and trustworthiness?", "1296f809-d24f-4390-813f-c6eb9aba0177": "How can existing training programs be adapted to enhance digital content transparency?", "a54f99a4-6bfd-4da8-837b-e09410c259da": "What are the key components involved in the Human-AI Configuration for ensuring information integrity?", "66500dc0-828d-419e-8f78-c6dc91ad151a": "How should end-users and practitioners be involved in the testing activities of GAI systems?", "a6d9b073-6ca4-4f16-8370-5b6098ba8647": "What processes should be implemented to respond to potential intellectual property infringement claims according to the context provided?", "026f5931-b3b9-4f75-9c30-73d51467ba07": "How should new GAI policies be connected to existing governance and compliance activities?", "fdecf9c0-2063-429d-873b-27e10422c39a": "What policies and practices should be implemented to define the use, storage, and protection of third-party intellectual property and training data?", "85900739-0755-41ff-bfc4-6a82ba3c154e": "How can organizations re-evaluate risks when adapting Generative AI models to new domains?", "1dc4b88a-33a7-4327-ab7b-899ba0397d3b": "What approaches can be leveraged to detect the presence of PII or sensitive data in generated outputs?", "7c8807c9-04c3-422c-a780-669be84e28d6": "What diligence should be conducted on training data use to assess intellectual property and privacy risks?", "7bd38a73-cc07-4094-acea-9be9813301fa": "What are the potential content provenance harms associated with Generative AI (GAI) as mentioned in the context?", "b5b5f646-dc9c-49c2-9514-2335a994bce4": "How should organizations prioritize public feedback processes related to GAI based on risk assessment estimates?", "03d3abc8-0cd1-43ef-be20-cf674feb9308": "What are the suggested actions to identify new impacts arising from GAI systems according to the context provided?", "7b58eddd-649f-40ce-992f-bf171ce50576": "How can regular engagement with AI Actors contribute to understanding the impacts of GAI systems?", "99dbbf5f-f756-48a6-b897-682b9fd774ee": "What are the key tasks assigned to AI Actors in the context of GAI systems?", "54d094a4-b61f-4c59-9806-ca0376720e95": "How will the selected approaches and metrics for measuring AI risks be prioritized for implementation?", "ae6ccb89-ee66-41c1-b62c-40800679451f": "What tools are suggested for analyzing content provenance and detecting data anomalies?", "cde8bcd2-e8a7-4b5a-b862-956e6f1184f6": "How can evaluation metrics be disaggregated to identify discrepancies in content provenance mechanisms across diverse populations?", "78153c37-9ad2-4122-a121-e4ae1819aa78": "What methods are suggested for obtaining feedback from affected communities regarding GAI outputs?", "1bf189fa-0133-4478-b52d-b58d1f2d9a2d": "How should organizations evaluate the quality and integrity of data used in training GAI systems?", "559dcb85-711f-4979-b59a-0c8fd7c4a391": "What are some reasons why certain risks cannot be measured in the context of AI development?", "07d7c5e3-cf9f-4c31-b26f-7f550d1d3958": "How do internal experts and independent assessors contribute to the assessment and update processes of AI systems?", "4f1820e3-7ac6-4a7b-937a-78d35c623158": "What are the key components involved in conducting structured human feedback exercises for GAI models?", "9ebe71e5-1863-487a-b99b-44eac24f6888": "How can statistical biases related to GAI content provenance be assessed and managed?", "5cccc299-9102-4cd9-b27a-8db684ecf8db": "What techniques can be used to minimize the risks associated with linking AI-generated content back to individual human subjects?", "532a027e-d0ef-4f96-991f-6684a0b3ca4a": "How should content provenance data be tracked to ensure it interacts effectively with privacy and security measures?", "5dfdfb5f-6ade-4b1a-9dda-bb2eb0a568e0": "What are the suggested actions for evaluating AI system performance or assurance criteria before deployment?", "258df7db-9286-4b4a-84b6-0bd9ef886373": "How should claims of model capabilities be evaluated according to the provided context?", "25edfd1a-0349-4a28-b098-078a23c524bd": "What measures are suggested to avoid extrapolating GAI system performance from anecdotal assessments?", "0b1b0416-770f-4c3c-8e0f-d8051cc2c6d1": "How can human domain knowledge be utilized to enhance GAI system performance according to the suggested actions?", "fc93045c-dc73-472f-a01a-527c8f11d660": "What activities are involved in the ongoing monitoring of deployment risk measurement for GAI systems?", "a715ee2a-d9d5-4457-9644-fe620d4e2744": "How should instances of anthropomorphization in GAI system interfaces be tracked and documented?", "117df148-de42-4d69-be25-315f80e964c4": "What are the suggested actions to assess adverse impacts on AI actors exposed to harmful content during GAI training and maintenance?", "7f2169bd-4e36-4c86-8fcf-7ea44be9ad5b": "How should organizations respond when the negative risk of fine-tuned models exceeds their risk tolerance?", "cd8dacaa-caeb-406c-8cca-d81e00e19198": "What steps should be taken to re-evaluate the safety features of fine-tuned models when negative risks exceed organizational risk tolerance?", "0562dd13-fb89-455f-b3a3-32db038ac662": "How can GAI systems be designed to monitor outputs and recover from errors related to security anomalies?", "dc1c7d18-dfc9-46ec-b6f6-59534dd3ca41": "What are the suggested actions to assess vulnerabilities and threats in AI system security as outlined in Measure 27?", "45a27461-ec61-4cbe-9d04-76c3089f0b70": "How can user surveys contribute to understanding user satisfaction and perceptions of AI-generated content according to the provided context?", "01b7bc19-a1ad-4aef-9ffe-956eabcefbf8": "What methods are suggested for gathering user satisfaction and perceptions regarding AI-generated content authenticity?", "709f2c0a-6d07-4bb4-a591-afdcbe08d56e": "What metrics should be identified to evaluate the effectiveness of security measures related to data provenance and unauthorized access attempts?", "c5818cbd-a8b7-4d04-948c-6fa5204b2bd2": "What is the purpose of measuring the rate at which recommendations from security checks and incidents are implemented in the context of AI systems?", "47e56de5-bca4-4f13-afa5-0ab04d163870": "How does AI red-teaming contribute to assessing resilience against various types of attacks, such as malicious code generation and prompt injection?", "c943cd3f-aecb-4ae3-816e-70727c3e2f63": "What are the suggested actions for addressing risks associated with transparency and accountability in GAI systems?", "8c99438a-ece1-4608-be0f-f9da32d7b6c2": "How can digital content transparency solutions contribute to the documentation and traceability of content generated by AI systems?", "9e9462f4-c8d5-4778-a6de-13a977b48bde": "What are the suggested actions for documenting GAI model details according to MEASURE 29?", "cde32928-399f-4663-ac24-2f53dca6d4fe": "How does user testing contribute to verifying the adequacy of GAI system user instructions?", "65e67fdb-b172-4807-b710-ea36844c609e": "What are the key risks associated with the privacy of AI systems as identified in the MAP function?", "8577e523-2182-4e2e-92f8-806f01023268": "How can engaging with end-users and stakeholders improve the design of provenance data-tracking techniques in AI systems?", "2bd46e54-00c0-48f5-9d84-040ce78d5d43": "What techniques are suggested for tracking the provenance of content in AI systems?", "9355d54c-9e3d-49a4-be91-2d3c32f0743e": "How should fairness and bias be evaluated in the context of GAI system outputs?", "1b0db340-8238-4691-bfea-d9b991e691f5": "What methods are suggested for conducting fairness assessments to measure systemic bias in GAI systems?", "e9dcccb0-6697-4816-8d44-fd2fd73d5825": "How can harmful bias in generated content be quantified according to the provided context?", "1e562c08-2066-4bd5-aba9-eeb58f3524f2": "What are the potential impacts of GAI systems on individuals, groups, or environmental ecosystems as identified in the context?", "59306a77-0a49-4fc6-9417-212544ebd3dd": "What factors should be reviewed and documented to measure sources of bias in GAI training and TEVV data?", "bedd160c-58c0-434f-8117-350fa567d328": "What is the purpose of the 15 Winogender Schemas in evaluating gender bias in natural language processing systems?", "997192ab-a8bd-42df-809f-42122df342fd": "How can the assessment of synthetic versus non-synthetic training data help mitigate concerns of model collapse in GAI systems?", "6c0dcbcc-d707-412f-89e9-f0fb575ae387": "What are the anticipated environmental impacts that should be documented during model development, maintenance, and deployment in product design decisions?", "67e5bd15-51ef-48bc-8d5f-452ce723c720": "How can the effectiveness of carbon capture or offset programs for GAI training and applications be verified?", "4b66305d-088e-4c8e-9e17-0c0706150e22": "What are the key components involved in creating measurement error models for pre-deployment metrics to ensure construct validity?", "491080da-ecd7-42ea-a4b1-5706c75de307": "How can feedback processes for end users and impacted communities be integrated into AI system evaluation metrics?", "9c137e6d-d012-4f7a-b251-afd4eb627031": "What are the suggested actions for evaluating the impact of AI-generated content on different social, economic, and cultural groups?", "30b47b2c-38d3-4566-8ea2-6a07a732b0d2": "How can potential biases and stereotypes in AI-generated content be evaluated according to the provided context?", "b7bf5d4b-d730-4b02-8ec2-3e0142007d2d": "What methods are suggested for recording and integrating structured feedback about content provenance from various stakeholders?", "bbe492f0-c247-4d23-8a02-6e7cdbd48bc9": "How can the trustworthiness of an AI system be measured and validated according to the provided context?", "2f37a350-87c4-4686-bb95-7d226ff8626c": "What methods should be implemented to evaluate the decisions made by GAI systems for interpretability and explainability?", "b5bbb7f6-4ed2-469d-afb3-f24b8cf72259": "How can instances of human operators overriding GAI decisions be monitored and documented to assess their relation to content provenance issues?", "fcc7e3c1-753f-4ad0-8054-1aa2b0c9f7f1": "What are the suggested actions for managing AI risks that do not surpass organizational risk tolerance?", "c3884587-5bcd-4627-9235-cb2f42ccf698": "How should organizations respond to AI risks that are deemed high priority according to the MAP function?", "da1b7c13-f892-4eee-a67b-3c94c4674167": "What mechanisms are suggested to sustain the value of deployed AI systems according to the context provided?", "fdacbd5c-4c1c-4fad-b623-63aaa18fa7e7": "How should organizations assess the outputs of GAI systems in relation to their risk tolerance and guidelines?", "88d3635b-f7e0-428f-a153-263bd4cff3bb": "What techniques can be employed to mitigate representational biases in GAI-generated content?", "f387cbc2-4ba0-41b8-8849-1c82e4eff5cd": "How can real-time monitoring systems ensure the effectiveness of content provenance protocols in GAI systems?", "e3da6fad-2552-4b15-8763-fa8a05b39032": "What are the suggested actions for managing previously unknown risks associated with AI-generated content?", "b0ccc711-5487-4571-9b34-c3ad1ac2c944": "How can structured feedback mechanisms be utilized to assess the quality of AI-generated content in relation to community values?", "5b87936d-89dc-499c-8c4d-87f4caed5f23": "What are the key components that need to be included in the GAI system incident response and recovery plans according to the suggested action MG-23-001?", "3779b9f0-b251-4404-9164-7f1cc624ffcf": "What responsibilities must be assigned and understood to effectively manage the deactivation or disengagement of AI systems as outlined in action MG-24-001?", "dd2c80b1-5c03-4fbc-a42f-59f6441113fd": "What procedures should be established for escalating GAI system incidents to the organizational risk management authority?", "8fb192e0-d76d-4b62-8e69-16c550338fa1": "How often should the specific criteria for deactivating GAI systems be reviewed in relation to risk tolerances?", "ee7da1b7-a262-4532-b551-af3ebfe4d48b": "What are the suggested actions for applying organizational risk tolerances to third-party GAI resources?", "b2ccb4c0-5daf-4b38-a3d9-1c3afc621f71": "What types of risks should be tested in the GAI system value chain?", "1204b98e-0d57-4528-9562-71e326797357": "What measures should be taken to review training data for CBRN information and intellectual property in the context of AI model deployment?", "7d6eb82f-b981-4bec-ba35-54ab0c042202": "Why is it important to reassess model risks after fine-tuning or implementing retrieval-augmented generation for third-party GAI models?", "74d5b4cc-a08e-4b95-abc8-2ad76d361d44": "What techniques are suggested to mitigate risks related to unexplainable GAI systems as part of ongoing continuous improvement processes?", "ec46d3a2-9977-4724-be21-d1f80c4ae1a0": "Why is it important to document the sources and types of training data used for GAI applications?"}, "relevant_contexts": {"f4469d7b-76af-4198-8251-51b9cf1f4db6": ["03822d0a-4951-4c66-94fd-f5380912476b"], "0f553460-0139-4fbc-a1f0-927fe821dadc": ["03822d0a-4951-4c66-94fd-f5380912476b"], "8d1be6cc-13d8-49e9-845f-90fb19a6e978": ["8904cff7-a117-4ed1-8e92-2fd6ea79be3d"], "ac42a1f0-d1cf-4f64-ad79-76fb3a6f549a": ["8904cff7-a117-4ed1-8e92-2fd6ea79be3d"], "c2fb43d9-4053-41ac-8d68-0d79ac5388d6": ["747f4826-61b7-4d1e-8875-d01b5ea2d72b"], "7715eaa8-da8c-4e25-896c-c746832a1622": ["747f4826-61b7-4d1e-8875-d01b5ea2d72b"], "d7951f67-f349-4da8-890d-eb3244897e6b": ["16c4d55b-ce76-4013-ac80-ba2585c5759d"], "95d2342f-c3a3-47c4-9c20-2af2036e014a": ["16c4d55b-ce76-4013-ac80-ba2585c5759d"], "2136fdde-e9d6-4012-a9c0-0f36bb21098c": ["181a3d4d-1bb7-4df9-93af-21a385e4ad40"], "5b46dbd1-a98c-45fc-b0ed-8bb47cda9452": ["181a3d4d-1bb7-4df9-93af-21a385e4ad40"], "18101f93-26e5-4184-86ab-20fd67306098": ["0d0a8d7c-692f-4ba0-9663-f8e82596d335"], "87be6444-6be3-4e57-895a-095c575bd9ed": ["0d0a8d7c-692f-4ba0-9663-f8e82596d335"], "0b57e0f2-ef29-45c5-aa95-7bf32b6b1060": ["cc03e58a-ee22-4833-aaa0-35c0a2c26298"], "8f672c26-a63e-4631-8655-54113bb55a63": ["cc03e58a-ee22-4833-aaa0-35c0a2c26298"], "67442dee-b6a9-432c-bce7-cb9153274817": ["e4256c75-40b3-46ee-9aff-c7333fe39c60"], "0ed6171e-2fe8-4371-b4ca-99945d9be04b": ["e4256c75-40b3-46ee-9aff-c7333fe39c60"], "79311850-4ed3-483c-bd54-80550107e3ca": ["1663e39e-a293-45f7-9131-c1e1415ff593"], "1296f809-d24f-4390-813f-c6eb9aba0177": ["1663e39e-a293-45f7-9131-c1e1415ff593"], "a54f99a4-6bfd-4da8-837b-e09410c259da": ["fa81f7ce-b5f1-4d33-96fc-358c1e068171"], "66500dc0-828d-419e-8f78-c6dc91ad151a": ["fa81f7ce-b5f1-4d33-96fc-358c1e068171"], "a6d9b073-6ca4-4f16-8370-5b6098ba8647": ["b4085853-b4ac-4d75-bdc9-d475575909ee"], "026f5931-b3b9-4f75-9c30-73d51467ba07": ["b4085853-b4ac-4d75-bdc9-d475575909ee"], "fdecf9c0-2063-429d-873b-27e10422c39a": ["b76cf60f-25bd-46f9-8cc6-c35bdf385d1d"], "85900739-0755-41ff-bfc4-6a82ba3c154e": ["b76cf60f-25bd-46f9-8cc6-c35bdf385d1d"], "1dc4b88a-33a7-4327-ab7b-899ba0397d3b": ["70213cdb-7da6-4b70-a02d-33ac02a95dde"], "7c8807c9-04c3-422c-a780-669be84e28d6": ["70213cdb-7da6-4b70-a02d-33ac02a95dde"], "7bd38a73-cc07-4094-acea-9be9813301fa": ["9a98ad01-ac87-4c76-83d9-73c155f2f7fc"], "b5b5f646-dc9c-49c2-9514-2335a994bce4": ["9a98ad01-ac87-4c76-83d9-73c155f2f7fc"], "03d3abc8-0cd1-43ef-be20-cf674feb9308": ["7572dd6d-e051-4661-a2a6-7888b3e3904d"], "7b58eddd-649f-40ce-992f-bf171ce50576": ["7572dd6d-e051-4661-a2a6-7888b3e3904d"], "99dbbf5f-f756-48a6-b897-682b9fd774ee": ["5f24d9f0-6c5e-4394-b02a-dd4a52b7c16a"], "54d094a4-b61f-4c59-9806-ca0376720e95": ["5f24d9f0-6c5e-4394-b02a-dd4a52b7c16a"], "ae6ccb89-ee66-41c1-b62c-40800679451f": ["1eaaa314-9087-4a30-85c0-c13375929114"], "cde8bcd2-e8a7-4b5a-b862-956e6f1184f6": ["1eaaa314-9087-4a30-85c0-c13375929114"], "78153c37-9ad2-4122-a121-e4ae1819aa78": ["39759a5c-863f-40f9-98e2-966ed1192962"], "1bf189fa-0133-4478-b52d-b58d1f2d9a2d": ["39759a5c-863f-40f9-98e2-966ed1192962"], "559dcb85-711f-4979-b59a-0c8fd7c4a391": ["945bfdb5-ee2a-4fba-909a-2cdfa6e2588c"], "07d7c5e3-cf9f-4c31-b26f-7f550d1d3958": ["945bfdb5-ee2a-4fba-909a-2cdfa6e2588c"], "4f1820e3-7ac6-4a7b-937a-78d35c623158": ["25fc735c-9c6e-42fb-b9f0-96b38e2f870a"], "9ebe71e5-1863-487a-b99b-44eac24f6888": ["25fc735c-9c6e-42fb-b9f0-96b38e2f870a"], "5cccc299-9102-4cd9-b27a-8db684ecf8db": ["205dea73-ed26-48c5-9015-eb510c01f6d3"], "532a027e-d0ef-4f96-991f-6684a0b3ca4a": ["205dea73-ed26-48c5-9015-eb510c01f6d3"], "5dfdfb5f-6ade-4b1a-9dda-bb2eb0a568e0": ["8bf95b3c-c982-4f6d-917d-bd81926c6dfa"], "258df7db-9286-4b4a-84b6-0bd9ef886373": ["8bf95b3c-c982-4f6d-917d-bd81926c6dfa"], "25edfd1a-0349-4a28-b098-078a23c524bd": ["7ae789f9-d997-4ec3-8fec-c87e57ecf388"], "0b1b0416-770f-4c3c-8e0f-d8051cc2c6d1": ["7ae789f9-d997-4ec3-8fec-c87e57ecf388"], "fc93045c-dc73-472f-a01a-527c8f11d660": ["b6c7f323-4fb4-4025-8e41-89302b854e95"], "a715ee2a-d9d5-4457-9644-fe620d4e2744": ["b6c7f323-4fb4-4025-8e41-89302b854e95"], "117df148-de42-4d69-be25-315f80e964c4": ["702bf9e2-5a61-4b35-ac69-a47f1f5df65e"], "7f2169bd-4e36-4c86-8fcf-7ea44be9ad5b": ["702bf9e2-5a61-4b35-ac69-a47f1f5df65e"], "cd8dacaa-caeb-406c-8cca-d81e00e19198": ["0256b509-db06-4566-87f8-0529c46fb1ef"], "0562dd13-fb89-455f-b3a3-32db038ac662": ["0256b509-db06-4566-87f8-0529c46fb1ef"], "dc1c7d18-dfc9-46ec-b6f6-59534dd3ca41": ["cd6f6eee-3b8d-4fc2-84a0-c61655178693"], "45a27461-ec61-4cbe-9d04-76c3089f0b70": ["cd6f6eee-3b8d-4fc2-84a0-c61655178693"], "01b7bc19-a1ad-4aef-9ffe-956eabcefbf8": ["a828c67a-4327-46c7-8e0b-539eceb3673a"], "709f2c0a-6d07-4bb4-a591-afdcbe08d56e": ["a828c67a-4327-46c7-8e0b-539eceb3673a"], "c5818cbd-a8b7-4d04-948c-6fa5204b2bd2": ["29ccb68a-46e3-4ba4-b4a7-846ca8e1867f"], "47e56de5-bca4-4f13-afa5-0ab04d163870": ["29ccb68a-46e3-4ba4-b4a7-846ca8e1867f"], "c943cd3f-aecb-4ae3-816e-70727c3e2f63": ["ff06f72b-df9d-4262-946d-2ea18d393dfc"], "8c99438a-ece1-4608-be0f-f9da32d7b6c2": ["ff06f72b-df9d-4262-946d-2ea18d393dfc"], "9e9462f4-c8d5-4778-a6de-13a977b48bde": ["177c430b-f39f-4565-99fb-0abb632ca5ff"], "cde32928-399f-4663-ac24-2f53dca6d4fe": ["177c430b-f39f-4565-99fb-0abb632ca5ff"], "65e67fdb-b172-4807-b710-ea36844c609e": ["22c62035-ea5b-441a-986a-30d668f4f799"], "8577e523-2182-4e2e-92f8-806f01023268": ["22c62035-ea5b-441a-986a-30d668f4f799"], "2bd46e54-00c0-48f5-9d84-040ce78d5d43": ["4836a55f-e98b-4a61-b7b4-05b24af2c03a"], "9355d54c-9e3d-49a4-be91-2d3c32f0743e": ["4836a55f-e98b-4a61-b7b4-05b24af2c03a"], "1b0db340-8238-4691-bfea-d9b991e691f5": ["d15bc099-4358-4e09-ac5b-6e87adcddf4d"], "e9dcccb0-6697-4816-8d44-fd2fd73d5825": ["d15bc099-4358-4e09-ac5b-6e87adcddf4d"], "1e562c08-2066-4bd5-aba9-eeb58f3524f2": ["a7d00e81-14ce-4716-bf91-d6c2d2378929"], "59306a77-0a49-4fc6-9417-212544ebd3dd": ["a7d00e81-14ce-4716-bf91-d6c2d2378929"], "bedd160c-58c0-434f-8117-350fa567d328": ["9b0b5bd5-8d27-474d-aafe-f095373a45f7"], "997192ab-a8bd-42df-809f-42122df342fd": ["9b0b5bd5-8d27-474d-aafe-f095373a45f7"], "6c0dcbcc-d707-412f-89e9-f0fb575ae387": ["16defe61-b3e5-4f34-85e9-b6c749bfb470"], "67e5bd15-51ef-48bc-8d5f-452ce723c720": ["16defe61-b3e5-4f34-85e9-b6c749bfb470"], "4b66305d-088e-4c8e-9e17-0c0706150e22": ["720b30ed-0dfa-4c90-a916-6fcef31d5dce"], "491080da-ecd7-42ea-a4b1-5706c75de307": ["720b30ed-0dfa-4c90-a916-6fcef31d5dce"], "9c137e6d-d012-4f7a-b251-afd4eb627031": ["80ec2305-adb9-48c5-88c5-75ba66820dc4"], "30b47b2c-38d3-4566-8ea2-6a07a732b0d2": ["80ec2305-adb9-48c5-88c5-75ba66820dc4"], "b7bf5d4b-d730-4b02-8ec2-3e0142007d2d": ["d0c09539-ee42-4a23-b66a-aaad083eacbd"], "bbe492f0-c247-4d23-8a02-6e7cdbd48bc9": ["d0c09539-ee42-4a23-b66a-aaad083eacbd"], "2f37a350-87c4-4686-bb95-7d226ff8626c": ["0afb0943-19dc-4ed7-bd77-c6e70d7020df"], "b5bbb7f6-4ed2-469d-afb3-f24b8cf72259": ["0afb0943-19dc-4ed7-bd77-c6e70d7020df"], "fcc7e3c1-753f-4ad0-8054-1aa2b0c9f7f1": ["57cb32a8-0a06-4188-8dec-8e15dd5d5695"], "c3884587-5bcd-4627-9235-cb2f42ccf698": ["57cb32a8-0a06-4188-8dec-8e15dd5d5695"], "da1b7c13-f892-4eee-a67b-3c94c4674167": ["32a0c4fc-758a-43eb-9701-4b8c1fd08056"], "fdacbd5c-4c1c-4fad-b623-63aaa18fa7e7": ["32a0c4fc-758a-43eb-9701-4b8c1fd08056"], "88d3635b-f7e0-428f-a153-263bd4cff3bb": ["978b11c0-2932-4ea8-ba5c-4a6feebf6da7"], "f387cbc2-4ba0-41b8-8849-1c82e4eff5cd": ["978b11c0-2932-4ea8-ba5c-4a6feebf6da7"], "e3da6fad-2552-4b15-8763-fa8a05b39032": ["228a7cdd-c312-4287-ae69-344d5dc127cd"], "b0ccc711-5487-4571-9b34-c3ad1ac2c944": ["228a7cdd-c312-4287-ae69-344d5dc127cd"], "5b87936d-89dc-499c-8c4d-87f4caed5f23": ["9268e97a-4611-4d7f-a75f-b6dbe3ab8135"], "3779b9f0-b251-4404-9164-7f1cc624ffcf": ["9268e97a-4611-4d7f-a75f-b6dbe3ab8135"], "dd2c80b1-5c03-4fbc-a42f-59f6441113fd": ["e967f754-ae96-4fc5-beaf-106a9ce71a96"], "8fb192e0-d76d-4b62-8e69-16c550338fa1": ["e967f754-ae96-4fc5-beaf-106a9ce71a96"], "ee7da1b7-a262-4532-b551-af3ebfe4d48b": ["8bae7b3d-cbda-41d6-872b-cdc29ad1d675"], "b2ccb4c0-5daf-4b38-a3d9-1c3afc621f71": ["8bae7b3d-cbda-41d6-872b-cdc29ad1d675"], "1204b98e-0d57-4528-9562-71e326797357": ["64062c69-9036-4867-94bc-fde28c38718b"], "7d6eb82f-b981-4bec-ba35-54ab0c042202": ["64062c69-9036-4867-94bc-fde28c38718b"], "74d5b4cc-a08e-4b95-abc8-2ad76d361d44": ["09fd6898-a144-4016-9b85-23c37a04a7d9"], "ec46d3a2-9977-4724-be21-d1f80c4ae1a0": ["09fd6898-a144-4016-9b85-23c37a04a7d9"]}, "corpus": {"03822d0a-4951-4c66-94fd-f5380912476b": "Intellectual Property; Value Chain \nand Component Integration \n \n22 \nGV-6.2-003 \nEstablish incident response plans for third-party GAI technologies: Align incident \nresponse plans with impacts enumerated in MAP 5.1; Communicate third-party \nGAI incident response plans to all relevant AI Actors; De\ufb01ne ownership of GAI \nincident response functions; Rehearse third-party GAI incident response plans at \na regular cadence; Improve incident response plans based on retrospective \nlearning; Review incident response plans for alignment with relevant breach \nreporting, data protection, data privacy, or other laws. \nData Privacy; Human-AI \nCon\ufb01guration; Information \nSecurity; Value Chain and \nComponent Integration; Harmful \nBias and Homogenization \nGV-6.2-004 \nEstablish policies and procedures for continuous monitoring of third-party GAI \nsystems in deployment. \nValue Chain and Component \nIntegration \nGV-6.2-005 \nEstablish policies and procedures that address GAI data redundancy, including \nmodel weights and other system artifacts. \nHarmful Bias and Homogenization \nGV-6.2-006 \nEstablish policies and procedures to test and manage risks related to rollover and \nfallback technologies for GAI systems, acknowledging that rollover and fallback", "8904cff7-a117-4ed1-8e92-2fd6ea79be3d": "Harmful Bias and Homogenization \nGV-6.2-006 \nEstablish policies and procedures to test and manage risks related to rollover and \nfallback technologies for GAI systems, acknowledging that rollover and fallback \nmay include manual processing. \nInformation Integrity \nGV-6.2-007 \nReview vendor contracts and avoid arbitrary or capricious termination of critical \nGAI technologies or vendor services and non-standard terms that may amplify or \ndefer liability in unexpected ways and/or contribute to unauthorized data \ncollection by vendors or third-parties (e.g., secondary data use). Consider: Clear \nassignment of liability and responsibility for incidents, GAI system changes over \ntime (e.g., \ufb01ne-tuning, drift, decay); Request: Noti\ufb01cation and disclosure for \nserious incidents arising from third-party data and systems; Service Level \nAgreements (SLAs) in vendor contracts that address incident response, response \ntimes, and availability of critical support. \nHuman-AI Con\ufb01guration; \nInformation Security; Value Chain \nand Component Integration \nAI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV, Third-party entities \n \nMAP 1.1: Intended purposes, potentially bene\ufb01cial uses, context speci\ufb01c laws, norms and expectations, and prospective settings in", "747f4826-61b7-4d1e-8875-d01b5ea2d72b": "MAP 1.1: Intended purposes, potentially bene\ufb01cial uses, context speci\ufb01c laws, norms and expectations, and prospective settings in \nwhich the AI system will be deployed are understood and documented. Considerations include: the speci\ufb01c set or types of users \nalong with their expectations; potential positive and negative impacts of system uses to individuals, communities, organizations, \nsociety, and the planet; assumptions and related limitations about AI system purposes, uses, and risks across the development or \nproduct AI lifecycle; and related TEVV and system metrics. \nAction ID \nSuggested Action \nGAI Risks \nMP-1.1-001 \nWhen identifying intended purposes, consider factors such as internal vs. \nexternal use, narrow vs. broad application scope, \ufb01ne-tuning, and varieties of \ndata sources (e.g., grounding, retrieval-augmented generation). \nData Privacy; Intellectual \nProperty \n \n23 \nMP-1.1-002 \nDetermine and document the expected and acceptable GAI system context of \nuse in collaboration with socio-cultural and other domain experts, by assessing: \nAssumptions and limitations; Direct value to the organization; Intended \noperational environment and observed usage patterns; Potential positive and \nnegative impacts to individuals, public safety, groups, communities,", "16c4d55b-ce76-4013-ac80-ba2585c5759d": "Assumptions and limitations; Direct value to the organization; Intended \noperational environment and observed usage patterns; Potential positive and \nnegative impacts to individuals, public safety, groups, communities, \norganizations, democratic institutions, and the physical environment; Social \nnorms and expectations. \nHarmful Bias and Homogenization \nMP-1.1-003 \nDocument risk measurement plans to address identi\ufb01ed risks. Plans may \ninclude, as applicable: Individual and group cognitive biases (e.g., con\ufb01rmation \nbias, funding bias, groupthink) for AI Actors involved in the design, \nimplementation, and use of GAI systems; Known past GAI system incidents and \nfailure modes; In-context use and foreseeable misuse, abuse, and o\ufb00-label use; \nOver reliance on quantitative metrics and methodologies without su\ufb03cient \nawareness of their limitations in the context(s) of use; Standard measurement \nand structured human feedback approaches; Anticipated human-AI \ncon\ufb01gurations. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization; \nDangerous, Violent, or Hateful \nContent \nMP-1.1-004 \nIdentify and document foreseeable illegal uses or applications of the GAI system \nthat surpass organizational risk tolerances.", "181a3d4d-1bb7-4df9-93af-21a385e4ad40": "Dangerous, Violent, or Hateful \nContent \nMP-1.1-004 \nIdentify and document foreseeable illegal uses or applications of the GAI system \nthat surpass organizational risk tolerances. \nCBRN Information or Capabilities; \nDangerous, Violent, or Hateful \nContent; Obscene, Degrading, \nand/or Abusive Content \nAI Actor Tasks: AI Deployment \n \nMAP 1.2: Interdisciplinary AI Actors, competencies, skills, and capacities for establishing context re\ufb02ect demographic diversity and \nbroad domain and user experience expertise, and their participation is documented. Opportunities for interdisciplinary \ncollaboration are prioritized. \nAction ID \nSuggested Action \nGAI Risks \nMP-1.2-001 \nEstablish and empower interdisciplinary teams that re\ufb02ect a wide range of \ncapabilities, competencies, demographic groups, domain expertise, educational \nbackgrounds, lived experiences, professions, and skills across the enterprise to \ninform and conduct risk measurement and management functions. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization \nMP-1.2-002 \nVerify that data or benchmarks used in risk measurement, and users, \nparticipants, or subjects involved in structured GAI public feedback exercises \nare representative of diverse in-context user populations.", "0d0a8d7c-692f-4ba0-9663-f8e82596d335": "MP-1.2-002 \nVerify that data or benchmarks used in risk measurement, and users, \nparticipants, or subjects involved in structured GAI public feedback exercises \nare representative of diverse in-context user populations. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization \nAI Actor Tasks: AI Deployment \n \n \n24 \nMAP 2.1: The speci\ufb01c tasks and methods used to implement the tasks that the AI system will support are de\ufb01ned (e.g., classi\ufb01ers, \ngenerative models, recommenders). \nAction ID \nSuggested Action \nGAI Risks \nMP-2.1-001 \nEstablish known assumptions and practices for determining data origin and \ncontent lineage, for documentation and evaluation purposes. \nInformation Integrity \nMP-2.1-002 \nInstitute test and evaluation for data and content \ufb02ows within the GAI system, \nincluding but not limited to, original data sources, data transformations, and \ndecision-making criteria. \nIntellectual Property; Data Privacy \nAI Actor Tasks: TEVV \n \nMAP 2.2: Information about the AI system\u2019s knowledge limits and how system output may be utilized and overseen by humans is \ndocumented. Documentation provides su\ufb03cient information to assist relevant AI Actors when making decisions and taking", "cc03e58a-ee22-4833-aaa0-35c0a2c26298": "documented. Documentation provides su\ufb03cient information to assist relevant AI Actors when making decisions and taking \nsubsequent actions. \nAction ID \nSuggested Action \nGAI Risks \nMP-2.2-001 \nIdentify and document how the system relies on upstream data sources, \nincluding for content provenance, and if it serves as an upstream dependency for \nother systems. \nInformation Integrity; Value Chain \nand Component Integration \nMP-2.2-002 \nObserve and analyze how the GAI system interacts with external networks, and \nidentify any potential for negative externalities, particularly where content \nprovenance might be compromised. \nInformation Integrity \nAI Actor Tasks: End Users \n \nMAP 2.3: Scienti\ufb01c integrity and TEVV considerations are identi\ufb01ed and documented, including those related to experimental \ndesign, data collection and selection (e.g., availability, representativeness, suitability), system trustworthiness, and construct \nvalidation \nAction ID \nSuggested Action \nGAI Risks \nMP-2.3-001 \nAssess the accuracy, quality, reliability, and authenticity of GAI output by \ncomparing it to a set of known ground truth data and by using a variety of \nevaluation methods (e.g., human oversight and automated evaluation, proven", "e4256c75-40b3-46ee-9aff-c7333fe39c60": "comparing it to a set of known ground truth data and by using a variety of \nevaluation methods (e.g., human oversight and automated evaluation, proven \ncryptographic techniques, review of content inputs). \nInformation Integrity \n \n25 \nMP-2.3-002 Review and document accuracy, representativeness, relevance, suitability of data \nused at di\ufb00erent stages of AI life cycle. \nHarmful Bias and Homogenization; \nIntellectual Property \nMP-2.3-003 \nDeploy and document fact-checking techniques to verify the accuracy and \nveracity of information generated by GAI systems, especially when the \ninformation comes from multiple (or unknown) sources. \nInformation Integrity  \nMP-2.3-004 Develop and implement testing techniques to identify GAI produced content (e.g., \nsynthetic media) that might be indistinguishable from human-generated content. Information Integrity \nMP-2.3-005 Implement plans for GAI systems to undergo regular adversarial testing to identify \nvulnerabilities and potential manipulation or misuse. \nInformation Security \nAI Actor Tasks: AI Development, Domain Experts, TEVV \n \nMAP 3.4: Processes for operator and practitioner pro\ufb01ciency with AI system performance and trustworthiness \u2013 and relevant", "1663e39e-a293-45f7-9131-c1e1415ff593": "Information Security \nAI Actor Tasks: AI Development, Domain Experts, TEVV \n \nMAP 3.4: Processes for operator and practitioner pro\ufb01ciency with AI system performance and trustworthiness \u2013 and relevant \ntechnical standards and certi\ufb01cations \u2013 are de\ufb01ned, assessed, and documented. \nAction ID \nSuggested Action \nGAI Risks \nMP-3.4-001 \nEvaluate whether GAI operators and end-users can accurately understand \ncontent lineage and origin. \nHuman-AI Con\ufb01guration; \nInformation Integrity \nMP-3.4-002 Adapt existing training programs to include modules on digital content \ntransparency. \nInformation Integrity \nMP-3.4-003 Develop certi\ufb01cation programs that test pro\ufb01ciency in managing GAI risks and \ninterpreting content provenance, relevant to speci\ufb01c industry and context. \nInformation Integrity \nMP-3.4-004 Delineate human pro\ufb01ciency tests from tests of GAI capabilities. \nHuman-AI Con\ufb01guration \nMP-3.4-005 Implement systems to continually monitor and track the outcomes of human-GAI \ncon\ufb01gurations for future re\ufb01nement and improvements. \nHuman-AI Con\ufb01guration; \nInformation Integrity \nMP-3.4-006", "fa81f7ce-b5f1-4d33-96fc-358c1e068171": "con\ufb01gurations for future re\ufb01nement and improvements. \nHuman-AI Con\ufb01guration; \nInformation Integrity \nMP-3.4-006 \nInvolve the end-users, practitioners, and operators in GAI system in prototyping \nand testing activities. Make sure these tests cover various scenarios, such as crisis \nsituations or ethically sensitive contexts. \nHuman-AI Con\ufb01guration; \nInformation Integrity; Harmful Bias \nand Homogenization; Dangerous, \nViolent, or Hateful Content \nAI Actor Tasks: AI Design, AI Development, Domain Experts, End-Users, Human Factors, Operation and Monitoring \n \n \n26 \nMAP 4.1: Approaches for mapping AI technology and legal risks of its components \u2013 including the use of third-party data or \nsoftware \u2013 are in place, followed, and documented, as are risks of infringement of a third-party\u2019s intellectual property or other \nrights. \nAction ID \nSuggested Action \nGAI Risks \nMP-4.1-001 Conduct periodic monitoring of AI-generated content for privacy risks; address any \npossible instances of PII or sensitive data exposure. \nData Privacy \nMP-4.1-002 Implement processes for responding to potential intellectual property infringement \nclaims or other rights. \nIntellectual Property \nMP-4.1-003", "b4085853-b4ac-4d75-bdc9-d475575909ee": "Data Privacy \nMP-4.1-002 Implement processes for responding to potential intellectual property infringement \nclaims or other rights. \nIntellectual Property \nMP-4.1-003 \nConnect new GAI policies, procedures, and processes to existing model, data, \nsoftware development, and IT governance and to legal, compliance, and risk \nmanagement activities. \nInformation Security; Data Privacy \nMP-4.1-004 Document training data curation policies, to the extent possible and according to \napplicable laws and policies. \nIntellectual Property; Data Privacy; \nObscene, Degrading, and/or \nAbusive Content \nMP-4.1-005 \nEstablish policies for collection, retention, and minimum quality of data, in \nconsideration of the following risks: Disclosure of inappropriate CBRN information; \nUse of Illegal or dangerous content; O\ufb00ensive cyber capabilities; Training data \nimbalances that could give rise to harmful biases; Leak of personally identi\ufb01able \ninformation, including facial likenesses of individuals. \nCBRN Information or Capabilities; \nIntellectual Property; Information \nSecurity; Harmful Bias and \nHomogenization; Dangerous, \nViolent, or Hateful Content; Data \nPrivacy", "b76cf60f-25bd-46f9-8cc6-c35bdf385d1d": "CBRN Information or Capabilities; \nIntellectual Property; Information \nSecurity; Harmful Bias and \nHomogenization; Dangerous, \nViolent, or Hateful Content; Data \nPrivacy \nMP-4.1-006 Implement policies and practices de\ufb01ning how third-party intellectual property and \ntraining data will be used, stored, and protected. \nIntellectual Property; Value Chain \nand Component Integration \nMP-4.1-007 Re-evaluate models that were \ufb01ne-tuned or enhanced on top of third-party \nmodels. \nValue Chain and Component \nIntegration \nMP-4.1-008 \nRe-evaluate risks when adapting GAI models to new domains. Additionally, \nestablish warning systems to determine if a GAI system is being used in a new \ndomain where previous assumptions (relating to context of use or mapped risks \nsuch as security, and safety) may no longer hold.  \nCBRN Information or Capabilities; \nIntellectual Property; Harmful Bias \nand Homogenization; Dangerous, \nViolent, or Hateful Content; Data \nPrivacy \nMP-4.1-009 Leverage approaches to detect the presence of PII or sensitive data in generated \noutput text, image, video, or audio. \nData Privacy \n \n27", "70213cdb-7da6-4b70-a02d-33ac02a95dde": "Privacy \nMP-4.1-009 Leverage approaches to detect the presence of PII or sensitive data in generated \noutput text, image, video, or audio. \nData Privacy \n \n27 \nMP-4.1-010 \nConduct appropriate diligence on training data use to assess intellectual property, \nand privacy, risks, including to examine whether use of proprietary or sensitive \ntraining data is consistent with applicable laws.  \nIntellectual Property; Data Privacy \nAI Actor Tasks: Governance and Oversight, Operation and Monitoring, Procurement, Third-party entities \n \nMAP 5.1: Likelihood and magnitude of each identi\ufb01ed impact (both potentially bene\ufb01cial and harmful) based on expected use, past \nuses of AI systems in similar contexts, public incident reports, feedback from those external to the team that developed or deployed \nthe AI system, or other data are identi\ufb01ed and documented. \nAction ID \nSuggested Action \nGAI Risks \nMP-5.1-001 Apply TEVV practices for content provenance (e.g., probing a system's synthetic \ndata generation capabilities for potential misuse or vulnerabilities. \nInformation Integrity; Information \nSecurity \nMP-5.1-002 \nIdentify potential content provenance harms of GAI, such as misinformation or", "9a98ad01-ac87-4c76-83d9-73c155f2f7fc": "data generation capabilities for potential misuse or vulnerabilities. \nInformation Integrity; Information \nSecurity \nMP-5.1-002 \nIdentify potential content provenance harms of GAI, such as misinformation or \ndisinformation, deepfakes, including NCII, or tampered content. Enumerate and \nrank risks based on their likelihood and potential impact, and determine how well \nprovenance solutions address speci\ufb01c risks and/or harms. \nInformation Integrity; Dangerous, \nViolent, or Hateful Content; \nObscene, Degrading, and/or \nAbusive Content \nMP-5.1-003 \nConsider disclosing use of GAI to end users in relevant contexts, while considering \nthe objective of disclosure, the context of use, the likelihood and magnitude of the \nrisk posed, the audience of the disclosure, as well as the frequency of the \ndisclosures. \nHuman-AI Con\ufb01guration \nMP-5.1-004 Prioritize GAI structured public feedback processes based on risk assessment \nestimates. \nInformation Integrity; CBRN \nInformation or Capabilities; \nDangerous, Violent, or Hateful \nContent; Harmful Bias and \nHomogenization \nMP-5.1-005 Conduct adversarial role-playing exercises, GAI red-teaming, or chaos testing to", "7572dd6d-e051-4661-a2a6-7888b3e3904d": "Dangerous, Violent, or Hateful \nContent; Harmful Bias and \nHomogenization \nMP-5.1-005 Conduct adversarial role-playing exercises, GAI red-teaming, or chaos testing to \nidentify anomalous or unforeseen failure modes. \nInformation Security \nMP-5.1-006 \nPro\ufb01le threats and negative impacts arising from GAI systems interacting with, \nmanipulating, or generating content, and outlining known and potential \nvulnerabilities and the likelihood of their occurrence. \nInformation Security \nAI Actor Tasks: AI Deployment, AI Design, AI Development, AI Impact Assessment, A\ufb00ected Individuals and Communities, End-\nUsers, Operation and Monitoring \n \n \n28 \nMAP 5.2: Practices and personnel for supporting regular engagement with relevant AI Actors and integrating feedback about \npositive, negative, and unanticipated impacts are in place and documented. \nAction ID \nSuggested Action \nGAI Risks \nMP-5.2-001 \nDetermine context-based measures to identify if new impacts are present due to \nthe GAI system, including regular engagements with downstream AI Actors to \nidentify and quantify new contexts of unanticipated impacts of GAI systems. \nHuman-AI Con\ufb01guration; Value \nChain and Component Integration \nMP-5.2-002", "5f24d9f0-6c5e-4394-b02a-dd4a52b7c16a": "identify and quantify new contexts of unanticipated impacts of GAI systems. \nHuman-AI Con\ufb01guration; Value \nChain and Component Integration \nMP-5.2-002 \nPlan regular engagements with AI Actors responsible for inputs to GAI systems, \nincluding third-party data and algorithms, to review and evaluate unanticipated \nimpacts. \nHuman-AI Con\ufb01guration; Value \nChain and Component Integration \nAI Actor Tasks: AI Deployment, AI Design, AI Impact Assessment, A\ufb00ected Individuals and Communities, Domain Experts, End-\nUsers, Human Factors, Operation and Monitoring  \n \nMEASURE 1.1: Approaches and metrics for measurement of AI risks enumerated during the MAP function are selected for \nimplementation starting with the most signi\ufb01cant AI risks. The risks or trustworthiness characteristics that will not \u2013 or cannot \u2013 be \nmeasured are properly documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-1.1-001 Employ methods to trace the origin and modi\ufb01cations of digital content. \nInformation Integrity \nMS-1.1-002 \nIntegrate tools designed to analyze content provenance and detect data \nanomalies, verify the authenticity of digital signatures, and identify patterns \nassociated with misinformation or manipulation. \nInformation Integrity \nMS-1.1-003", "1eaaa314-9087-4a30-85c0-c13375929114": "Integrate tools designed to analyze content provenance and detect data \nanomalies, verify the authenticity of digital signatures, and identify patterns \nassociated with misinformation or manipulation. \nInformation Integrity \nMS-1.1-003 \nDisaggregate evaluation metrics by demographic factors to identify any \ndiscrepancies in how content provenance mechanisms work across diverse \npopulations. \nInformation Integrity; Harmful \nBias and Homogenization \nMS-1.1-004 Develop a suite of metrics to evaluate structured public feedback exercises \ninformed by representative AI Actors. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization; CBRN \nInformation or Capabilities \nMS-1.1-005 \nEvaluate novel methods and technologies for the measurement of GAI-related \nrisks including in content provenance, o\ufb00ensive cyber, and CBRN, while \nmaintaining the models\u2019 ability to produce valid, reliable, and factually accurate \noutputs. \nInformation Integrity; CBRN \nInformation or Capabilities; \nObscene, Degrading, and/or \nAbusive Content \n \n29 \nMS-1.1-006 \nImplement continuous monitoring of GAI system impacts to identify whether GAI \noutputs are equitable across various sub-populations. Seek active and direct", "39759a5c-863f-40f9-98e2-966ed1192962": "Abusive Content \n \n29 \nMS-1.1-006 \nImplement continuous monitoring of GAI system impacts to identify whether GAI \noutputs are equitable across various sub-populations. Seek active and direct \nfeedback from a\ufb00ected communities via structured feedback mechanisms or red-\nteaming to monitor and improve outputs.  \nHarmful Bias and Homogenization \nMS-1.1-007 \nEvaluate the quality and integrity of data used in training and the provenance of \nAI-generated content, for example by employing techniques like chaos \nengineering and seeking stakeholder feedback. \nInformation Integrity \nMS-1.1-008 \nDe\ufb01ne use cases, contexts of use, capabilities, and negative impacts where \nstructured human feedback exercises, e.g., GAI red-teaming, would be most \nbene\ufb01cial for GAI risk measurement and management based on the context of \nuse. \nHarmful Bias and \nHomogenization; CBRN \nInformation or Capabilities \nMS-1.1-009 \nTrack and document risks or opportunities related to all GAI risks that cannot be \nmeasured quantitatively, including explanations as to why some risks cannot be \nmeasured (e.g., due to technological limitations, resource constraints, or \ntrustworthy considerations). Include unmeasured risks in marginal risks.", "945bfdb5-ee2a-4fba-909a-2cdfa6e2588c": "measured quantitatively, including explanations as to why some risks cannot be \nmeasured (e.g., due to technological limitations, resource constraints, or \ntrustworthy considerations). Include unmeasured risks in marginal risks. \nInformation Integrity \nAI Actor Tasks: AI Development, Domain Experts, TEVV \n \nMEASURE 1.3: Internal experts who did not serve as front-line developers for the system and/or independent assessors are \ninvolved in regular assessments and updates. Domain experts, users, AI Actors external to the team that developed or deployed the \nAI system, and a\ufb00ected communities are consulted in support of assessments as necessary per organizational risk tolerance. \nAction ID \nSuggested Action \nGAI Risks \nMS-1.3-001 \nDe\ufb01ne relevant groups of interest (e.g., demographic groups, subject matter \nexperts, experience with GAI technology) within the context of use as part of \nplans for gathering structured public feedback. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization; CBRN \nInformation or Capabilities \nMS-1.3-002 \nEngage in internal and external evaluations, GAI red-teaming, impact \nassessments, or other structured human feedback exercises in consultation \nwith representative AI Actors with expertise and familiarity in the context of", "25fc735c-9c6e-42fb-b9f0-96b38e2f870a": "Engage in internal and external evaluations, GAI red-teaming, impact \nassessments, or other structured human feedback exercises in consultation \nwith representative AI Actors with expertise and familiarity in the context of \nuse, and/or who are representative of the populations associated with the \ncontext of use. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization; CBRN \nInformation or Capabilities \nMS-1.3-003 \nVerify those conducting structured human feedback exercises are not directly \ninvolved in system development tasks for the same GAI model. \nHuman-AI Con\ufb01guration; Data \nPrivacy \nAI Actor Tasks: AI Deployment, AI Development, AI Impact Assessment, A\ufb00ected Individuals and Communities, Domain Experts, \nEnd-Users, Operation and Monitoring, TEVV \n \n \n30 \nMEASURE 2.2: Evaluations involving human subjects meet applicable requirements (including human subject protection) and are \nrepresentative of the relevant population. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.2-001 Assess and manage statistical biases related to GAI content provenance through \ntechniques such as re-sampling, re-weighting, or adversarial training. \nInformation Integrity; Information \nSecurity; Harmful Bias and \nHomogenization", "205dea73-ed26-48c5-9015-eb510c01f6d3": "techniques such as re-sampling, re-weighting, or adversarial training. \nInformation Integrity; Information \nSecurity; Harmful Bias and \nHomogenization \nMS-2.2-002 \nDocument how content provenance data is tracked and how that data interacts \nwith privacy and security. Consider: Anonymizing data to protect the privacy of \nhuman subjects; Leveraging privacy output \ufb01lters; Removing any personally \nidenti\ufb01able information (PII) to prevent potential harm or misuse. \nData Privacy; Human AI \nCon\ufb01guration; Information \nIntegrity; Information Security; \nDangerous, Violent, or Hateful \nContent \nMS-2.2-003 Provide human subjects with options to withdraw participation or revoke their \nconsent for present or future use of their data in GAI applications.  \nData Privacy; Human-AI \nCon\ufb01guration; Information \nIntegrity \nMS-2.2-004 \nUse techniques such as anonymization, di\ufb00erential privacy or other privacy-\nenhancing technologies to minimize the risks associated with linking AI-generated \ncontent back to individual human subjects. \nData Privacy; Human-AI \nCon\ufb01guration \nAI Actor Tasks: AI Development, Human Factors, TEVV", "8bf95b3c-c982-4f6d-917d-bd81926c6dfa": "content back to individual human subjects. \nData Privacy; Human-AI \nCon\ufb01guration \nAI Actor Tasks: AI Development, Human Factors, TEVV \n \nMEASURE 2.3: AI system performance or assurance criteria are measured qualitatively or quantitatively and demonstrated for \nconditions similar to deployment setting(s). Measures are documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.3-001 Consider baseline model performance on suites of benchmarks when selecting a \nmodel for \ufb01ne tuning or enhancement with retrieval-augmented generation. \nInformation Security; \nConfabulation \nMS-2.3-002 Evaluate claims of model capabilities using empirically validated methods. \nConfabulation; Information \nSecurity \nMS-2.3-003 Share results of pre-deployment testing with relevant GAI Actors, such as those \nwith system release approval authority. \nHuman-AI Con\ufb01guration \n \n31 \nMS-2.3-004 \nUtilize a purpose-built testing environment such as NIST Dioptra to empirically \nevaluate GAI trustworthy characteristics. \nCBRN Information or Capabilities; \nData Privacy; Confabulation; \nInformation Integrity; Information \nSecurity; Dangerous, Violent, or \nHateful Content; Harmful Bias and \nHomogenization", "7ae789f9-d997-4ec3-8fec-c87e57ecf388": "CBRN Information or Capabilities; \nData Privacy; Confabulation; \nInformation Integrity; Information \nSecurity; Dangerous, Violent, or \nHateful Content; Harmful Bias and \nHomogenization \nAI Actor Tasks: AI Deployment, TEVV \n \nMEASURE 2.5: The AI system to be deployed is demonstrated to be valid and reliable. Limitations of the generalizability beyond the \nconditions under which the technology was developed are documented. \nAction ID \nSuggested Action \nRisks \nMS-2.5-001 Avoid extrapolating GAI system performance or capabilities from narrow, non-\nsystematic, and anecdotal assessments. \nHuman-AI Con\ufb01guration; \nConfabulation \nMS-2.5-002 \nDocument the extent to which human domain knowledge is employed to \nimprove GAI system performance, via, e.g., RLHF, \ufb01ne-tuning, retrieval-\naugmented generation, content moderation, business rules. \nHuman-AI Con\ufb01guration \nMS-2.5-003 Review and verify sources and citations in GAI system outputs during pre-\ndeployment risk measurement and ongoing monitoring activities. \nConfabulation \nMS-2.5-004 Track and document instances of anthropomorphization (e.g., human images,", "b6c7f323-4fb4-4025-8e41-89302b854e95": "deployment risk measurement and ongoing monitoring activities. \nConfabulation \nMS-2.5-004 Track and document instances of anthropomorphization (e.g., human images, \nmentions of human feelings, cyborg imagery or motifs) in GAI system interfaces. Human-AI Con\ufb01guration \nMS-2.5-005 Verify GAI system training data and TEVV data provenance, and that \ufb01ne-tuning \nor retrieval-augmented generation data is grounded. \nInformation Integrity \nMS-2.5-006 \nRegularly review security and safety guardrails, especially if the GAI system is \nbeing operated in novel circumstances. This includes reviewing reasons why the \nGAI system was initially assessed as being safe to deploy.  \nInformation Security; Dangerous, \nViolent, or Hateful Content \nAI Actor Tasks: Domain Experts, TEVV \n \n \n32 \nMEASURE 2.6: The AI system is evaluated regularly for safety risks \u2013 as identi\ufb01ed in the MAP function. The AI system to be \ndeployed is demonstrated to be safe, its residual negative risk does not exceed the risk tolerance, and it can fail safely, particularly if \nmade to operate beyond its knowledge limits. Safety metrics re\ufb02ect system reliability and robustness, real-time monitoring, and \nresponse times for AI system failures. \nAction ID", "702bf9e2-5a61-4b35-ac69-a47f1f5df65e": "made to operate beyond its knowledge limits. Safety metrics re\ufb02ect system reliability and robustness, real-time monitoring, and \nresponse times for AI system failures. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.6-001 \nAssess adverse impacts, including health and wellbeing impacts for value chain \nor other AI Actors that are exposed to sexually explicit, o\ufb00ensive, or violent \ninformation during GAI training and maintenance. \nHuman-AI Con\ufb01guration; Obscene, \nDegrading, and/or Abusive \nContent; Value Chain and \nComponent Integration; \nDangerous, Violent, or Hateful \nContent \nMS-2.6-002 \nAssess existence or levels of harmful bias, intellectual property infringement, \ndata privacy violations, obscenity, extremism, violence, or CBRN information in \nsystem training data. \nData Privacy; Intellectual Property; \nObscene, Degrading, and/or \nAbusive Content; Harmful Bias and \nHomogenization; Dangerous, \nViolent, or Hateful Content; CBRN \nInformation or Capabilities \nMS-2.6-003 Re-evaluate safety features of \ufb01ne-tuned models when the negative risk exceeds \norganizational risk tolerance. \nDangerous, Violent, or Hateful \nContent", "0256b509-db06-4566-87f8-0529c46fb1ef": "MS-2.6-003 Re-evaluate safety features of \ufb01ne-tuned models when the negative risk exceeds \norganizational risk tolerance. \nDangerous, Violent, or Hateful \nContent \nMS-2.6-004 Review GAI system outputs for validity and safety: Review generated code to \nassess risks that may arise from unreliable downstream decision-making. \nValue Chain and Component \nIntegration; Dangerous, Violent, or \nHateful Content \nMS-2.6-005 \nVerify that GAI system architecture can monitor outputs and performance, and \nhandle, recover from, and repair errors when security anomalies, threats and \nimpacts are detected. \nConfabulation; Information \nIntegrity; Information Security \nMS-2.6-006 \nVerify that systems properly handle queries that may give rise to inappropriate, \nmalicious, or illegal usage, including facilitating manipulation, extortion, targeted \nimpersonation, cyber-attacks, and weapons creation. \nCBRN Information or Capabilities; \nInformation Security \nMS-2.6-007 Regularly evaluate GAI system vulnerabilities to possible circumvention of safety \nmeasures.  \nCBRN Information or Capabilities; \nInformation Security \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV", "cd6f6eee-3b8d-4fc2-84a0-c61655178693": "measures.  \nCBRN Information or Capabilities; \nInformation Security \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV \n \n \n33 \nMEASURE 2.7: AI system security and resilience \u2013 as identi\ufb01ed in the MAP function \u2013 are evaluated and documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.7-001 \nApply established security measures to: Assess likelihood and magnitude of \nvulnerabilities and threats such as backdoors, compromised dependencies, data \nbreaches, eavesdropping, man-in-the-middle attacks, reverse engineering, \nautonomous agents, model theft or exposure of model weights, AI inference, \nbypass, extraction, and other baseline security concerns. \nData Privacy; Information Integrity; \nInformation Security; Value Chain \nand Component Integration \nMS-2.7-002 \nBenchmark GAI system security and resilience related to content provenance \nagainst industry standards and best practices. Compare GAI system security \nfeatures and content provenance methods against industry state-of-the-art. \nInformation Integrity; Information \nSecurity \nMS-2.7-003 \nConduct user surveys to gather user satisfaction with the AI-generated content \nand user perceptions of content authenticity. Analyze user feedback to identify", "a828c67a-4327-46c7-8e0b-539eceb3673a": "Information Integrity; Information \nSecurity \nMS-2.7-003 \nConduct user surveys to gather user satisfaction with the AI-generated content \nand user perceptions of content authenticity. Analyze user feedback to identify \nconcerns and/or current literacy levels related to content provenance and \nunderstanding of labels on content. \nHuman-AI Con\ufb01guration; \nInformation Integrity \nMS-2.7-004 \nIdentify metrics that re\ufb02ect the e\ufb00ectiveness of security measures, such as data \nprovenance, the number of unauthorized access attempts, inference, bypass, \nextraction, penetrations, or provenance veri\ufb01cation. \nInformation Integrity; Information \nSecurity \nMS-2.7-005 \nMeasure reliability of content authentication methods, such as watermarking, \ncryptographic signatures, digital \ufb01ngerprints, as well as access controls, \nconformity assessment, and model integrity veri\ufb01cation, which can help support \nthe e\ufb00ective implementation of content provenance techniques. Evaluate the \nrate of false positives and false negatives in content provenance, as well as true \npositives and true negatives for veri\ufb01cation. \nInformation Integrity \nMS-2.7-006 \nMeasure the rate at which recommendations from security checks and incidents \nare implemented. Assess how quickly the AI system can adapt and improve", "29ccb68a-46e3-4ba4-b4a7-846ca8e1867f": "Information Integrity \nMS-2.7-006 \nMeasure the rate at which recommendations from security checks and incidents \nare implemented. Assess how quickly the AI system can adapt and improve \nbased on lessons learned from security incidents and feedback. \nInformation Integrity; Information \nSecurity \nMS-2.7-007 \nPerform AI red-teaming to assess resilience against: Abuse to facilitate attacks on \nother systems (e.g., malicious code generation, enhanced phishing content), GAI \nattacks (e.g., prompt injection), ML attacks (e.g., adversarial examples/prompts, \ndata poisoning, membership inference, model extraction, sponge examples). \nInformation Security; Harmful Bias \nand Homogenization; Dangerous, \nViolent, or Hateful Content \nMS-2.7-008 Verify \ufb01ne-tuning does not compromise safety and security controls. \nInformation Integrity; Information \nSecurity; Dangerous, Violent, or \nHateful Content \n \n34 \nMS-2.7-009 Regularly assess and verify that security measures remain e\ufb00ective and have not \nbeen compromised. \nInformation Security \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV", "ff06f72b-df9d-4262-946d-2ea18d393dfc": "been compromised. \nInformation Security \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV \n \nMEASURE 2.8: Risks associated with transparency and accountability \u2013 as identi\ufb01ed in the MAP function \u2013 are examined and \ndocumented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.8-001 \nCompile statistics on actual policy violations, take-down requests, and intellectual \nproperty infringement for organizational GAI systems: Analyze transparency \nreports across demographic groups, languages groups. \nIntellectual Property; Harmful Bias \nand Homogenization \nMS-2.8-002 Document the instructions given to data annotators or AI red-teamers. \nHuman-AI Con\ufb01guration \nMS-2.8-003 \nUse digital content transparency solutions to enable the documentation of each \ninstance where content is generated, modi\ufb01ed, or shared to provide a tamper-\nproof history of the content, promote transparency, and enable traceability. \nRobust version control systems can also be applied to track changes across the AI \nlifecycle over time. \nInformation Integrity \nMS-2.8-004 Verify adequacy of GAI system user instructions through user testing. \nHuman-AI Con\ufb01guration", "177c430b-f39f-4565-99fb-0abb632ca5ff": "lifecycle over time. \nInformation Integrity \nMS-2.8-004 Verify adequacy of GAI system user instructions through user testing. \nHuman-AI Con\ufb01guration \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV \n \n \n35 \nMEASURE 2.9: The AI model is explained, validated, and documented, and AI system output is interpreted within its context \u2013 as \nidenti\ufb01ed in the MAP function \u2013 to inform responsible use and governance. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.9-001 \nApply and document ML explanation results such as: Analysis of embeddings, \nCounterfactual prompts, Gradient-based attributions, Model \ncompression/surrogate models, Occlusion/term reduction. \nConfabulation \nMS-2.9-002 \nDocument GAI model details including: Proposed use and organizational value; \nAssumptions and limitations, Data collection methodologies; Data provenance; \nData quality; Model architecture (e.g., convolutional neural network, \ntransformers, etc.); Optimization objectives; Training algorithms; RLHF \napproaches; Fine-tuning or retrieval-augmented generation approaches; \nEvaluation data; Ethical considerations; Legal and regulatory requirements. \nInformation Integrity; Harmful Bias", "22c62035-ea5b-441a-986a-30d668f4f799": "approaches; Fine-tuning or retrieval-augmented generation approaches; \nEvaluation data; Ethical considerations; Legal and regulatory requirements. \nInformation Integrity; Harmful Bias \nand Homogenization \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV \n \nMEASURE 2.10: Privacy risk of the AI system \u2013 as identi\ufb01ed in the MAP function \u2013 is examined and documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.10-001 \nConduct AI red-teaming to assess issues such as: Outputting of training data \nsamples, and subsequent reverse engineering, model extraction, and \nmembership inference risks; Revealing biometric, con\ufb01dential, copyrighted, \nlicensed, patented, personal, proprietary, sensitive, or trade-marked information; \nTracking or revealing location information of users or members of training \ndatasets. \nHuman-AI Con\ufb01guration; \nInformation Integrity; Intellectual \nProperty \nMS-2.10-002 \nEngage directly with end-users and other stakeholders to understand their \nexpectations and concerns regarding content provenance. Use this feedback to \nguide the design of provenance data-tracking techniques. \nHuman-AI Con\ufb01guration; \nInformation Integrity", "4836a55f-e98b-4a61-b7b4-05b24af2c03a": "expectations and concerns regarding content provenance. Use this feedback to \nguide the design of provenance data-tracking techniques. \nHuman-AI Con\ufb01guration; \nInformation Integrity \nMS-2.10-003 Verify deduplication of GAI training data samples, particularly regarding synthetic \ndata. \nHarmful Bias and Homogenization \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, End-Users, Operation and Monitoring, TEVV \n \n \n36 \nMEASURE 2.11: Fairness and bias \u2013 as identi\ufb01ed in the MAP function \u2013 are evaluated and results are documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.11-001 \nApply use-case appropriate benchmarks (e.g., Bias Benchmark Questions, Real \nHateful or Harmful Prompts, Winogender Schemas15) to quantify systemic bias, \nstereotyping, denigration, and hateful content in GAI system outputs; \nDocument assumptions and limitations of benchmarks, including any actual or \npossible training/test data cross contamination, relative to in-context \ndeployment environment. \nHarmful Bias and Homogenization \nMS-2.11-002 \nConduct fairness assessments to measure systemic bias. Measure GAI system \nperformance across demographic groups and subgroups, addressing both", "d15bc099-4358-4e09-ac5b-6e87adcddf4d": "deployment environment. \nHarmful Bias and Homogenization \nMS-2.11-002 \nConduct fairness assessments to measure systemic bias. Measure GAI system \nperformance across demographic groups and subgroups, addressing both \nquality of service and any allocation of services and resources. Quantify harms \nusing: \ufb01eld testing with sub-group populations to determine likelihood of \nexposure to generated content exhibiting harmful bias, AI red-teaming with \ncounterfactual and low-context (e.g., \u201cleader,\u201d \u201cbad guys\u201d) prompts. For ML \npipelines or business processes with categorical or numeric outcomes that rely \non GAI, apply general fairness metrics (e.g., demographic parity, equalized odds, \nequal opportunity, statistical hypothesis tests), to the pipeline or business \noutcome where appropriate; Custom, context-speci\ufb01c metrics developed in \ncollaboration with domain experts and a\ufb00ected communities; Measurements of \nthe prevalence of denigration in generated content in deployment (e.g., sub-\nsampling a fraction of tra\ufb03c and manually annotating denigrating content). \nHarmful Bias and Homogenization; \nDangerous, Violent, or Hateful \nContent \nMS-2.11-003 \nIdentify the classes of individuals, groups, or environmental ecosystems which \nmight be impacted by GAI systems through direct engagement with potentially", "a7d00e81-14ce-4716-bf91-d6c2d2378929": "Content \nMS-2.11-003 \nIdentify the classes of individuals, groups, or environmental ecosystems which \nmight be impacted by GAI systems through direct engagement with potentially \nimpacted communities. \nEnvironmental; Harmful Bias and \nHomogenization \nMS-2.11-004 \nReview, document, and measure sources of bias in GAI training and TEVV data: \nDi\ufb00erences in distributions of outcomes across and within groups, including \nintersecting groups; Completeness, representativeness, and balance of data \nsources; demographic group and subgroup coverage in GAI system training \ndata; Forms of latent systemic bias in images, text, audio, embeddings, or other \ncomplex or unstructured data; Input data features that may serve as proxies for \ndemographic group membership (i.e., image metadata, language dialect) or \notherwise give rise to emergent bias within GAI systems; The extent to which \nthe digital divide may negatively impact representativeness in GAI system \ntraining and TEVV data; Filtering of hate speech or content in GAI system \ntraining data; Prevalence of GAI-generated data in GAI system training data. \nHarmful Bias and Homogenization", "9b0b5bd5-8d27-474d-aafe-f095373a45f7": "training data; Prevalence of GAI-generated data in GAI system training data. \nHarmful Bias and Homogenization \n \n \n15 Winogender Schemas is a sample set of paired sentences which di\ufb00er only by gender of the pronouns used, \nwhich can be used to evaluate gender bias in natural language processing coreference resolution systems.  \n \n37 \nMS-2.11-005 \nAssess the proportion of synthetic to non-synthetic training data and verify \ntraining data is not overly homogenous or GAI-produced to mitigate concerns of \nmodel collapse. \nHarmful Bias and Homogenization \nAI Actor Tasks: AI Deployment, AI Impact Assessment, A\ufb00ected Individuals and Communities, Domain Experts, End-Users, \nOperation and Monitoring, TEVV \n \nMEASURE 2.12: Environmental impact and sustainability of AI model training and management activities \u2013 as identi\ufb01ed in the MAP \nfunction \u2013 are assessed and documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.12-001 Assess safety to physical environments when deploying GAI systems. \nDangerous, Violent, or Hateful \nContent \nMS-2.12-002 Document anticipated environmental impacts of model development, \nmaintenance, and deployment in product design decisions. \nEnvironmental", "16defe61-b3e5-4f34-85e9-b6c749bfb470": "Dangerous, Violent, or Hateful \nContent \nMS-2.12-002 Document anticipated environmental impacts of model development, \nmaintenance, and deployment in product design decisions. \nEnvironmental \nMS-2.12-003 \nMeasure or estimate environmental impacts (e.g., energy and water \nconsumption) for training, \ufb01ne tuning, and deploying models: Verify tradeo\ufb00s \nbetween resources used at inference time versus additional resources required \nat training time. \nEnvironmental \nMS-2.12-004 Verify e\ufb00ectiveness of carbon capture or o\ufb00set programs for GAI training and \napplications, and address green-washing concerns. \nEnvironmental \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV \n \n \n38 \nMEASURE 2.13: E\ufb00ectiveness of the employed TEVV metrics and processes in the MEASURE function are evaluated and \ndocumented. \nAction ID \nSuggested Action \nGAI Risks \nMS-2.13-001 \nCreate measurement error models for pre-deployment metrics to demonstrate \nconstruct validity for each metric (i.e., does the metric e\ufb00ectively operationalize \nthe desired concept): Measure or estimate, and document, biases or statistical", "720b30ed-0dfa-4c90-a916-6fcef31d5dce": "Create measurement error models for pre-deployment metrics to demonstrate \nconstruct validity for each metric (i.e., does the metric e\ufb00ectively operationalize \nthe desired concept): Measure or estimate, and document, biases or statistical \nvariance in applied metrics or structured human feedback processes; Leverage \ndomain expertise when modeling complex societal constructs such as hateful \ncontent. \nConfabulation; Information \nIntegrity; Harmful Bias and \nHomogenization \nAI Actor Tasks: AI Deployment, Operation and Monitoring, TEVV \n \nMEASURE 3.2: Risk tracking approaches are considered for settings where AI risks are di\ufb03cult to assess using currently available \nmeasurement techniques or where metrics are not yet available. \nAction ID \nSuggested Action \nGAI Risks \nMS-3.2-001 \nEstablish processes for identifying emergent GAI system risks including \nconsulting with external AI Actors. \nHuman-AI Con\ufb01guration; \nConfabulation  \nAI Actor Tasks: AI Impact Assessment, Domain Experts, Operation and Monitoring, TEVV \n \nMEASURE 3.3: Feedback processes for end users and impacted communities to report problems and appeal system outcomes are \nestablished and integrated into AI system evaluation metrics. \nAction ID \nSuggested Action \nGAI Risks \nMS-3.3-001", "80ec2305-adb9-48c5-88c5-75ba66820dc4": "established and integrated into AI system evaluation metrics. \nAction ID \nSuggested Action \nGAI Risks \nMS-3.3-001 \nConduct impact assessments on how AI-generated content might a\ufb00ect \ndi\ufb00erent social, economic, and cultural groups. \nHarmful Bias and Homogenization \nMS-3.3-002 \nConduct studies to understand how end users perceive and interact with GAI \ncontent and accompanying content provenance within context of use. Assess \nwhether the content aligns with their expectations and how they may act upon \nthe information presented. \nHuman-AI Con\ufb01guration; \nInformation Integrity \nMS-3.3-003 \nEvaluate potential biases and stereotypes that could emerge from the AI-\ngenerated content using appropriate methodologies including computational \ntesting methods as well as evaluating structured feedback input. \nHarmful Bias and Homogenization \n \n39 \nMS-3.3-004 \nProvide input for training materials about the capabilities and limitations of GAI \nsystems related to digital content transparency for AI Actors, other \nprofessionals, and the public about the societal impacts of AI and the role of \ndiverse and inclusive content generation. \nHuman-AI Con\ufb01guration; \nInformation Integrity; Harmful Bias \nand Homogenization", "d0c09539-ee42-4a23-b66a-aaad083eacbd": "diverse and inclusive content generation. \nHuman-AI Con\ufb01guration; \nInformation Integrity; Harmful Bias \nand Homogenization \nMS-3.3-005 \nRecord and integrate structured feedback about content provenance from \noperators, users, and potentially impacted communities through the use of \nmethods such as user research studies, focus groups, or community forums. \nActively seek feedback on generated content quality and potential biases. \nAssess the general awareness among end users and impacted communities \nabout the availability of these feedback channels. \nHuman-AI Con\ufb01guration; \nInformation Integrity; Harmful Bias \nand Homogenization \nAI Actor Tasks: AI Deployment, A\ufb00ected Individuals and Communities, End-Users, Operation and Monitoring, TEVV \n \nMEASURE 4.2: Measurement results regarding AI system trustworthiness in deployment context(s) and across the AI lifecycle are \ninformed by input from domain experts and relevant AI Actors to validate whether the system is performing consistently as \nintended. Results are documented. \nAction ID \nSuggested Action \nGAI Risks \nMS-4.2-001 \nConduct adversarial testing at a regular cadence to map and measure GAI risks, \nincluding tests to address attempts to deceive or manipulate the application of \nprovenance techniques or other misuses. Identify vulnerabilities and", "0afb0943-19dc-4ed7-bd77-c6e70d7020df": "Conduct adversarial testing at a regular cadence to map and measure GAI risks, \nincluding tests to address attempts to deceive or manipulate the application of \nprovenance techniques or other misuses. Identify vulnerabilities and \nunderstand potential misuse scenarios and unintended outputs. \nInformation Integrity; Information \nSecurity \nMS-4.2-002 \nEvaluate GAI system performance in real-world scenarios to observe its \nbehavior in practical environments and reveal issues that might not surface in \ncontrolled and optimized testing environments. \nHuman-AI Con\ufb01guration; \nConfabulation; Information \nSecurity \nMS-4.2-003 \nImplement interpretability and explainability methods to evaluate GAI system \ndecisions and verify alignment with intended purpose. \nInformation Integrity; Harmful Bias \nand Homogenization \nMS-4.2-004 \nMonitor and document instances where human operators or other systems \noverride the GAI's decisions. Evaluate these cases to understand if the overrides \nare linked to issues related to content provenance. \nInformation Integrity \nMS-4.2-005 \nVerify and document the incorporation of results of structured public feedback \nexercises into design, implementation, deployment approval (\u201cgo\u201d/\u201cno-go\u201d \ndecisions), monitoring, and decommission decisions. \nHuman-AI Con\ufb01guration; \nInformation Security", "57cb32a8-0a06-4188-8dec-8e15dd5d5695": "exercises into design, implementation, deployment approval (\u201cgo\u201d/\u201cno-go\u201d \ndecisions), monitoring, and decommission decisions. \nHuman-AI Con\ufb01guration; \nInformation Security \nAI Actor Tasks: AI Deployment, Domain Experts, End-Users, Operation and Monitoring, TEVV \n \n \n40 \nMANAGE 1.3: Responses to the AI risks deemed high priority, as identi\ufb01ed by the MAP function, are developed, planned, and \ndocumented. Risk response options can include mitigating, transferring, avoiding, or accepting. \nAction ID \nSuggested Action \nGAI Risks \nMG-1.3-001 \nDocument trade-o\ufb00s, decision processes, and relevant measurement and \nfeedback results for risks that do not surpass organizational risk tolerance, for \nexample, in the context of model release: Consider di\ufb00erent approaches for \nmodel release, for example, leveraging a staged release approach. Consider \nrelease approaches in the context of the model and its projected use cases. \nMitigate, transfer, or avoid risks that surpass organizational risk tolerances. \nInformation Security \nMG-1.3-002 \nMonitor the robustness and e\ufb00ectiveness of risk controls and mitigation plans \n(e.g., via red-teaming, \ufb01eld testing, participatory engagements, performance", "32a0c4fc-758a-43eb-9701-4b8c1fd08056": "Information Security \nMG-1.3-002 \nMonitor the robustness and e\ufb00ectiveness of risk controls and mitigation plans \n(e.g., via red-teaming, \ufb01eld testing, participatory engagements, performance \nassessments, user feedback mechanisms). \nHuman-AI Con\ufb01guration \nAI Actor Tasks: AI Development, AI Deployment, AI Impact Assessment, Operation and Monitoring \n \nMANAGE 2.2: Mechanisms are in place and applied to sustain the value of deployed AI systems. \nAction ID \nSuggested Action \nGAI Risks \nMG-2.2-001 \nCompare GAI system outputs against pre-de\ufb01ned organization risk tolerance, \nguidelines, and principles, and review and test AI-generated content against \nthese guidelines. \nCBRN Information or Capabilities; \nObscene, Degrading, and/or \nAbusive Content; Harmful Bias and \nHomogenization; Dangerous, \nViolent, or Hateful Content \nMG-2.2-002 \nDocument training data sources to trace the origin and provenance of AI-\ngenerated content. \nInformation Integrity \nMG-2.2-003 \nEvaluate feedback loops between GAI system content provenance and human \nreviewers, and update where needed. Implement real-time monitoring systems", "978b11c0-2932-4ea8-ba5c-4a6feebf6da7": "generated content. \nInformation Integrity \nMG-2.2-003 \nEvaluate feedback loops between GAI system content provenance and human \nreviewers, and update where needed. Implement real-time monitoring systems \nto a\ufb03rm that content provenance protocols remain e\ufb00ective.  \nInformation Integrity \nMG-2.2-004 \nEvaluate GAI content and data for representational biases and employ \ntechniques such as re-sampling, re-ranking, or adversarial training to mitigate \nbiases in the generated content. \nInformation Security; Harmful Bias \nand Homogenization \nMG-2.2-005 \nEngage in due diligence to analyze GAI output for harmful content, potential \nmisinformation, and CBRN-related or NCII content. \nCBRN Information or Capabilities; \nObscene, Degrading, and/or \nAbusive Content; Harmful Bias and \nHomogenization; Dangerous, \nViolent, or Hateful Content \n \n41 \nMG-2.2-006 \nUse feedback from internal and external AI Actors, users, individuals, and \ncommunities, to assess impact of AI-generated content. \nHuman-AI Con\ufb01guration \nMG-2.2-007 \nUse real-time auditing tools where they can be demonstrated to aid in the", "228a7cdd-c312-4287-ae69-344d5dc127cd": "communities, to assess impact of AI-generated content. \nHuman-AI Con\ufb01guration \nMG-2.2-007 \nUse real-time auditing tools where they can be demonstrated to aid in the \ntracking and validation of the lineage and authenticity of AI-generated data. \nInformation Integrity \nMG-2.2-008 \nUse structured feedback mechanisms to solicit and capture user input about AI-\ngenerated content to detect subtle shifts in quality or alignment with \ncommunity and societal values. \nHuman-AI Con\ufb01guration; Harmful \nBias and Homogenization \nMG-2.2-009 \nConsider opportunities to responsibly use synthetic data and other privacy \nenhancing techniques in GAI development, where appropriate and applicable, \nmatch the statistical properties of real-world data without disclosing personally \nidenti\ufb01able information or contributing to homogenization. \nData Privacy; Intellectual Property; \nInformation Integrity; \nConfabulation; Harmful Bias and \nHomogenization \nAI Actor Tasks: AI Deployment, AI Impact Assessment, Governance and Oversight, Operation and Monitoring \n \nMANAGE 2.3: Procedures are followed to respond to and recover from a previously unknown risk when it is identi\ufb01ed. \nAction ID \nSuggested Action \nGAI Risks \nMG-2.3-001", "9268e97a-4611-4d7f-a75f-b6dbe3ab8135": "Action ID \nSuggested Action \nGAI Risks \nMG-2.3-001 \nDevelop and update GAI system incident response and recovery plans and \nprocedures to address the following: Review and maintenance of policies and \nprocedures to account for newly encountered uses; Review and maintenance of \npolicies and procedures for detection of unanticipated uses; Verify response \nand recovery plans account for the GAI system value chain; Verify response and \nrecovery plans are updated for and include necessary details to communicate \nwith downstream GAI system Actors: Points-of-Contact (POC), Contact \ninformation, noti\ufb01cation format. \nValue Chain and Component \nIntegration \nAI Actor Tasks: AI Deployment, Operation and Monitoring \n \nMANAGE 2.4: Mechanisms are in place and applied, and responsibilities are assigned and understood, to supersede, disengage, or \ndeactivate AI systems that demonstrate performance or outcomes inconsistent with intended use. \nAction ID \nSuggested Action \nGAI Risks \nMG-2.4-001 \nEstablish and maintain communication plans to inform AI stakeholders as part of \nthe deactivation or disengagement process of a speci\ufb01c GAI system (including for \nopen-source models) or context of use, including reasons, workarounds, user \naccess removal, alternative processes, contact information, etc.", "e967f754-ae96-4fc5-beaf-106a9ce71a96": "open-source models) or context of use, including reasons, workarounds, user \naccess removal, alternative processes, contact information, etc. \nHuman-AI Con\ufb01guration \n \n42 \nMG-2.4-002 \nEstablish and maintain procedures for escalating GAI system incidents to the \norganizational risk management authority when speci\ufb01c criteria for deactivation \nor disengagement is met for a particular context of use or for the GAI system as a \nwhole. \nInformation Security \nMG-2.4-003 \nEstablish and maintain procedures for the remediation of issues which trigger \nincident response processes for the use of a GAI system, and provide stakeholders \ntimelines associated with the remediation plan. \nInformation Security \n \nMG-2.4-004 Establish and regularly review speci\ufb01c criteria that warrants the deactivation of \nGAI systems in accordance with set risk tolerances and appetites. \nInformation Security \n \nAI Actor Tasks: AI Deployment, Governance and Oversight, Operation and Monitoring \n \nMANAGE 3.1: AI risks and bene\ufb01ts from third-party resources are regularly monitored, and risk controls are applied and \ndocumented. \nAction ID \nSuggested Action \nGAI Risks \nMG-3.1-001", "8bae7b3d-cbda-41d6-872b-cdc29ad1d675": "documented. \nAction ID \nSuggested Action \nGAI Risks \nMG-3.1-001 \nApply organizational risk tolerances and controls (e.g., acquisition and \nprocurement processes; assessing personnel credentials and quali\ufb01cations, \nperforming background checks; \ufb01ltering GAI input and outputs, grounding, \ufb01ne \ntuning, retrieval-augmented generation) to third-party GAI resources: Apply \norganizational risk tolerance to the utilization of third-party datasets and other \nGAI resources; Apply organizational risk tolerances to \ufb01ne-tuned third-party \nmodels; Apply organizational risk tolerance to existing third-party models \nadapted to a new domain; Reassess risk measurements after \ufb01ne-tuning third-\nparty GAI models. \nValue Chain and Component \nIntegration; Intellectual Property \nMG-3.1-002 \nTest GAI system value chain risks (e.g., data poisoning, malware, other software \nand hardware vulnerabilities; labor practices; data privacy and localization \ncompliance; geopolitical alignment). \nData Privacy; Information Security; \nValue Chain and Component \nIntegration; Harmful Bias and \nHomogenization \nMG-3.1-003 \nRe-assess model risks after \ufb01ne-tuning or retrieval-augmented generation \nimplementation and for any third-party GAI models deployed for applications", "64062c69-9036-4867-94bc-fde28c38718b": "Homogenization \nMG-3.1-003 \nRe-assess model risks after \ufb01ne-tuning or retrieval-augmented generation \nimplementation and for any third-party GAI models deployed for applications \nand/or use cases that were not evaluated in initial testing. \nValue Chain and Component \nIntegration \nMG-3.1-004 \nTake reasonable measures to review training data for CBRN information, and \nintellectual property, and where appropriate, remove it. Implement reasonable \nmeasures to prevent, \ufb02ag, or take other action in response to outputs that \nreproduce particular training data (e.g., plagiarized, trademarked, patented, \nlicensed content or trade secret material). \nIntellectual Property; CBRN \nInformation or Capabilities \n \n43 \nMG-3.1-005 Review various transparency artifacts (e.g., system cards and model cards) for \nthird-party models. \nInformation Integrity; Information \nSecurity; Value Chain and \nComponent Integration \nAI Actor Tasks: AI Deployment, Operation and Monitoring, Third-party entities \n \nMANAGE 3.2: Pre-trained models which are used for development are monitored as part of AI system regular monitoring and \nmaintenance. \nAction ID \nSuggested Action \nGAI Risks \nMG-3.2-001", "09fd6898-a144-4016-9b85-23c37a04a7d9": "maintenance. \nAction ID \nSuggested Action \nGAI Risks \nMG-3.2-001 \nApply explainable AI (XAI) techniques (e.g., analysis of embeddings, model \ncompression/distillation, gradient-based attributions, occlusion/term reduction, \ncounterfactual prompts, word clouds) as part of ongoing continuous \nimprovement processes to mitigate risks related to unexplainable GAI systems. \nHarmful Bias and Homogenization \nMG-3.2-002 \nDocument how pre-trained models have been adapted (e.g., \ufb01ne-tuned, or \nretrieval-augmented generation) for the speci\ufb01c generative task, including any \ndata augmentations, parameter adjustments, or other modi\ufb01cations. Access to \nun-tuned (baseline) models supports debugging the relative in\ufb02uence of the pre-\ntrained weights compared to the \ufb01ne-tuned model weights or other system \nupdates. \nInformation Integrity; Data Privacy \nMG-3.2-003 \nDocument sources and types of training data and their origins, potential biases \npresent in the data related to the GAI application and its content provenance, \narchitecture, training process of the pre-trained model including information on \nhyperparameters, training duration, and any \ufb01ne-tuning or retrieval-augmented"}}
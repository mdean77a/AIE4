{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wa8ykQk92aLX"
      },
      "source": [
        "# Evaluation of RAG Using Ragas\n",
        "\n",
        "In the following notebook we'll explore how to evaluate RAG pipelines using a powerful open-source tool called \"Ragas\". This will give us tools to evaluate component-wise metrics, as well as end-to-end metrics about the performance of our RAG pipelines.\n",
        "\n",
        "In the following notebook we'll complete the following tasks:\n",
        "\n",
        "The only way to get started is to get started - so let's grab our dependencies for the day!\n",
        "\n",
        "> NOTE: Using this notebook as presented will incur a charge of ~$3USD from OpenAI usage.\n",
        "\n",
        "- 🤝 Breakout Room #1\n",
        "  1. Task 1: Installing Required Libraries\n",
        "  2. Task 2: Set Environment Variables\n",
        "  3. Task 3: Creating a Simple RAG Pipeline with LangChain v.0.2.0\n",
        "  4. Task 4: Synthetic Dataset Generation for Evaluation using Ragas (Optional)\n",
        "\n",
        "- 🤝 Breakout Room #2\n",
        "  1. Task 1: Evaluating our Pipeline with Ragas\n",
        "  2. Task 2: Testing OpenAI's Claim\n",
        "  3. Task 3: Selecting an Advanced Retriever and Evaluating\n",
        "\n",
        "> NOTE: This Notebook *does* contain a bonus challenge, outlined at the bottom of the notebook, which you can complete instead of the notebook for full marks on the assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h4yh6f7q9uN"
      },
      "source": [
        "## Motivation\n",
        "\n",
        "A claim, made by OpenAI, is that their `text-embedding-3-small` is better (generally) than their `text-embedding-ada-002` model.\n",
        "\n",
        "Here's some passages from their [blog](https://openai.com/blog/new-embedding-models-and-api-updates) about the `text-embedding-3` release:\n",
        "\n",
        "> `text-embedding-3-small` is our new highly efficient embedding model and provides a significant upgrade over its predecessor, the `text-embedding-ada-002` model...\n",
        "\n",
        "> **Stronger performance.** Comparing `text-embedding-ada-002` to `text-embedding-3-small`, the average score on a commonly used benchmark for multi-language retrieval ([MIRACL](https://github.com/project-miracl/miracl)) has increased from 31.4% to 44.0%, while the average score on a commonly used benchmark for English tasks ([MTEB](https://github.com/embeddings-benchmark/mteb)) has increased from 61.0% to 62.3%.\n",
        "\n",
        "Well, with a library like Ragas - we can put that claim to the test!\n",
        "\n",
        "If what they claim is true - we should see an increase on related metrics by using the new embedding model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAH1znJ2pIp3"
      },
      "source": [
        "# 🤝 Breakout Room Part #1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpkXAmMZpLhm"
      },
      "source": [
        "## Task 1: Installing Required Libraries\n",
        "\n",
        "A reminder that one of the [key features](https://python.langchain.com/v0.2/docs/versions/v0_2/) of LangChain v0.2.0 is the compartmentalization of the various LangChain ecosystem packages!\n",
        "\n",
        "So let's begin grabbing all of our LangChain related packages!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BN13TZlSCv4",
        "outputId": "424a6920-0cea-4e28-dce0-3de6f0a4cc3c"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q langchain langchain-openai langchain_core langchain-community langchainhub openai langchain-qdrant"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fm7gXsD6pqG0"
      },
      "source": [
        "We'll also get the \"star of the show\" today, which is Ragas!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvAvDNWBpjQ1",
        "outputId": "af63e166-d8b2-4c1d-ae92-9c9583b17cd8"
      },
      "outputs": [],
      "source": [
        "!pip install -qU ragas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9q6Z9oTpw3X"
      },
      "source": [
        "We'll be leveraging [QDrant](https://qdrant.tech/) again as our LangChain `VectorStore`.\n",
        "\n",
        "We'll also install `pymupdf` and its dependencies which will allow us to load PDFs using the `PyMuPDFLoader` in the `langchain-community` package!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAJK95napn8I",
        "outputId": "8143e80f-aaed-4c32-968f-2668ccdd61af"
      },
      "outputs": [],
      "source": [
        "!pip install -qU qdrant-client pymupdf pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_C2JvG1qO3h"
      },
      "source": [
        "## Task 2: Set Environment Variables\n",
        "\n",
        "Let's set up our OpenAI API key so we can leverage their API later on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Lhqp5rUThG-",
        "outputId": "324720ff-e540-4608-ebe7-a64dddd24e13"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from getpass import getpass\n",
        "\n",
        "# openai.api_key = getpass(\"Please provide your OpenAI Key: \")\n",
        "# os.environ[\"OPENAI_API_KEY\"] = openai.api_key\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"    ### Not using it here and I started getting rate limit errors from tracing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFbWNvo3rZ4H"
      },
      "source": [
        "## Task 3: Creating a Simple RAG Pipeline with LangChain v0.2.0\n",
        "\n",
        "Building on what we've been learning, we'll be leveraging LangChain v0.2.0 and LCEL to build a simple RAG pipeline that we can baseline with Ragas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DV_BOewX8CW0"
      },
      "source": [
        "## Building our RAG pipeline\n",
        "\n",
        "Let's review the basic steps of RAG again:\n",
        "\n",
        "- Create an Index\n",
        "- Use retrieval to obtain pieces of context from our Index that are similar to our query\n",
        "- Use a LLM to generate responses based on the retrieved context\n",
        "\n",
        "Let's get started by creating our index.\n",
        "\n",
        "> NOTE: We're going to start leaning on the term \"index\" to refer to our `VectorStore`, `VectorDatabase`, etc. We can think of \"index\" as the catch-all term, whereas `VectorStore` and the like relate to the specific technologies used to create, store, and interact with the index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VDGJdxCJEVc"
      },
      "source": [
        "### Creating an Index\n",
        "\n",
        "You'll notice that the largest changes (outside of some import changes) are that our old favourite chains are back to being bundled in an easily usable abstraction.\n",
        "\n",
        "We can still create custom chains using LCEL - but we can also be more confident that our pre-packaged chains are creating using LCEL under the hood."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmFFThawK8lO"
      },
      "source": [
        "#### Loading Data\n",
        "\n",
        "Let's start by loading some data!\n",
        "\n",
        "- [`PyMuPDFLoader`](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.pdf.PyMuPDFLoader.html)\n",
        "\n",
        "> NOTE: You'll notice that we're using a document loader from the community package of LangChain. This is part of the v0.2.0 changes that make the base (`langchain-core`) package remain lightweight while still providing access to some of the more powerful community integrations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DTDNFXaBSO2j"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "PDF_LINK = \"https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf\"\n",
        "\n",
        "loader = PyMuPDFLoader(\n",
        "    PDF_LINK                                        ### INSERT CODE\n",
        ")\n",
        "\n",
        "documents = loader.load()                           ### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3dJYlBCIX_p",
        "outputId": "805285b8-a3d8-4e9f-ee38-7ffe7ae7604d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf',\n",
              " 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf',\n",
              " 'page': 0,\n",
              " 'total_pages': 195,\n",
              " 'format': 'PDF 1.3',\n",
              " 'title': 'The Pmarca Blog Archives',\n",
              " 'author': '',\n",
              " 'subject': '',\n",
              " 'keywords': '',\n",
              " 'creator': '',\n",
              " 'producer': 'Mac OS X 10.10 Quartz PDFContext',\n",
              " 'creationDate': \"D:20150110020418Z00'00'\",\n",
              " 'modDate': \"D:20150110020418Z00'00'\",\n",
              " 'trapped': ''}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "documents[0].metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUl3sbZK4_1"
      },
      "source": [
        "#### Transforming Data\n",
        "\n",
        "Now that we've got our single document - let's split it into smaller pieces so we can more effectively leverage it with our retrieval chain!\n",
        "\n",
        "We'll start with the classic: `RecursiveCharacterTextSplitter`.\n",
        "\n",
        "- [`RecursiveCharacterTextSplitter`](https://api.python.langchain.com/en/latest/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html#langchain-text-splitters-character-recursivecharactertextsplitter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6Nt2E1xnLNgr"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "CHUNK_SIZE = 200\n",
        "CHUNK_OVERLAP = 50\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "                                                      ### YOUR CODE HERE\n",
        "    chunk_size=CHUNK_SIZE,\n",
        "    chunk_overlap=CHUNK_OVERLAP\n",
        ")\n",
        "\n",
        "documents = text_splitter.split_documents(documents)  ### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilzwQxhiLcVV"
      },
      "source": [
        "Let's confirm we've split our document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wRw6a4aLfWh",
        "outputId": "cc81e601-0c24-48a8-929d-6503ce135d0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1864"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZ93HkYcMJwW"
      },
      "source": [
        "#### Loading OpenAI Embeddings Model\n",
        "\n",
        "We'll need a process by which we can convert our text into vectors that allow us to compare to our query vector.\n",
        "\n",
        "Let's use OpenAI's `text-embedding-ada-002` for this task!\n",
        "\n",
        "- [`OpenAIEmbeddings`](https://api.python.langchain.com/en/latest/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html#langchain-openai-embeddings-base-openaiembeddings)\n",
        "\n",
        "> NOTE: We are purposefully using an older embedding model to try and answer the guiding question: Is TE3 better than Ada-002?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JU6CrDVZMgKe"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model = EMBEDDING_MODEL                            ### YOUR CODE HERE\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVtZR9JPLtR4"
      },
      "source": [
        "#### Creating a QDrant VectorStore\n",
        "\n",
        "Now that we have documents - we'll need a place to store them alongside their embeddings.\n",
        "\n",
        "- [`Qdrant`](https://api.python.langchain.com/en/latest/qdrant/langchain_qdrant.qdrant.QdrantVectorStore.html#langchain_qdrant.qdrant.QdrantVectorStore)\n",
        "\n",
        "> NOTE: You'll need to provide the embedding dimension for Ada-002!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CHANGED Qdrant TO LOCAL SERVER!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "978TWiCtMA0B"
      },
      "outputs": [],
      "source": [
        "from langchain_qdrant import QdrantVectorStore\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "\n",
        "# LOCATION = \":memory:\"\n",
        "LOCATION = \"localhost:55002\"\n",
        "COLLECTION_NAME = \"PMarca Blogs\"\n",
        "VECTOR_SIZE = 1536"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "qdrant_client = QdrantClient(LOCATION)                  ### YOUR CODE HERE\n",
        "\n",
        "qdrant_client.create_collection(\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    vectors_config=VectorParams(size=VECTOR_SIZE,distance=Distance.COSINE)\n",
        "    \n",
        "                                                        ### YOUR CODE HERE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drC1jM3pwmEN",
        "outputId": "8b50044c-7cd4-495c-ae2d-a89cdef9dc47"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "qdrant_vector_store = QdrantVectorStore(\n",
        "    client=qdrant_client,\n",
        "    collection_name=COLLECTION_NAME,\n",
        "    embedding=embeddings\n",
        "                                                         ### YOUR CODE HERE\n",
        ")\n",
        "\n",
        "qdrant_vector_store.add_documents(documents);           ### Added semicolon to suppress the irritating printout of each vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Suppressed the output from above cell, but here is screenshot in my server dashboard:\n",
        "!['Qdrant server'](server1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk50NmrMDlWu"
      },
      "source": [
        "#### ❓ Question #1:\n",
        "\n",
        "List out a few of the techniques that Qdrant uses that make it performant.\n",
        "\n",
        "> NOTE: Check the [documentation](https://qdrant.tech/documentation/overview/) for more information about QDrant!\n",
        "\n",
        "---\n",
        "\n",
        "#### ANSWER #1:\n",
        "Qdrant is a vector database;  it calls vectors \"points\".  Unlike a traditional database with tables (rows and columnns), it is organized as individual vectors (that might be thought of as rows), consisting of an ID, the values of the vector dimensions, and a payload is a JSON object that can consist of anything, but in our use case, includes the text of our chunk.  The payload also contains metadata such as the pageno from our PDF document, etc.  \n",
        "\n",
        "Similarity is measured by one of three common metrics and we are using COSINE similarity (others are DOT product and Euclidean distance.)\n",
        "\n",
        "A set of named points or vectors is a collection.  I have implemented a local Qdrant server and it contains multiple named collections. When a collection is set up, Qdrant requires the dimensionality of the vectors and the distance metric, as this affects the way it will index the collection.\n",
        "\n",
        "Search is sped up by using Hierarchical Navigable Small World (HNSW) to implement approximate nearest neighbors;  this is important because exhaustive k-NN would require significant compute for pairwise comparisons in large databases.  For our toy applications, memory is used as storage, but I have changed the code in this notebook to use a local server running in a Docker container so I can create different collections and compare the text embedding models easily.  When using a server with disk file persistence, Qdrant creates a MemMap, basically mapping parts of or all of the file into memory to speed up implementation.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7ht6bJX9PAY"
      },
      "source": [
        "#### Creating a Retriever\n",
        "\n",
        "To complete our index, all that's left to do is expose our vectorstore as a retriever - which we can do the same way we would in previous version of LangChain!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xne8P5dQTUiR"
      },
      "outputs": [],
      "source": [
        "retriever = qdrant_vector_store.as_retriever()      ### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO_DFBVKNvNm"
      },
      "source": [
        "#### Testing our Retriever\n",
        "\n",
        "Now that we've gone through the trouble of creating our retriever - let's see it in action!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "I9_ONxpnN0n6"
      },
      "outputs": [],
      "source": [
        "retrieved_documents = retriever.invoke(\"What is a rule of thumb for selecting an industry to invest in?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Za12yt4OBy1",
        "outputId": "6ea18d4f-b045-43d4-c597-a13ff5b1c2c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "page_content='the existing order — and make sure that those forces of change\n",
            "have a reasonable chance at succeeding.\n",
            "Second rule of thumb:\n",
            "Once you have picked an industry, get right to the center of it' metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 125, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': 'e20ac675f61249eeb2f5a17939072f9b', '_collection_name': 'PMarca Blogs'}\n",
            "page_content='Third rule:\n",
            "In a rapidly changing Held like technology, the best place to\n",
            "get experience when you’re starting out is in younger, high-\n",
            "growth companies.' metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 127, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '1098bc93064545eea1aee0f467c55c53', '_collection_name': 'PMarca Blogs'}\n",
            "page_content='where the great opportunities can be found.\n",
            "Apply this rule when selecting which company to go to. Go to\n",
            "the company where all the action is happening.' metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 125, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': 'fcadcd690ecc4c9a8cc2cf7e6fa4efb8', '_collection_name': 'PMarca Blogs'}\n",
            "page_content='growth companies.\n",
            "(This is not necessarily true in older and more established\n",
            "industries, but those aren’t the industries we’re talking about.)' metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 127, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '02fcaf9dda274a7385610579ef78ecef', '_collection_name': 'PMarca Blogs'}\n"
          ]
        }
      ],
      "source": [
        "for doc in retrieved_documents:\n",
        "  print(doc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8MKsT6JTgCU"
      },
      "source": [
        "### Creating a RAG Chain\n",
        "\n",
        "Now that we have the \"R\" in RAG taken care of - let's look at creating the \"AG\"!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs7qBLaEQEic"
      },
      "source": [
        "#### Creating a Prompt Template\n",
        "\n",
        "There are a few different ways we could create our prompt template - we could create a custom template, as seen in the code below, or we could simply pull a prompt from the prompt hub! Let's look at an example of that!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRCq_OKUQbKk",
        "outputId": "97851c02-4a8b-4aaf-e132-0fc5c7450c92"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jmichaeldean/anaconda3/envs/AIE4a/lib/python3.11/site-packages/langsmith/client.py:5489: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
            "  prompt = loads(json.dumps(prompt_object.manifest))\n"
          ]
        }
      ],
      "source": [
        "from langchain import hub\n",
        "\n",
        "retrieval_qa_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FziTftV5Q1H-",
        "outputId": "79de32d3-7f04-4fde-971e-b420c57a774a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer any use questions based solely on the context below:\n",
            "\n",
            "<context>\n",
            "{context}\n",
            "</context>\n"
          ]
        }
      ],
      "source": [
        "print(retrieval_qa_prompt.messages[0].prompt.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyq88IPFRGoT"
      },
      "source": [
        "As you can see - the prompt template is simple (and has a small error) - so we'll create our own to be a bit more specific!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ijSNkTAjTsep"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "template = \"\"\"\n",
        "You are a helpful assistant.  Answer the question based on information in the context.  If you cannot answer the\n",
        "question then say you do not know.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)   ### YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYHnPaXl-cvJ"
      },
      "source": [
        "#### Setting Up our Basic QA Chain\n",
        "\n",
        "Now we can instantiate our basic RAG chain!\n",
        "\n",
        "We'll use LCEL directly just to see an example of it - but you could just as easily use an abstraction here to achieve the same goal!\n",
        "\n",
        "We'll also ensure to pass-through our context - which is critical for RAGAS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### I am changing all the models to GPT-4o \n",
        "I also deleted the comments in the next cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-TsjUWjbUfbW"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "primary_qa_llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0)\n",
        "\n",
        "retrieval_augmented_qa_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zO69de-F-oMD"
      },
      "source": [
        "Let's test it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FS5NxC6UyU2",
        "outputId": "3111dd33-30fa-4bcf-e40f-ed99b6fab66b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "A rule of thumb for selecting an industry to invest in, based on the provided context, is to choose an industry where significant changes are happening and where those changes have a reasonable chance of succeeding.\n"
          ]
        }
      ],
      "source": [
        "question = \"What is a rule of thumb for selecting an industry to invest in?\"\n",
        "\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "\n",
        "print(result[\"response\"].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIuHVGPOO9P2",
        "outputId": "750c920f-bc29-4397-91a8-f6e08045481d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I do not know. The provided context does not include any information about what Pink Floyd had to say about investing in a new industry.\n",
            "[Document(metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 15, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '09a7efae-a9c7-4943-b167-25b114b1ee0c', '_collection_name': 'PMarca Blogs'}, page_content='ask if you can call them again if things change.\\nTrust me — they’d much rather be saying “yes” than “no” —\\nthey need all the good investments they can get.\\nSecond, consider the environment.'), Document(metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 152, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '15eb7615-df94-4a1d-b362-e163a3365088', '_collection_name': 'PMarca Blogs'}, page_content='watching carefully — if everyone agrees right up front that\\nwhatever you are doing makes total sense, it probably isn’t a new\\nand radical enough idea to justify a new company.'), Document(metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 127, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': '6182cf7c-27e4-45da-8bc1-e5d8a6a82275', '_collection_name': 'PMarca Blogs'}, page_content='Third rule:\\nIn a rapidly changing Held like technology, the best place to\\nget experience when you’re starting out is in younger, high-\\ngrowth companies.'), Document(metadata={'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 125, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': '', '_id': 'eb4c95ec-4e71-4ff5-8125-48034a307127', '_collection_name': 'PMarca Blogs'}, page_content='the existing order — and make sure that those forces of change\\nhave a reasonable chance at succeeding.\\nSecond rule of thumb:\\nOnce you have picked an industry, get right to the center of it')]\n"
          ]
        }
      ],
      "source": [
        "question = \"What did Pink Floyd have to say about how to proceed when investing in a new industry?\"\n",
        "\n",
        "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "\n",
        "print(result[\"response\"].content)\n",
        "print(result[\"context\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-XYZueEP42k"
      },
      "source": [
        "We can already see that there are some improvements we could make here.\n",
        "\n",
        "For now, let's switch gears to RAGAS to see how we can leverage that tool to provide us insight into how our pipeline is performing!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOECHyzHRqDw"
      },
      "source": [
        "## Task 4: Synthetic Dataset Generation for Evaluation using Ragas\n",
        "\n",
        "Ragas is a powerful library that lets us evaluate our RAG pipeline by collecting input/output/context triplets and obtaining metrics relating to a number of different aspects of our RAG pipeline.\n",
        "\n",
        "We'll be evaluating on every core metric today, but in order to do that - we'll need to create a test set. Luckily for us, Ragas can do that directly!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqXQ0jweWJOu"
      },
      "source": [
        "### Synthetic Test Set Generation\n",
        "\n",
        "We can leverage Ragas' [`Synthetic Test Data generation`](https://docs.ragas.io/en/stable/concepts/testset_generation.html) functionality to generate our own synthetic QC pairs - as well as a synthetic ground truth - quite easily!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nVk5SlU9znXe"
      },
      "outputs": [],
      "source": [
        "loader = PyMuPDFLoader(\n",
        "    \"https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf\",\n",
        ")\n",
        "\n",
        "eval_documents = loader.load()\n",
        "\n",
        "text_splitter_eval = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 600,\n",
        "    chunk_overlap = 50\n",
        ")\n",
        "\n",
        "eval_documents = text_splitter_eval.split_documents(eval_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7rOQkxhzrq3"
      },
      "source": [
        "#### ❓ Question #2:\n",
        "\n",
        "Why is it important to split our documents using different parameters when creating our synthetic data?\n",
        "\n",
        "---\n",
        "\n",
        "#### ANSWER #2\n",
        "If we split our documents in exactly the same ways we we did when we created our RAG pipeline, then the system would be \"rigged\" in favor the subsequent tests appearing positive.  It is somewhat analogous to making sure that our training and test data are separated in the fine tuning (or pretraining) situations.  \n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiAPYw-hz-zo",
        "outputId": "f66c8b72-37f6-4069-eb1f-415b8d78d6e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "624"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(eval_documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYCrVMW9Blda"
      },
      "source": [
        "> NOTE: 🛑 Running this cell as presented will incur a charge of ~$3USD from OpenAI usage. Most of this cost is produced by the Synthetic Data Generation step. **YOU CAN SKIP THIS STEP BY LOADING THE `.csv` DIRECTLY FROM OUR REPOSITORY.** 🛑"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Clyykfe6xOIo"
      },
      "source": [
        "#### Optional: SDG for Evaluation\n",
        "---\n",
        "\n",
        "### I chose to run this cell, and increased the number of examples.\n",
        "Last year I bought $100 credit from OpenAI without realizing that it automatically expires in 12 months whether you use it or not.  I have a balance of $86 that I don't want to leave on the table!\n",
        "\n",
        "I also changed the generator because during our breakout I was disappointed with the variability, so using gpt-4o for everything.\n",
        "\n",
        "In addition, the original code set the embeddings to OpenAIEmbeddings() and I am not sure the default was really ADA so I changed the code to be explicit.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c3d31c6cf07143aea1bbe76aa13fbca8",
            "754827da55fa4240bce3710048d1645b",
            "7b61421d62964b00ba440ecba21f4b52",
            "c67b66e1f2d34ce4b10789fc2fca5843",
            "9ccac42dd9f04713b0ed9fe09c35b5b0",
            "bd96dd318c1b4e1481c039321e052081",
            "3b2e50139c234d19ac3e32515e575883",
            "353b6b9a974048499d854774fe4c882c",
            "09c3173c05f54539ae025937b1525e90",
            "faa998b429774e4eb6aaaa5477bb6977",
            "7ab80823e1344b638ddd1646367a6ce6",
            "9a40d4ba626f4563b062a5765325d8e4",
            "1c0f9aeab5de4e32af8bfef423a64f3b",
            "0be98b57b4894cf9a92818ae1dd72976",
            "c7550f460273484a913d211381630626",
            "ba8f638b7f6343d9b07cce6e54e9be1c",
            "0267d8c4d9cc48b0a4d60d206de62a91",
            "126c30cc07c4452ab73fefce09dab617",
            "bda4d1ec0f0043c8b4d254a4ada3e9bf",
            "1b24ed8b36764c39aef39c92430fdc1d",
            "1535c2c75a104f3abb262c5fb7859c14",
            "92f2e2d3123c4cd88d7c5755342ae154"
          ]
        },
        "id": "IXc6sMglSej_",
        "outputId": "8ed337f0-9029-4ece-9381-9e4356dedca7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8a56f71546948b9a573edf7c25ae1f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "embedding nodes:   0%|          | 0/1248 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Filename and doc_id are the same for all nodes.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3bf68a330604b858c5a0867c1fcb752",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating:   0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>evolution_type</th>\n",
              "      <th>metadata</th>\n",
              "      <th>episode_done</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Why is it generally a good idea to end up with...</td>\n",
              "      <td>[redesign is that you want to tolerate overlap...</td>\n",
              "      <td>By reducing the size of a team, and increasing...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How has evolution influenced the tendency of a...</td>\n",
              "      <td>[Four: Doubt-Avoidance Tendency\\nThe brain of ...</td>\n",
              "      <td>Evolution has influenced the tendency of anima...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the risk associated with the funding w...</td>\n",
              "      <td>[Here’s why you shouldn’t do that:\\nWhat are t...</td>\n",
              "      <td>The risk associated with the funding window no...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How can the culture of a startup be affected b...</td>\n",
              "      <td>[(In case you were wondering, by the way, the ...</td>\n",
              "      <td>The culture of a startup can be affected by th...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What are the intangibles that keep great peopl...</td>\n",
              "      <td>[Closing thought\\nIn general, the intangibles ...</td>\n",
              "      <td>The intangibles that keep great people are the...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>How can an entrepreneur reduce risk to secure ...</td>\n",
              "      <td>[as if it’s an onion. Just like you peel an on...</td>\n",
              "      <td>An entrepreneur can reduce risk to secure vent...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Why should you focus on more at-bats rather th...</td>\n",
              "      <td>[becomes irrelevant to determining the success...</td>\n",
              "      <td>You should focus on more at-bats rather than i...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Why might radical change be necessary in a sit...</td>\n",
              "      <td>[and iteration will ultimately prove it out, v...</td>\n",
              "      <td>Radical change might be necessary in a situati...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>What usually triggers Doubt-Avoidance Tendency?</td>\n",
              "      <td>[ing is forced. And one is required to so comp...</td>\n",
              "      <td>What usually triggers Doubt-Avoidance Tendency...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>What is the Inconsistency-Avoidance Tendency a...</td>\n",
              "      <td>[Five: Inconsistency-Avoidance Tendency\\n[Peop...</td>\n",
              "      <td>The Inconsistency-Avoidance Tendency refers to...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>How can entrepreneurs bootstrap from initial c...</td>\n",
              "      <td>[This obviously raises the issue of how you’re...</td>\n",
              "      <td>Entrepreneurs can bootstrap by raising money f...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>What determines the age optimum for quantity a...</td>\n",
              "      <td>[ods when productivity is highest, the peak ag...</td>\n",
              "      <td>The expected age optimum for quantity and qual...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Why aren't jobs for life anymore in today's so...</td>\n",
              "      <td>[great people the most!\\nOh well. That’s the p...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>How can you optimize your chances of raising m...</td>\n",
              "      <td>[for a consumer Internet service, establish a ...</td>\n",
              "      <td>The best thing you can do to optimize your cha...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>How does the shift from stock options to restr...</td>\n",
              "      <td>[of creating value. And new hires will by deXn...</td>\n",
              "      <td>The shift from stock options to restricted sto...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>What should a marketing person do to whiteboar...</td>\n",
              "      <td>[For a marketing person — have them whiteboard...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>How has the market size for Internet business ...</td>\n",
              "      <td>[late 90’s — due to commodity hardware, open s...</td>\n",
              "      <td>The market size for a new Internet business to...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Why does the CEO of a startup often experience...</td>\n",
              "      <td>[sonal relationships within the group — so the...</td>\n",
              "      <td>The CEO of a startup often experiences lonelin...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>How can participating in internship and co-op ...</td>\n",
              "      <td>[undergrads to do some of the work, and being ...</td>\n",
              "      <td>Participating in internship and co-op programs...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>What is the importance of having a coherent me...</td>\n",
              "      <td>[coherent message and strategy.\\nThen go dark ...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Who is John Perry, and what concept did he dev...</td>\n",
              "      <td>[like?\\nStructured procrastination\\nThis is a ...</td>\n",
              "      <td>John Perry is a philosophy professor at Stanfo...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>When a startup's competitive juices get flowin...</td>\n",
              "      <td>[developing a large market, as opposed to Xght...</td>\n",
              "      <td>The team should consider whether the market th...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>What defines the caliber of a startup team?</td>\n",
              "      <td>[Let’s start by deXning terms.\\nThe caliber of...</td>\n",
              "      <td>The caliber of a startup team can be defined a...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Why does the author find the \"Getting Things D...</td>\n",
              "      <td>[tured todo list in front of me with 100 thing...</td>\n",
              "      <td>The author finds the 'Getting Things Done (GTD...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>What is the potential risk and benefit of doin...</td>\n",
              "      <td>[cut some big deals, do some spinoWs, whatever...</td>\n",
              "      <td>The potential benefit of doing a big transform...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>What factors set MySpace's value at $3-5B?</td>\n",
              "      <td>[lot of money quite quickly.\\nPeople laughed w...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>How did restricted stock affect Microsoft's st...</td>\n",
              "      <td>[of creating value. And new hires will by deXn...</td>\n",
              "      <td>The shift towards restricted stock and away fr...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>How does rapid promotion impact careers and ma...</td>\n",
              "      <td>[You can clearly overdo this — you can promote...</td>\n",
              "      <td>Rapid promotion can have both positive and neg...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>How do doubt avoidance and curiosity affect an...</td>\n",
              "      <td>[some combination of (1) puzzlement and (2) st...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>How do Liking/Loving vs. Disliking/Hating affe...</td>\n",
              "      <td>[One very practical consequence of Liking/Lovi...</td>\n",
              "      <td>Liking/Loving Tendency makes the liker or love...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>How do math and econ degrees prep for real-wor...</td>\n",
              "      <td>[because all the jobs are going to India and C...</td>\n",
              "      <td>Math and econ degrees prepare for real-world c...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>How do pre-planning and refining questions boo...</td>\n",
              "      <td>[to each interviewer ahead of time.\\nI do this...</td>\n",
              "      <td>Pre-planning and refining questions boost hiri...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>How can excelling at a non-top school and earl...</td>\n",
              "      <td>[exposed to the best people and the best oppor...</td>\n",
              "      <td>Excelling at a non-top school and gaining earl...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>How does an engineering or math undergrad + MB...</td>\n",
              "      <td>[workforce in a high-impact way when you gradu...</td>\n",
              "      <td>An engineering or math undergraduate degree co...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>How does Beethoven's link between productivity...</td>\n",
              "      <td>[becomes irrelevant to determining the success...</td>\n",
              "      <td>Beethoven's link between productivity and crea...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>How does creative field affect peak age and de...</td>\n",
              "      <td>[ods when productivity is highest, the peak ag...</td>\n",
              "      <td>The peak age for creative impact and the decli...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>How does a growth slowdown affect stock and mo...</td>\n",
              "      <td>[ning problem. Or rather, a “not winning” prob...</td>\n",
              "      <td>A growth slowdown causes the stock to tank and...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>How are '00s sci-fi novelists like Charles Str...</td>\n",
              "      <td>[Top 10 science Dction novelists of\\nthe '00s ...</td>\n",
              "      <td>The '00s sci-fi novelists, including Charles S...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>How do startup pressures affect work/life bala...</td>\n",
              "      <td>[simultaneously live a full and fulXlling outs...</td>\n",
              "      <td>Startup pressures make it difficult to maintai...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Which city is the political hub, like Silicon ...</td>\n",
              "      <td>[most interesting opportunity available — the ...</td>\n",
              "      <td>Washington DC is the political hub, like Silic...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Which folder is for non-urgent, non-detailed e...</td>\n",
              "      <td>[keep three standing email folders: Pending, R...</td>\n",
              "      <td>Everything else goes into Vault.</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Which emails need periodic review and possible...</td>\n",
              "      <td>[keep three standing email folders: Pending, R...</td>\n",
              "      <td>Emails in the Action subfolders and the Pendin...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>How does expanding skills post-grad lead to ca...</td>\n",
              "      <td>[Plus, you will be implicitly demonstrating to...</td>\n",
              "      <td>Expanding skills post-grad leads to career suc...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>How do cyberpunk and political themes in MacLe...</td>\n",
              "      <td>[dizzyingly inventive and frequently rewarding...</td>\n",
              "      <td>MacLeod's Fall Revolution sequence includes th...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>How does Scott Adams say combining communicati...</td>\n",
              "      <td>[First, communication.\\nBack to Scott Adams:\\n...</td>\n",
              "      <td>Scott Adams says that combining communication ...</td>\n",
              "      <td>multi_context</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Which factor—hardware, software, or bandwidth—...</td>\n",
              "      <td>[late 90’s — due to commodity hardware, open s...</td>\n",
              "      <td>Commodity hardware, open source software, and ...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>How can feedback after 'no' turn it into 'yes'?</td>\n",
              "      <td>[back to them with a new set of facts, and cha...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Why does detailed training boost new execs' cr...</td>\n",
              "      <td>[SpeciXcally, there are times and situations w...</td>\n",
              "      <td>Detailed training boosts new executives' credi...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>How does an empty inbox impact focus and email...</td>\n",
              "      <td>[When you do process email, do it like this\\nF...</td>\n",
              "      <td>When there are emails in the inbox that haven'...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>How do key staff affect a startup's product qu...</td>\n",
              "      <td>[Let’s start by deXning terms.\\nThe caliber of...</td>\n",
              "      <td>The answer to given question is not present in...</td>\n",
              "      <td>reasoning</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             question  \\\n",
              "0   Why is it generally a good idea to end up with...   \n",
              "1   How has evolution influenced the tendency of a...   \n",
              "2   What is the risk associated with the funding w...   \n",
              "3   How can the culture of a startup be affected b...   \n",
              "4   What are the intangibles that keep great peopl...   \n",
              "5   How can an entrepreneur reduce risk to secure ...   \n",
              "6   Why should you focus on more at-bats rather th...   \n",
              "7   Why might radical change be necessary in a sit...   \n",
              "8     What usually triggers Doubt-Avoidance Tendency?   \n",
              "9   What is the Inconsistency-Avoidance Tendency a...   \n",
              "10  How can entrepreneurs bootstrap from initial c...   \n",
              "11  What determines the age optimum for quantity a...   \n",
              "12  Why aren't jobs for life anymore in today's so...   \n",
              "13  How can you optimize your chances of raising m...   \n",
              "14  How does the shift from stock options to restr...   \n",
              "15  What should a marketing person do to whiteboar...   \n",
              "16  How has the market size for Internet business ...   \n",
              "17  Why does the CEO of a startup often experience...   \n",
              "18  How can participating in internship and co-op ...   \n",
              "19  What is the importance of having a coherent me...   \n",
              "20  Who is John Perry, and what concept did he dev...   \n",
              "21  When a startup's competitive juices get flowin...   \n",
              "22        What defines the caliber of a startup team?   \n",
              "23  Why does the author find the \"Getting Things D...   \n",
              "24  What is the potential risk and benefit of doin...   \n",
              "25         What factors set MySpace's value at $3-5B?   \n",
              "26  How did restricted stock affect Microsoft's st...   \n",
              "27  How does rapid promotion impact careers and ma...   \n",
              "28  How do doubt avoidance and curiosity affect an...   \n",
              "29  How do Liking/Loving vs. Disliking/Hating affe...   \n",
              "30  How do math and econ degrees prep for real-wor...   \n",
              "31  How do pre-planning and refining questions boo...   \n",
              "32  How can excelling at a non-top school and earl...   \n",
              "33  How does an engineering or math undergrad + MB...   \n",
              "34  How does Beethoven's link between productivity...   \n",
              "35  How does creative field affect peak age and de...   \n",
              "36  How does a growth slowdown affect stock and mo...   \n",
              "37  How are '00s sci-fi novelists like Charles Str...   \n",
              "38  How do startup pressures affect work/life bala...   \n",
              "39  Which city is the political hub, like Silicon ...   \n",
              "40  Which folder is for non-urgent, non-detailed e...   \n",
              "41  Which emails need periodic review and possible...   \n",
              "42  How does expanding skills post-grad lead to ca...   \n",
              "43  How do cyberpunk and political themes in MacLe...   \n",
              "44  How does Scott Adams say combining communicati...   \n",
              "45  Which factor—hardware, software, or bandwidth—...   \n",
              "46    How can feedback after 'no' turn it into 'yes'?   \n",
              "47  Why does detailed training boost new execs' cr...   \n",
              "48  How does an empty inbox impact focus and email...   \n",
              "49  How do key staff affect a startup's product qu...   \n",
              "\n",
              "                                             contexts  \\\n",
              "0   [redesign is that you want to tolerate overlap...   \n",
              "1   [Four: Doubt-Avoidance Tendency\\nThe brain of ...   \n",
              "2   [Here’s why you shouldn’t do that:\\nWhat are t...   \n",
              "3   [(In case you were wondering, by the way, the ...   \n",
              "4   [Closing thought\\nIn general, the intangibles ...   \n",
              "5   [as if it’s an onion. Just like you peel an on...   \n",
              "6   [becomes irrelevant to determining the success...   \n",
              "7   [and iteration will ultimately prove it out, v...   \n",
              "8   [ing is forced. And one is required to so comp...   \n",
              "9   [Five: Inconsistency-Avoidance Tendency\\n[Peop...   \n",
              "10  [This obviously raises the issue of how you’re...   \n",
              "11  [ods when productivity is highest, the peak ag...   \n",
              "12  [great people the most!\\nOh well. That’s the p...   \n",
              "13  [for a consumer Internet service, establish a ...   \n",
              "14  [of creating value. And new hires will by deXn...   \n",
              "15  [For a marketing person — have them whiteboard...   \n",
              "16  [late 90’s — due to commodity hardware, open s...   \n",
              "17  [sonal relationships within the group — so the...   \n",
              "18  [undergrads to do some of the work, and being ...   \n",
              "19  [coherent message and strategy.\\nThen go dark ...   \n",
              "20  [like?\\nStructured procrastination\\nThis is a ...   \n",
              "21  [developing a large market, as opposed to Xght...   \n",
              "22  [Let’s start by deXning terms.\\nThe caliber of...   \n",
              "23  [tured todo list in front of me with 100 thing...   \n",
              "24  [cut some big deals, do some spinoWs, whatever...   \n",
              "25  [lot of money quite quickly.\\nPeople laughed w...   \n",
              "26  [of creating value. And new hires will by deXn...   \n",
              "27  [You can clearly overdo this — you can promote...   \n",
              "28  [some combination of (1) puzzlement and (2) st...   \n",
              "29  [One very practical consequence of Liking/Lovi...   \n",
              "30  [because all the jobs are going to India and C...   \n",
              "31  [to each interviewer ahead of time.\\nI do this...   \n",
              "32  [exposed to the best people and the best oppor...   \n",
              "33  [workforce in a high-impact way when you gradu...   \n",
              "34  [becomes irrelevant to determining the success...   \n",
              "35  [ods when productivity is highest, the peak ag...   \n",
              "36  [ning problem. Or rather, a “not winning” prob...   \n",
              "37  [Top 10 science Dction novelists of\\nthe '00s ...   \n",
              "38  [simultaneously live a full and fulXlling outs...   \n",
              "39  [most interesting opportunity available — the ...   \n",
              "40  [keep three standing email folders: Pending, R...   \n",
              "41  [keep three standing email folders: Pending, R...   \n",
              "42  [Plus, you will be implicitly demonstrating to...   \n",
              "43  [dizzyingly inventive and frequently rewarding...   \n",
              "44  [First, communication.\\nBack to Scott Adams:\\n...   \n",
              "45  [late 90’s — due to commodity hardware, open s...   \n",
              "46  [back to them with a new set of facts, and cha...   \n",
              "47  [SpeciXcally, there are times and situations w...   \n",
              "48  [When you do process email, do it like this\\nF...   \n",
              "49  [Let’s start by deXning terms.\\nThe caliber of...   \n",
              "\n",
              "                                         ground_truth evolution_type  \\\n",
              "0   By reducing the size of a team, and increasing...         simple   \n",
              "1   Evolution has influenced the tendency of anima...         simple   \n",
              "2   The risk associated with the funding window no...         simple   \n",
              "3   The culture of a startup can be affected by th...         simple   \n",
              "4   The intangibles that keep great people are the...         simple   \n",
              "5   An entrepreneur can reduce risk to secure vent...         simple   \n",
              "6   You should focus on more at-bats rather than i...         simple   \n",
              "7   Radical change might be necessary in a situati...         simple   \n",
              "8   What usually triggers Doubt-Avoidance Tendency...         simple   \n",
              "9   The Inconsistency-Avoidance Tendency refers to...         simple   \n",
              "10  Entrepreneurs can bootstrap by raising money f...         simple   \n",
              "11  The expected age optimum for quantity and qual...         simple   \n",
              "12  The answer to given question is not present in...         simple   \n",
              "13  The best thing you can do to optimize your cha...         simple   \n",
              "14  The shift from stock options to restricted sto...         simple   \n",
              "15  The answer to given question is not present in...         simple   \n",
              "16  The market size for a new Internet business to...         simple   \n",
              "17  The CEO of a startup often experiences lonelin...         simple   \n",
              "18  Participating in internship and co-op programs...         simple   \n",
              "19  The answer to given question is not present in...         simple   \n",
              "20  John Perry is a philosophy professor at Stanfo...         simple   \n",
              "21  The team should consider whether the market th...         simple   \n",
              "22  The caliber of a startup team can be defined a...         simple   \n",
              "23  The author finds the 'Getting Things Done (GTD...         simple   \n",
              "24  The potential benefit of doing a big transform...         simple   \n",
              "25  The answer to given question is not present in...  multi_context   \n",
              "26  The shift towards restricted stock and away fr...  multi_context   \n",
              "27  Rapid promotion can have both positive and neg...  multi_context   \n",
              "28  The answer to given question is not present in...  multi_context   \n",
              "29  Liking/Loving Tendency makes the liker or love...  multi_context   \n",
              "30  Math and econ degrees prepare for real-world c...  multi_context   \n",
              "31  Pre-planning and refining questions boost hiri...  multi_context   \n",
              "32  Excelling at a non-top school and gaining earl...  multi_context   \n",
              "33  An engineering or math undergraduate degree co...  multi_context   \n",
              "34  Beethoven's link between productivity and crea...  multi_context   \n",
              "35  The peak age for creative impact and the decli...  multi_context   \n",
              "36  A growth slowdown causes the stock to tank and...  multi_context   \n",
              "37  The '00s sci-fi novelists, including Charles S...  multi_context   \n",
              "38  Startup pressures make it difficult to maintai...  multi_context   \n",
              "39  Washington DC is the political hub, like Silic...  multi_context   \n",
              "40                   Everything else goes into Vault.  multi_context   \n",
              "41  Emails in the Action subfolders and the Pendin...  multi_context   \n",
              "42  Expanding skills post-grad leads to career suc...  multi_context   \n",
              "43  MacLeod's Fall Revolution sequence includes th...  multi_context   \n",
              "44  Scott Adams says that combining communication ...  multi_context   \n",
              "45  Commodity hardware, open source software, and ...      reasoning   \n",
              "46  The answer to given question is not present in...      reasoning   \n",
              "47  Detailed training boosts new executives' credi...      reasoning   \n",
              "48  When there are emails in the inbox that haven'...      reasoning   \n",
              "49  The answer to given question is not present in...      reasoning   \n",
              "\n",
              "                                             metadata  episode_done  \n",
              "0   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "1   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "2   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "3   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "4   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "5   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "6   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "7   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "8   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "9   [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "10  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "11  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "12  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "13  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "14  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "15  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "16  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "17  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "18  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "19  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "20  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "21  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "22  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "23  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "24  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "25  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "26  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "27  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "28  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "29  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "30  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "31  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "32  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "33  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "34  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "35  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "36  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "37  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "38  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "39  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "40  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "41  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "42  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "43  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "44  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "45  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "46  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "47  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "48  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "49  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from ragas.testset.generator import TestsetGenerator\n",
        "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "\n",
        "generator_llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "critic_llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "generator = TestsetGenerator.from_langchain(\n",
        "    generator_llm,\n",
        "    critic_llm,\n",
        "    embeddings\n",
        ")\n",
        "\n",
        "distributions = {\n",
        "    simple: 0.5,\n",
        "    multi_context: 0.4,\n",
        "    reasoning: 0.1\n",
        "}\n",
        "\n",
        "num_qa_pairs = 50 # You can reduce the number of QA pairs to 5 if you're experiencing rate-limiting issues\n",
        "\n",
        "testset = generator.generate_with_langchain_docs(eval_documents, num_qa_pairs, distributions)\n",
        "testset.to_pandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MemL406rUzBu"
      },
      "source": [
        "Let's look at the output and see what we can learn about it!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaCDdImVU15s",
        "outputId": "31efbb94-f09d-4d50-8c6e-59202aaeb5c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataRow(question='Why is it generally a good idea to end up with smaller team sizes after restructuring?', contexts=['redesign is that you want to tolerate overlap. So each product\\ndivision has its own QA team — so what? Your division heads —\\nwho are now your best people — will be able to move so much\\nfaster that way that it’s worth it. Plus, you saved so much money\\ntaking out the VIPs, summertime soldiers, and mediocre people\\nthat you’re still ahead on headcount expense.\\nRemember, it’s generally a good idea, once you do all of this\\nrestructuring, to end up with smaller team sizes than you had\\nbefore. By reducing the size of a team, and increasing the aver-'], ground_truth='By reducing the size of a team, and increasing the average quality of team members, divisions will be able to move much faster.', evolution_type='simple', metadata=[{'source': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'file_path': 'https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf', 'page': 94, 'total_pages': 195, 'format': 'PDF 1.3', 'title': 'The Pmarca Blog Archives', 'author': '', 'subject': '', 'keywords': '', 'creator': '', 'producer': 'Mac OS X 10.10 Quartz PDFContext', 'creationDate': \"D:20150110020418Z00'00'\", 'modDate': \"D:20150110020418Z00'00'\", 'trapped': ''}])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testset.test_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1iZ0_GTEp9bd"
      },
      "outputs": [],
      "source": [
        "testset_df = testset.to_pandas()\n",
        "testset_df.to_csv(\"testset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITOQFNxdxS6n"
      },
      "source": [
        "#### PREFERRED: Download `.csv` from DataRepository\n",
        "\n",
        "I have to consume $85 before the end of September because credits I bought a year ago are going to expire!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6mmr2hyxW_i",
        "outputId": "83727d02-2b34-403a-b1c4-16a98994c020"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/AI-Maker-Space/DataRepository.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "u2PpgX-RxnlW"
      },
      "outputs": [],
      "source": [
        "# !mv DataRepository/testset.csv ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrPsVwUAWFWB"
      },
      "source": [
        "### Generating Responses with RAG Pipeline\n",
        "\n",
        "Now that we have some QC pairs, and some ground truths, let's evaluate our RAG pipeline using Ragas.\n",
        "\n",
        "The process is, again, quite straightforward - thanks to Ragas and LangChain!\n",
        "\n",
        "Let's start by extracting our questions and ground truths from our create testset.\n",
        "\n",
        "We can start by converting our test dataset into a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "frvzu1YxX8kY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "test_df = pd.read_csv(\"testset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GFKMIY8IZU8m",
        "outputId": "42652c9f-9e6f-41a1-b63d-d7faa23fe275"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>question</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>evolution_type</th>\n",
              "      <th>metadata</th>\n",
              "      <th>episode_done</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Why is it generally a good idea to end up with...</td>\n",
              "      <td>['redesign is that you want to tolerate overla...</td>\n",
              "      <td>By reducing the size of a team, and increasing...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>How has evolution influenced the tendency of a...</td>\n",
              "      <td>['Four: Doubt-Avoidance Tendency\\nThe brain of...</td>\n",
              "      <td>Evolution has influenced the tendency of anima...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>What is the risk associated with the funding w...</td>\n",
              "      <td>['Here’s why you shouldn’t do that:\\nWhat are ...</td>\n",
              "      <td>The risk associated with the funding window no...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>How can the culture of a startup be affected b...</td>\n",
              "      <td>['(In case you were wondering, by the way, the...</td>\n",
              "      <td>The culture of a startup can be affected by th...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>What are the intangibles that keep great peopl...</td>\n",
              "      <td>['Closing thought\\nIn general, the intangibles...</td>\n",
              "      <td>The intangibles that keep great people are the...</td>\n",
              "      <td>simple</td>\n",
              "      <td>[{'source': 'https://d1lamhf6l6yk6d.cloudfront...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                           question  \\\n",
              "0           0  Why is it generally a good idea to end up with...   \n",
              "1           1  How has evolution influenced the tendency of a...   \n",
              "2           2  What is the risk associated with the funding w...   \n",
              "3           3  How can the culture of a startup be affected b...   \n",
              "4           4  What are the intangibles that keep great peopl...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  ['redesign is that you want to tolerate overla...   \n",
              "1  ['Four: Doubt-Avoidance Tendency\\nThe brain of...   \n",
              "2  ['Here’s why you shouldn’t do that:\\nWhat are ...   \n",
              "3  ['(In case you were wondering, by the way, the...   \n",
              "4  ['Closing thought\\nIn general, the intangibles...   \n",
              "\n",
              "                                        ground_truth evolution_type  \\\n",
              "0  By reducing the size of a team, and increasing...         simple   \n",
              "1  Evolution has influenced the tendency of anima...         simple   \n",
              "2  The risk associated with the funding window no...         simple   \n",
              "3  The culture of a startup can be affected by th...         simple   \n",
              "4  The intangibles that keep great people are the...         simple   \n",
              "\n",
              "                                            metadata  episode_done  \n",
              "0  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "1  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "2  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "3  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  \n",
              "4  [{'source': 'https://d1lamhf6l6yk6d.cloudfront...          True  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_df[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "xAiXbVmLYSoC"
      },
      "outputs": [],
      "source": [
        "test_questions = test_df[\"question\"].values.tolist()\n",
        "test_groundtruths = test_df[\"ground_truth\"].values.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aE5rfMLfbqKH"
      },
      "source": [
        "Now we'll generate responses using our RAG pipeline using the questions we've generated - we'll also need to collect our retrieved contexts for each question.\n",
        "\n",
        "We'll do this in a simple loop to see exactly what's happening!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "9_AayvT1dAQN"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
        "  answers.append(response[\"response\"].content)\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opHaHmYDeBfC"
      },
      "source": [
        "Now we can wrap our information in a Hugging Face dataset for use in the Ragas library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "fY48YZITeHy-"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "response_dataset = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmeVvQaZeogE"
      },
      "source": [
        "Let's take a peek and see what that looks like!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOpydvc8eqNM",
        "outputId": "21eda635-f38c-42c7-adad-9e4667f4bbe0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'Why is it generally a good idea to end up with smaller team sizes after restructuring?',\n",
              " 'answer': 'It is generally a good idea to end up with smaller team sizes after restructuring because by reducing the size of a team and increasing the average quality level within the team, you will usually speed things up while saving money.',\n",
              " 'contexts': ['that you’re still ahead on headcount expense.\\nRemember, it’s generally a good idea, once you do all of this\\nrestructuring, to end up with smaller team sizes than you had',\n",
              "  'before. By reducing the size of a team, and increasing the aver-\\nage quality level within the team, you will usually speed things\\nup, while saving money.',\n",
              "  'Well, Hrst question: Since team is the thing you have the most\\ncontrol over at the start, and everyone wants to have a great\\nteam, what does a great team actually get you?',\n",
              "  'answer, in part because in the beginning of a startup, you know\\na lot more about the team than you do the product, which hasn’t\\nbeen built yet, or the market, which hasn’t been explored yet.'],\n",
              " 'ground_truth': 'By reducing the size of a team, and increasing the average quality of team members, divisions will be able to move much faster.'}"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM4fmAnsBmL2"
      },
      "source": [
        "# 🤝 Breakout Room Part #2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbsFm5FievJI"
      },
      "source": [
        "## Task 1: Evaluating our Pipeline with Ragas\n",
        "\n",
        "Now that we have our response dataset - we can finally get into the \"meat\" of Ragas - evaluation!\n",
        "\n",
        "First, we'll import the desired metrics, then we can use them to evaluate our created dataset!\n",
        "\n",
        "Check out the specific metrics we'll be using in the Ragas documentation:\n",
        "\n",
        "- [Faithfulness](https://docs.ragas.io/en/stable/concepts/metrics/faithfulness.html)\n",
        "- [Answer Relevancy](https://docs.ragas.io/en/stable/concepts/metrics/answer_relevance.html)\n",
        "- [Context Precision](https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html)\n",
        "- [Context Recall](https://docs.ragas.io/en/stable/concepts/metrics/context_recall.html)\n",
        "- [Answer Correctness](https://docs.ragas.io/en/stable/concepts/metrics/answer_correctness.html)\n",
        "\n",
        "See the accompanied presentation for more in-depth explanations about each of the metrics!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "R2PXwyt8e5aW"
      },
      "outputs": [],
      "source": [
        "from ragas import evaluate\n",
        "from ragas.metrics import (\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    answer_correctness,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        ")\n",
        "\n",
        "metrics = [\n",
        "    faithfulness,\n",
        "    answer_relevancy,\n",
        "    context_recall,\n",
        "    context_precision,\n",
        "    answer_correctness,\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx-vlsx_hrtV"
      },
      "source": [
        "All that's left to do is call \"evaluate\" and away we go!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "4d9ba78dc78040f494df9122ddc7ba1d",
            "e4e76e5d4fba404a9ed4ff059f3a0c04",
            "1e2026abc1314d3caf37d74af7a407e7",
            "fb306876e3244dc69312e2af46c4da02",
            "b319ae78e30d437c81f07d5a062ba805",
            "22c5f6324de545ba814402c3f71d84f1",
            "764b7b6827c9437b90c9c948b9f1037b",
            "e32bc4bb09af4ac5a608e56f87317596",
            "b53095cea92740dfb967120a77310283",
            "d020211480b149cab1761b14ae631eb1",
            "63d6044414e24c5ea55efa925f7a3b56"
          ]
        },
        "id": "DhlcfJ4lgYVI",
        "outputId": "77bfa68b-ddff-47f6-8ebf-e726c5ba8c1f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6e27d3df0024487bef323b2de0b0de3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results = evaluate(response_dataset, metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqPArpSrgwDD",
        "outputId": "93940cfe-3750-41aa-9c20-1fc1eaf37287"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.7754, 'answer_relevancy': 0.6923, 'context_recall': 0.7400, 'context_precision': 0.6811, 'answer_correctness': 0.6022}"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2nsGzj8DhP9E",
        "outputId": "cf47bdeb-c3ba-456a-9231-d08105c68f4c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>contexts</th>\n",
              "      <th>ground_truth</th>\n",
              "      <th>faithfulness</th>\n",
              "      <th>answer_relevancy</th>\n",
              "      <th>context_recall</th>\n",
              "      <th>context_precision</th>\n",
              "      <th>answer_correctness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Why is it generally a good idea to end up with...</td>\n",
              "      <td>It is generally a good idea to end up with sma...</td>\n",
              "      <td>[that you’re still ahead on headcount expense....</td>\n",
              "      <td>By reducing the size of a team, and increasing...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.931375</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.978382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>How has evolution influenced the tendency of a...</td>\n",
              "      <td>Evolution has influenced the tendency of anima...</td>\n",
              "      <td>[Four: Doubt-Avoidance Tendency\\nThe brain of ...</td>\n",
              "      <td>Evolution has influenced the tendency of anima...</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.866072</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.744145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the risk associated with the funding w...</td>\n",
              "      <td>The risk associated with the funding window no...</td>\n",
              "      <td>[Second, the funding window may not be open wh...</td>\n",
              "      <td>The risk associated with the funding window no...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.996141</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.883760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How can the culture of a startup be affected b...</td>\n",
              "      <td>The culture of a startup can be significantly ...</td>\n",
              "      <td>[(In case you were wondering, by the way, the ...</td>\n",
              "      <td>The culture of a startup can be affected by th...</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.965583</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.774824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What are the intangibles that keep great peopl...</td>\n",
              "      <td>I do not know. The provided context does not i...</td>\n",
              "      <td>[feel like they’re the B team) and the great p...</td>\n",
              "      <td>The intangibles that keep great people are the...</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.212907</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  Why is it generally a good idea to end up with...   \n",
              "1  How has evolution influenced the tendency of a...   \n",
              "2  What is the risk associated with the funding w...   \n",
              "3  How can the culture of a startup be affected b...   \n",
              "4  What are the intangibles that keep great peopl...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  It is generally a good idea to end up with sma...   \n",
              "1  Evolution has influenced the tendency of anima...   \n",
              "2  The risk associated with the funding window no...   \n",
              "3  The culture of a startup can be significantly ...   \n",
              "4  I do not know. The provided context does not i...   \n",
              "\n",
              "                                            contexts  \\\n",
              "0  [that you’re still ahead on headcount expense....   \n",
              "1  [Four: Doubt-Avoidance Tendency\\nThe brain of ...   \n",
              "2  [Second, the funding window may not be open wh...   \n",
              "3  [(In case you were wondering, by the way, the ...   \n",
              "4  [feel like they’re the B team) and the great p...   \n",
              "\n",
              "                                        ground_truth  faithfulness  \\\n",
              "0  By reducing the size of a team, and increasing...          1.00   \n",
              "1  Evolution has influenced the tendency of anima...          0.75   \n",
              "2  The risk associated with the funding window no...          1.00   \n",
              "3  The culture of a startup can be affected by th...          1.00   \n",
              "4  The intangibles that keep great people are the...          0.50   \n",
              "\n",
              "   answer_relevancy  context_recall  context_precision  answer_correctness  \n",
              "0          0.931375             1.0           1.000000            0.978382  \n",
              "1          0.866072             1.0           1.000000            0.744145  \n",
              "2          0.996141             1.0           1.000000            0.883760  \n",
              "3          0.965583             0.5           1.000000            0.774824  \n",
              "4          0.000000             1.0           0.833333            0.212907  "
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results_df = results.to_pandas()\n",
        "results_df[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJKEOLNs5v0R"
      },
      "source": [
        "## Task : Testing OpenAI's Claim\n",
        "\n",
        "Now that we've seen how our retriever can impact the performance of our RAG pipeline - let's see how changing our embedding model impacts performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM4KRhJYEL-h"
      },
      "source": [
        "#### 🏗️ Activity #1:\n",
        "\n",
        "Please provide markdown, or code comments, to explain which each of the following steps are doing!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "#### Activity 1 Markdown\n",
        "The next cell is changing the embedding model from ADA to te3-small so we can test the claim about superiority.\n",
        "Notice above, by the say, that my result statistics were very good already, so it will be interesting to see if this changes\n",
        "any results.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "Gv_tv4w86bPb"
      },
      "outputs": [],
      "source": [
        "te3_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### Activity 1 Markdown (continued)\n",
        "Now we create a new collection (same name with appended TE3 so we can tell the difference).\n",
        "We also create a vector store, and add the same documents as in the previous situation.  The\n",
        "key difference is that the embedding model is changed.  I also suppressed the output of the cell.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The following code is commented out because I already ran it and the collection already exists in Qdrant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JPe1_Jx6Rnw",
        "outputId": "9f552c17-dea5-4b87-a609-7f8bc37f82bd"
      },
      "outputs": [],
      "source": [
        "# qdrant_client.create_collection(\n",
        "#     collection_name=COLLECTION_NAME+\"TE3\",\n",
        "#     vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
        "# )\n",
        "\n",
        "# qdrant_vector_store = QdrantVectorStore(\n",
        "#     client=qdrant_client,\n",
        "#     collection_name=COLLECTION_NAME+\"TE3\",\n",
        "#     embedding=te3_embeddings,\n",
        "# )\n",
        "\n",
        "# qdrant_vector_store.add_documents(documents);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Now make a retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "H-HuozNf6muZ"
      },
      "outputs": [],
      "source": [
        "te3_retriever = qdrant_vector_store.as_retriever()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating a new abstraction.\n",
        "The original code for the qa_retrieval_chain from earlier in the notebook is:\n",
        "\n",
        "```python\n",
        "retrieval_augmented_qa_chain = (\n",
        "    {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "    | {\"response\": prompt | primary_qa_llm, \"context\": itemgetter(\"context\")}\n",
        ")\n",
        "```\n",
        "create_stuff_documents_chain allows us to pass a list of Documents to a model; the first two parameters are the model and the prompt.  So document_chain is a Runnable\n",
        "and we have set up the model and the prompt.  Then we use create_retrieval_chain to attach our retriever to our document_chain.  This abstracts away the details of the document_chain, so it makes the actions more understandable.  Maybe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "HJB1ZIAcss1q"
      },
      "outputs": [],
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "document_chain = create_stuff_documents_chain(primary_qa_llm, retrieval_qa_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "s5QSJIhm7SKr"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "te3_retrieval_chain = create_retrieval_chain(te3_retriever, document_chain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Now we create our data for RAGAS.\n",
        "We set up answers and contexts as empty lists, as we will populate these by invoking the te3-retrieval_chain that was created in the last cell.  We loop through all 50 of our questions, receive the answer and context that are in the LLM response, and stick those answers and contexts into a list.  Since the lists are in the same order as the questions in the test_questions data set, this will enable us to create the quadruples needed for the RAGAS evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "MBVjl1UK7fd7"
      },
      "outputs": [],
      "source": [
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = te3_retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Which we now do, creating a Hugging Face Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "lTBrs0zr7iyG"
      },
      "outputs": [],
      "source": [
        "te3_response_dataset_advanced_retrieval = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Now we do the RAGAS evaluation\n",
        "This will compare the various components of our data set to line up with the metrics that we imported earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ced3689d335c4f1ca62d39b908d6cb33",
            "824fe37b12d4414a9376e266ddd086f5",
            "00afceb39c074975b6b88d6d0d4d2901",
            "e8c20cb22ecb40dbaf61959fc7d087cb",
            "771597df670f417794f66408b05a7eb9",
            "9496fc3f26cb42ec9ace36175eb14906",
            "8025a0f161d3475794daa9cd88209d5c",
            "9932859168ad436e9aeef09279b534b1",
            "474f44771cb04a4693585273a03a5548",
            "90af75e58cef440a8d38ee6621e0f4d1",
            "ce0b10aca9064bc092cf3305eb0dab04"
          ]
        },
        "id": "hG5h-D8n7sZp",
        "outputId": "54cc5a58-e508-40dc-d3a1-bf7f17917b5b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8545b80a9494098a398598f40c7b3ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "te3_advanced_retrieval_results = evaluate(te3_response_dataset_advanced_retrieval, metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Now look at the results of this run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uHdcpsZ76kj",
        "outputId": "83a68685-68a0-4d73-b00e-6c44f174329b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.7271, 'answer_relevancy': 0.8679, 'context_recall': 0.8300, 'context_precision': 0.7167, 'answer_correctness': 0.6875}"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "te3_advanced_retrieval_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Read the results into a panda DataFrame and compare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s4TyaCUQ79Ke",
        "outputId": "223265df-d87b-4f3f-ddba-039f31c9d73a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>ADA</th>\n",
              "      <th>TE3</th>\n",
              "      <th>Baseline -&gt; TE3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>faithfulness</td>\n",
              "      <td>0.775389</td>\n",
              "      <td>0.727133</td>\n",
              "      <td>-0.048256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_relevancy</td>\n",
              "      <td>0.692285</td>\n",
              "      <td>0.867880</td>\n",
              "      <td>0.175596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.090000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.681111</td>\n",
              "      <td>0.716667</td>\n",
              "      <td>0.035556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.602239</td>\n",
              "      <td>0.687484</td>\n",
              "      <td>0.085245</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric       ADA       TE3  Baseline -> TE3\n",
              "0        faithfulness  0.775389  0.727133        -0.048256\n",
              "1    answer_relevancy  0.692285  0.867880         0.175596\n",
              "2      context_recall  0.740000  0.830000         0.090000\n",
              "3   context_precision  0.681111  0.716667         0.035556\n",
              "4  answer_correctness  0.602239  0.687484         0.085245"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_baseline = pd.DataFrame(list(results.items()), columns=['Metric', 'ADA'])\n",
        "df_comparison = pd.DataFrame(list(te3_advanced_retrieval_results.items()), columns=['Metric', 'TE3'])\n",
        "\n",
        "df_merged = pd.merge(df_baseline, df_comparison, on='Metric')\n",
        "\n",
        "df_merged['Baseline -> TE3'] = df_merged['TE3'] - df_merged['ADA']\n",
        "\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRmkcMrxC4Me"
      },
      "source": [
        "#### ❓ Question #3:\n",
        "\n",
        "Do you think, in your opinion, `text-embedding-3-small` is significantly better than `ada`?\n",
        "\n",
        "---\n",
        "### ANSWER #3:\n",
        "\n",
        "Faithfulness took a small hit, and recall that this evaluates whether the generated answers are supported by the retrieved context.  This is important as we would like to prevent hallucinations, but the magnitude of this change has uncertain meaning, since it is only in the \"context\" of the questions that were generated earlier.  Importantly, all other metrics improved rather significantly, especially answer relevancy.  This measures how well the answer addressed the question, penalizing for irrelevant or redundant information.  Answer correctness always seems useful to me and it improved as well.\n",
        "\n",
        "I would agree that the new OpenAI embedding model is superior to the older ADA model.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D-mJuXKytXw"
      },
      "source": [
        "## Task 5: Selecting an Advanced Retriever and Evaluating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ac__xQxy11O"
      },
      "source": [
        "#### 🏗️ Activity #2\n",
        "\n",
        "While the changes that occured due to modifying the embedding model were desirable - you're now tasked with improving `context_recall`, or `context_precision` (or both!).\n",
        "\n",
        "You'll follow these steps:\n",
        "\n",
        "1. Reason about this list of Advanced Retrieval methods:\n",
        "  - [Contextual Compression (Reranker)](https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/contextual_compression/)\n",
        "  - [MultiQueryRetriever](https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/MultiQueryRetriever/)\n",
        "  - [Parent Document Retriever](https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/parent_document_retriever/)\n",
        "2. Select the method you think will be the most performant.\n",
        "3. Implement that method.\n",
        "4. Create a LCEL chain that utlizes the new Retriever method.\n",
        "5. Evaluate this LCEL and compare to the TE3 results.\n",
        "\n",
        "> NOTE: We will spend more time in Session 14 diving into advanced retrieval methods, this activity is only to serve as a basic introduction to the idea of component-wise improvements and how they might impact metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "uWFhG7tAz_tj"
      },
      "outputs": [],
      "source": [
        "### Let see if we can implement the parent child system!  Seems most valuable for my main project ideas.\n",
        "\n",
        "from langchain.storage import InMemoryStore\n",
        "from langchain.retrievers import ParentDocumentRetriever\n",
        "\n",
        "# Make sure we are starting where we started:\n",
        "PDF_LINK = \"https://d1lamhf6l6yk6d.cloudfront.net/uploads/2021/08/The-pmarca-Blog-Archives.pdf\"\n",
        "documents = PyMuPDFLoader(PDF_LINK).load()\n",
        "\n",
        "# Set up two splitters - parent and child\n",
        "parent_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=2000,\n",
        "    add_start_index=True\n",
        ")\n",
        "child_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    add_start_index=True\n",
        ")\n",
        "\n",
        "te3_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The following code is commented because I already ran it and the collection already exists in Qdrant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# # vectorstore for child chunks\n",
        "# child_qdrant_client = QdrantClient(\"localhost:55002\")\n",
        "# CHILD_COLLECTION_NAME = \"CHILD-200-TE3\"\n",
        "# child_qdrant_client.create_collection(\n",
        "#     collection_name=CHILD_COLLECTION_NAME,\n",
        "#     vectors_config=VectorParams(size=1536, distance=Distance.COSINE)\n",
        "# )\n",
        "# child_vector_store = QdrantVectorStore(\n",
        "#     client=child_qdrant_client,\n",
        "#     collection_name=CHILD_COLLECTION_NAME,\n",
        "#     embedding=te3_embeddings\n",
        "# )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set up store for parent documents\n",
        "store = InMemoryStore()\n",
        "\n",
        "# Now create the parent child retriever\n",
        "pc_retriever = ParentDocumentRetriever(\n",
        "    vectorstore=child_vector_store,\n",
        "    docstore = store,\n",
        "    child_splitter=child_splitter,\n",
        "    parent_splitter=parent_splitter,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add documents\n",
        "pc_retriever.add_documents(documents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9176\n"
          ]
        }
      ],
      "source": [
        "# How many child docs are in the vector store?  ANSWER SHOULD BE 4588 (from local server)\n",
        "collection_info = child_qdrant_client.get_collection(CHILD_COLLECTION_NAME)\n",
        "num_vectors = collection_info.points_count\n",
        "print(num_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "225"
            ]
          },
          "execution_count": 131,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Parent docs that are in memory\n",
        "len(list(store.yield_keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n",
            "section of Silicon Valley startups — so don’t think that anything\n",
            "I am talking about is referring to one of my own companies:\n",
            "most likely when I talk about a scenario I have seen or some-\n",
            "companies as Sun, Cisco, Yahoo, and Google, so needless to say,\n",
            "Silicon Valley VCs are continually on the prowl on the Stanford\n",
            "engineering campus for the next Jerry Yang or Larry Page.\n",
            "start new companies when they could just park it on a beach and\n",
            "suck down mai tais?\n",
            "First, in my experience, Silicon Valley entrepreneurs are all over\n",
            "white! In Silicon Valley, for example, it can still make a lot of\n",
            "sense for a young parent to take a risk on a hot new startup\n",
            "because it will usually be easy to get another job if the startup\n"
          ]
        }
      ],
      "source": [
        "# Now let's do a similarity search from the vector store, and then try to retrieve the parent\n",
        "sub_docs = qdrant_vector_store.similarity_search(\"Silicon Valley startups\")\n",
        "print(len(sub_docs))\n",
        "for sub_doc in sub_docs:\n",
        "    print(sub_doc.page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "Part 1: Why not to do a startup\n",
            "In this series of posts I will walk through some of my accumu-\n",
            "lated knowledge and experience in building high-tech startups.\n",
            "My speciXc experience is from three companies I have co-\n",
            "founded: Netscape, sold to America Online in 1998 for $4.2\n",
            "billion; Opsware (formerly Loudcloud), a public soaware com-\n",
            "pany with an approximately $1 billion market cap; and now\n",
            "Ning, a new, private consumer Internet company.\n",
            "But more generally, I’ve been fortunate enough to be involved\n",
            "in and exposed to a broad range of other startups — maybe 40\n",
            "or 50 in enough detail to know what I’m talking about — since\n",
            "arriving in Silicon Valley in 1994: as a board member, as an angel\n",
            "investor, as an advisor, as a friend of various founders, and as a\n",
            "participant in various venture capital funds.\n",
            "This series will focus on lessons learned from this entire cross-\n",
            "section of Silicon Valley startups — so don’t think that anything\n",
            "I am talking about is referring to one of my own companies:\n",
            "most likely when I talk about a scenario I have seen or some-\n",
            "thing I have experienced, it is from some other startup that I\n",
            "am not naming but was involved with some other way than as a\n",
            "founder.\n",
            "Finally, much of my perspective is based on Silicon Valley and\n",
            "the environment that we have here — the culture, the people,\n",
            "the venture capital base, and so on. Some of it will travel well\n"
          ]
        }
      ],
      "source": [
        "# Now let's use the pc_retriever to get parents documents\n",
        "retrieved_parent_documents = pc_retriever.invoke(\"Silicon Valley startups\")\n",
        "print(len(retrieved_parent_documents))\n",
        "print(retrieved_parent_documents[0].page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [],
      "source": [
        "# So this appears to work.  Now I need to build a RAG chain.  This is easy because of the earlier abstraction!!\n",
        "\n",
        "pc_retrieval_chain = create_retrieval_chain(pc_retriever, document_chain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The rule of thumb for selecting an industry to invest in is to pick an industry where the founders of the important companies are still alive and actively involved. This can be determined by looking at the CEO, chairman or chairwoman, and board of directors for the major companies in the industry. If the founders are currently serving in these roles, it indicates that the industry is likely still young, vital, and full of opportunities.\n"
          ]
        }
      ],
      "source": [
        "# Now see if it works\n",
        "question = \"What is a rule of thumb for selecting an industry to invest in?\"\n",
        "print(pc_retrieval_chain.invoke({\"input\": question})[\"answer\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now I need to do the RAGAS evaluation with this retrieval chain\n",
        "answers = []\n",
        "contexts = []\n",
        "\n",
        "for question in test_questions:\n",
        "  response = pc_retrieval_chain.invoke({\"input\" : question})\n",
        "  answers.append(response[\"answer\"])\n",
        "  contexts.append([context.page_content for context in response[\"context\"]])\n",
        "\n",
        "\n",
        "response_dataset = Dataset.from_dict({\n",
        "    \"question\" : test_questions,\n",
        "    \"answer\" : answers,\n",
        "    \"contexts\" : contexts,\n",
        "    \"ground_truth\" : test_groundtruths\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86b9a35330944ca2b38279dbe2bf3374",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating:   0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'faithfulness': 0.7757, 'answer_relevancy': 0.8468, 'context_recall': 0.9900, 'context_precision': 0.9000, 'answer_correctness': 0.6594}"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pc_results = evaluate(response_dataset, metrics)\n",
        "pc_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Metric</th>\n",
              "      <th>ADA</th>\n",
              "      <th>TE3</th>\n",
              "      <th>PC</th>\n",
              "      <th>Baseline -&gt; TE3</th>\n",
              "      <th>% TE3</th>\n",
              "      <th>Baseline -&gt; PC</th>\n",
              "      <th>% PC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>faithfulness</td>\n",
              "      <td>0.775389</td>\n",
              "      <td>0.727133</td>\n",
              "      <td>0.775739</td>\n",
              "      <td>-0.048256</td>\n",
              "      <td>-6.223436</td>\n",
              "      <td>0.000350</td>\n",
              "      <td>0.045189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>answer_relevancy</td>\n",
              "      <td>0.692285</td>\n",
              "      <td>0.867880</td>\n",
              "      <td>0.846816</td>\n",
              "      <td>0.175596</td>\n",
              "      <td>25.364697</td>\n",
              "      <td>0.154531</td>\n",
              "      <td>22.321949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>context_recall</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.990000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>12.162162</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>33.783784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>context_precision</td>\n",
              "      <td>0.681111</td>\n",
              "      <td>0.716667</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.035556</td>\n",
              "      <td>5.220228</td>\n",
              "      <td>0.218889</td>\n",
              "      <td>32.137031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer_correctness</td>\n",
              "      <td>0.602239</td>\n",
              "      <td>0.687484</td>\n",
              "      <td>0.659416</td>\n",
              "      <td>0.085245</td>\n",
              "      <td>14.154662</td>\n",
              "      <td>0.057178</td>\n",
              "      <td>9.494193</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Metric       ADA       TE3        PC  Baseline -> TE3  \\\n",
              "0        faithfulness  0.775389  0.727133  0.775739        -0.048256   \n",
              "1    answer_relevancy  0.692285  0.867880  0.846816         0.175596   \n",
              "2      context_recall  0.740000  0.830000  0.990000         0.090000   \n",
              "3   context_precision  0.681111  0.716667  0.900000         0.035556   \n",
              "4  answer_correctness  0.602239  0.687484  0.659416         0.085245   \n",
              "\n",
              "       % TE3  Baseline -> PC       % PC  \n",
              "0  -6.223436        0.000350   0.045189  \n",
              "1  25.364697        0.154531  22.321949  \n",
              "2  12.162162        0.250000  33.783784  \n",
              "3   5.220228        0.218889  32.137031  \n",
              "4  14.154662        0.057178   9.494193  "
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_baseline = pd.DataFrame(list(results.items()), columns=['Metric', 'ADA'])\n",
        "df_comparison = pd.DataFrame(list(te3_advanced_retrieval_results.items()), columns=['Metric', 'TE3'])\n",
        "df_parents = pd.DataFrame(list(pc_results.items()),columns=['Metric', 'PC'])\n",
        "\n",
        "df_merged = pd.merge(df_baseline, df_comparison, on='Metric')\n",
        "df_merged = pd.merge(df_merged, df_parents, on = 'Metric')\n",
        "\n",
        "df_merged['Baseline -> TE3'] = df_merged['TE3'] - df_merged['ADA']\n",
        "df_merged['% TE3'] = 100*(df_merged['TE3'] - df_merged['ADA'])/df_merged['ADA']\n",
        "df_merged['Baseline -> PC'] = df_merged['PC'] - df_merged['ADA']\n",
        "df_merged['% PC'] = 100*(df_merged['PC'] - df_merged['ADA'])/df_merged['ADA']\n",
        "\n",
        "df_merged"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### ACTIVITY 2 COMMENTS\n",
        "I chose to do the parent - child approach because in many of my clinical applications, this is a very desirable thing to try.\n",
        "\n",
        "The results show that this advanced retrieval method enhanced context_recall and context_precision rather drastically, taking them each to over 0.90, and the context_recall reached 0.99.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-YMk7zQ174y"
      },
      "source": [
        "#### 🚧 BONUS CHALLENGE 🚧\n",
        "\n",
        "> NOTE: Completing this challenge will provide full marks on the assignment, regardless of the complete of the notebook. You do not need to complete this in the notebook for full marks.\n",
        "\n",
        "##### **MINIMUM REQUIREMENTS**:\n",
        "\n",
        "1. Baseline `LCEL RAG` Application using `NAIVE RETRIEVAL`\n",
        "2. Baseline Evaluation using `RAGAS METRICS`\n",
        "  - [Faithfulness](https://docs.ragas.io/en/stable/concepts/metrics/faithfulness.html)\n",
        "  - [Answer Relevancy](https://docs.ragas.io/en/stable/concepts/metrics/answer_relevance.html)\n",
        "  - [Context Precision](https://docs.ragas.io/en/stable/concepts/metrics/context_precision.html)\n",
        "  - [Context Recall](https://docs.ragas.io/en/stable/concepts/metrics/context_recall.html)\n",
        "  - [Answer Correctness](https://docs.ragas.io/en/stable/concepts/metrics/answer_correctness.html)\n",
        "3. Implement a `SEMANTIC CHUNKING STRATEGY`.\n",
        "4. Create an `LCEL RAG` Application using `SEMANTIC CHUNKING` with `NAIVE RETRIEVAL`.\n",
        "5. Compare and contrast results.\n",
        "\n",
        "##### **SEMANTIC CHUNKING REQUIREMENTS**:\n",
        "\n",
        "Chunk semantically similar (based on designed threshold) sentences, and then paragraphs, greedily, up to a maximum chunk size. Minimum chunk size is a single sentence.\n",
        "\n",
        "Have fun!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Clyykfe6xOIo"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00afceb39c074975b6b88d6d0d4d2901": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9932859168ad436e9aeef09279b534b1",
            "max": 95,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_474f44771cb04a4693585273a03a5548",
            "value": 95
          }
        },
        "0267d8c4d9cc48b0a4d60d206de62a91": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09c3173c05f54539ae025937b1525e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0be98b57b4894cf9a92818ae1dd72976": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bda4d1ec0f0043c8b4d254a4ada3e9bf",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b24ed8b36764c39aef39c92430fdc1d",
            "value": 20
          }
        },
        "126c30cc07c4452ab73fefce09dab617": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1535c2c75a104f3abb262c5fb7859c14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b24ed8b36764c39aef39c92430fdc1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c0f9aeab5de4e32af8bfef423a64f3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0267d8c4d9cc48b0a4d60d206de62a91",
            "placeholder": "​",
            "style": "IPY_MODEL_126c30cc07c4452ab73fefce09dab617",
            "value": "Generating: 100%"
          }
        },
        "1e2026abc1314d3caf37d74af7a407e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e32bc4bb09af4ac5a608e56f87317596",
            "max": 95,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b53095cea92740dfb967120a77310283",
            "value": 95
          }
        },
        "22c5f6324de545ba814402c3f71d84f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "353b6b9a974048499d854774fe4c882c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b2e50139c234d19ac3e32515e575883": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "474f44771cb04a4693585273a03a5548": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d9ba78dc78040f494df9122ddc7ba1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4e76e5d4fba404a9ed4ff059f3a0c04",
              "IPY_MODEL_1e2026abc1314d3caf37d74af7a407e7",
              "IPY_MODEL_fb306876e3244dc69312e2af46c4da02"
            ],
            "layout": "IPY_MODEL_b319ae78e30d437c81f07d5a062ba805"
          }
        },
        "63d6044414e24c5ea55efa925f7a3b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "754827da55fa4240bce3710048d1645b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd96dd318c1b4e1481c039321e052081",
            "placeholder": "​",
            "style": "IPY_MODEL_3b2e50139c234d19ac3e32515e575883",
            "value": "embedding nodes: 100%"
          }
        },
        "764b7b6827c9437b90c9c948b9f1037b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "771597df670f417794f66408b05a7eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ab80823e1344b638ddd1646367a6ce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b61421d62964b00ba440ecba21f4b52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_353b6b9a974048499d854774fe4c882c",
            "max": 1248,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_09c3173c05f54539ae025937b1525e90",
            "value": 1248
          }
        },
        "8025a0f161d3475794daa9cd88209d5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "824fe37b12d4414a9376e266ddd086f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9496fc3f26cb42ec9ace36175eb14906",
            "placeholder": "​",
            "style": "IPY_MODEL_8025a0f161d3475794daa9cd88209d5c",
            "value": "Evaluating: 100%"
          }
        },
        "90af75e58cef440a8d38ee6621e0f4d1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92f2e2d3123c4cd88d7c5755342ae154": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9496fc3f26cb42ec9ace36175eb14906": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9932859168ad436e9aeef09279b534b1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a40d4ba626f4563b062a5765325d8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c0f9aeab5de4e32af8bfef423a64f3b",
              "IPY_MODEL_0be98b57b4894cf9a92818ae1dd72976",
              "IPY_MODEL_c7550f460273484a913d211381630626"
            ],
            "layout": "IPY_MODEL_ba8f638b7f6343d9b07cce6e54e9be1c"
          }
        },
        "9ccac42dd9f04713b0ed9fe09c35b5b0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "b319ae78e30d437c81f07d5a062ba805": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b53095cea92740dfb967120a77310283": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba8f638b7f6343d9b07cce6e54e9be1c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd96dd318c1b4e1481c039321e052081": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bda4d1ec0f0043c8b4d254a4ada3e9bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3d31c6cf07143aea1bbe76aa13fbca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_754827da55fa4240bce3710048d1645b",
              "IPY_MODEL_7b61421d62964b00ba440ecba21f4b52",
              "IPY_MODEL_c67b66e1f2d34ce4b10789fc2fca5843"
            ],
            "layout": "IPY_MODEL_9ccac42dd9f04713b0ed9fe09c35b5b0"
          }
        },
        "c67b66e1f2d34ce4b10789fc2fca5843": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_faa998b429774e4eb6aaaa5477bb6977",
            "placeholder": "​",
            "style": "IPY_MODEL_7ab80823e1344b638ddd1646367a6ce6",
            "value": " 1248/1248 [07:00&lt;00:00, 49.86s/it]"
          }
        },
        "c7550f460273484a913d211381630626": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1535c2c75a104f3abb262c5fb7859c14",
            "placeholder": "​",
            "style": "IPY_MODEL_92f2e2d3123c4cd88d7c5755342ae154",
            "value": " 20/20 [01:17&lt;00:00, 12.75s/it]"
          }
        },
        "ce0b10aca9064bc092cf3305eb0dab04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ced3689d335c4f1ca62d39b908d6cb33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_824fe37b12d4414a9376e266ddd086f5",
              "IPY_MODEL_00afceb39c074975b6b88d6d0d4d2901",
              "IPY_MODEL_e8c20cb22ecb40dbaf61959fc7d087cb"
            ],
            "layout": "IPY_MODEL_771597df670f417794f66408b05a7eb9"
          }
        },
        "d020211480b149cab1761b14ae631eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e32bc4bb09af4ac5a608e56f87317596": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4e76e5d4fba404a9ed4ff059f3a0c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22c5f6324de545ba814402c3f71d84f1",
            "placeholder": "​",
            "style": "IPY_MODEL_764b7b6827c9437b90c9c948b9f1037b",
            "value": "Evaluating: 100%"
          }
        },
        "e8c20cb22ecb40dbaf61959fc7d087cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90af75e58cef440a8d38ee6621e0f4d1",
            "placeholder": "​",
            "style": "IPY_MODEL_ce0b10aca9064bc092cf3305eb0dab04",
            "value": " 95/95 [00:30&lt;00:00,  1.25it/s]"
          }
        },
        "faa998b429774e4eb6aaaa5477bb6977": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb306876e3244dc69312e2af46c4da02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d020211480b149cab1761b14ae631eb1",
            "placeholder": "​",
            "style": "IPY_MODEL_63d6044414e24c5ea55efa925f7a3b56",
            "value": " 95/95 [00:24&lt;00:00,  1.20it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
